{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lstm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dataset import LABELS\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dataset import silence_detection_training, silence_detection_validation, silence_detection_full, label_detection_validation, label_detection_training, label_detection_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_pickle('results\\\\model_lstm_final_version.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 2.1143 - accuracy: 0.3546\n",
      "Epoch 1: val_accuracy improved from -inf to 0.62180, saving model to models\\lstm.h5\n",
      "214/214 [==============================] - 45s 116ms/step - loss: 2.1143 - accuracy: 0.3546 - val_loss: 1.5125 - val_accuracy: 0.6218\n",
      "Epoch 2/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 1.4649 - accuracy: 0.6138\n",
      "Epoch 2: val_accuracy improved from 0.62180 to 0.63754, saving model to models\\lstm.h5\n",
      "214/214 [==============================] - 23s 109ms/step - loss: 1.4649 - accuracy: 0.6138 - val_loss: 1.3276 - val_accuracy: 0.6375\n",
      "Epoch 3/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 1.2641 - accuracy: 0.6464\n",
      "Epoch 3: val_accuracy improved from 0.63754 to 0.65166, saving model to models\\lstm.h5\n",
      "214/214 [==============================] - 25s 115ms/step - loss: 1.2641 - accuracy: 0.6464 - val_loss: 1.2581 - val_accuracy: 0.6517\n",
      "Epoch 4/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 1.0990 - accuracy: 0.6721\n",
      "Epoch 4: val_accuracy improved from 0.65166 to 0.65828, saving model to models\\lstm.h5\n",
      "214/214 [==============================] - 24s 113ms/step - loss: 1.0990 - accuracy: 0.6721 - val_loss: 1.1788 - val_accuracy: 0.6583\n",
      "Epoch 5/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 0.9547 - accuracy: 0.7067\n",
      "Epoch 5: val_accuracy improved from 0.65828 to 0.68241, saving model to models\\lstm.h5\n",
      "214/214 [==============================] - 25s 116ms/step - loss: 0.9547 - accuracy: 0.7067 - val_loss: 1.1218 - val_accuracy: 0.6824\n",
      "Epoch 6/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 0.8556 - accuracy: 0.7308\n",
      "Epoch 6: val_accuracy improved from 0.68241 to 0.69123, saving model to models\\lstm.h5\n",
      "214/214 [==============================] - 24s 111ms/step - loss: 0.8556 - accuracy: 0.7308 - val_loss: 1.1764 - val_accuracy: 0.6912\n",
      "Epoch 7/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 0.7386 - accuracy: 0.7760\n",
      "Epoch 7: val_accuracy did not improve from 0.69123\n",
      "214/214 [==============================] - 21s 100ms/step - loss: 0.7386 - accuracy: 0.7760 - val_loss: 1.0623 - val_accuracy: 0.6912\n",
      "Epoch 8/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 0.6678 - accuracy: 0.7963\n",
      "Epoch 8: val_accuracy improved from 0.69123 to 0.70035, saving model to models\\lstm.h5\n",
      "214/214 [==============================] - 25s 117ms/step - loss: 0.6678 - accuracy: 0.7963 - val_loss: 1.0823 - val_accuracy: 0.7004\n",
      "Epoch 9/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 0.5907 - accuracy: 0.8133\n",
      "Epoch 9: val_accuracy improved from 0.70035 to 0.71006, saving model to models\\lstm.h5\n",
      "214/214 [==============================] - 26s 123ms/step - loss: 0.5907 - accuracy: 0.8133 - val_loss: 1.0873 - val_accuracy: 0.7101\n",
      "Epoch 10/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 0.5245 - accuracy: 0.8348\n",
      "Epoch 10: val_accuracy did not improve from 0.71006\n",
      "214/214 [==============================] - 26s 120ms/step - loss: 0.5245 - accuracy: 0.8348 - val_loss: 1.1187 - val_accuracy: 0.6895\n",
      "Epoch 11/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 0.4737 - accuracy: 0.8522\n",
      "Epoch 11: val_accuracy did not improve from 0.71006\n",
      "214/214 [==============================] - 27s 124ms/step - loss: 0.4737 - accuracy: 0.8522 - val_loss: 1.2085 - val_accuracy: 0.6926\n",
      "Epoch 12/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 0.4366 - accuracy: 0.8617\n",
      "Epoch 12: val_accuracy improved from 0.71006 to 0.71683, saving model to models\\lstm.h5\n",
      "214/214 [==============================] - 27s 124ms/step - loss: 0.4366 - accuracy: 0.8617 - val_loss: 1.1626 - val_accuracy: 0.7168\n",
      "Epoch 13/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 0.4152 - accuracy: 0.8685\n",
      "Epoch 13: val_accuracy did not improve from 0.71683\n",
      "214/214 [==============================] - 26s 122ms/step - loss: 0.4152 - accuracy: 0.8685 - val_loss: 1.1762 - val_accuracy: 0.6929\n",
      "Epoch 14/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 0.3830 - accuracy: 0.8753\n",
      "Epoch 14: val_accuracy did not improve from 0.71683\n",
      "214/214 [==============================] - 27s 124ms/step - loss: 0.3830 - accuracy: 0.8753 - val_loss: 1.2978 - val_accuracy: 0.6749\n",
      "Epoch 15/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 0.3364 - accuracy: 0.8931\n",
      "Epoch 15: val_accuracy improved from 0.71683 to 0.72551, saving model to models\\lstm.h5\n",
      "214/214 [==============================] - 27s 128ms/step - loss: 0.3364 - accuracy: 0.8931 - val_loss: 1.2333 - val_accuracy: 0.7255\n",
      "Epoch 16/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 0.3312 - accuracy: 0.8917\n",
      "Epoch 16: val_accuracy did not improve from 0.72551\n",
      "214/214 [==============================] - 27s 126ms/step - loss: 0.3312 - accuracy: 0.8917 - val_loss: 1.2092 - val_accuracy: 0.6924\n",
      "Epoch 17/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 0.2871 - accuracy: 0.9086\n",
      "Epoch 17: val_accuracy did not improve from 0.72551\n",
      "214/214 [==============================] - 24s 113ms/step - loss: 0.2871 - accuracy: 0.9086 - val_loss: 1.3625 - val_accuracy: 0.7224\n",
      "Epoch 18/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 0.2893 - accuracy: 0.9065\n",
      "Epoch 18: val_accuracy improved from 0.72551 to 0.72580, saving model to models\\lstm.h5\n",
      "214/214 [==============================] - 24s 114ms/step - loss: 0.2893 - accuracy: 0.9065 - val_loss: 1.3054 - val_accuracy: 0.7258\n",
      "Epoch 19/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 0.2711 - accuracy: 0.9127\n",
      "Epoch 19: val_accuracy did not improve from 0.72580\n",
      "214/214 [==============================] - 27s 125ms/step - loss: 0.2711 - accuracy: 0.9127 - val_loss: 1.2822 - val_accuracy: 0.7257\n",
      "Epoch 20/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 0.2464 - accuracy: 0.9207\n",
      "Epoch 20: val_accuracy did not improve from 0.72580\n",
      "214/214 [==============================] - 28s 131ms/step - loss: 0.2464 - accuracy: 0.9207 - val_loss: 1.3009 - val_accuracy: 0.7246\n",
      "Epoch 1/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 2.3535 - accuracy: 0.2996\n",
      "Epoch 1: val_accuracy improved from -inf to 0.61915, saving model to models\\lstm.h5\n",
      "107/107 [==============================] - 65s 329ms/step - loss: 2.3535 - accuracy: 0.2996 - val_loss: 1.7678 - val_accuracy: 0.6192\n",
      "Epoch 2/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.6455 - accuracy: 0.5589\n",
      "Epoch 2: val_accuracy improved from 0.61915 to 0.62474, saving model to models\\lstm.h5\n",
      "107/107 [==============================] - 25s 233ms/step - loss: 1.6455 - accuracy: 0.5589 - val_loss: 1.4836 - val_accuracy: 0.6247\n",
      "Epoch 3/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.3579 - accuracy: 0.6364\n",
      "Epoch 3: val_accuracy improved from 0.62474 to 0.63401, saving model to models\\lstm.h5\n",
      "107/107 [==============================] - 24s 223ms/step - loss: 1.3579 - accuracy: 0.6364 - val_loss: 1.3678 - val_accuracy: 0.6340\n",
      "Epoch 4/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.2017 - accuracy: 0.6683\n",
      "Epoch 4: val_accuracy improved from 0.63401 to 0.64637, saving model to models\\lstm.h5\n",
      "107/107 [==============================] - 24s 226ms/step - loss: 1.2017 - accuracy: 0.6683 - val_loss: 1.2834 - val_accuracy: 0.6464\n",
      "Epoch 5/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.0566 - accuracy: 0.7005\n",
      "Epoch 5: val_accuracy improved from 0.64637 to 0.65196, saving model to models\\lstm.h5\n",
      "107/107 [==============================] - 24s 225ms/step - loss: 1.0566 - accuracy: 0.7005 - val_loss: 1.2663 - val_accuracy: 0.6520\n",
      "Epoch 6/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.9088 - accuracy: 0.7317\n",
      "Epoch 6: val_accuracy improved from 0.65196 to 0.66211, saving model to models\\lstm.h5\n",
      "107/107 [==============================] - 22s 209ms/step - loss: 0.9088 - accuracy: 0.7317 - val_loss: 1.1835 - val_accuracy: 0.6621\n",
      "Epoch 7/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.8261 - accuracy: 0.7470\n",
      "Epoch 7: val_accuracy improved from 0.66211 to 0.67829, saving model to models\\lstm.h5\n",
      "107/107 [==============================] - 20s 188ms/step - loss: 0.8261 - accuracy: 0.7470 - val_loss: 1.1905 - val_accuracy: 0.6783\n",
      "Epoch 8/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.7097 - accuracy: 0.7865\n",
      "Epoch 8: val_accuracy improved from 0.67829 to 0.67932, saving model to models\\lstm.h5\n",
      "107/107 [==============================] - 20s 183ms/step - loss: 0.7097 - accuracy: 0.7865 - val_loss: 1.2002 - val_accuracy: 0.6793\n",
      "Epoch 9/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.6354 - accuracy: 0.8047\n",
      "Epoch 9: val_accuracy improved from 0.67932 to 0.68608, saving model to models\\lstm.h5\n",
      "107/107 [==============================] - 23s 218ms/step - loss: 0.6354 - accuracy: 0.8047 - val_loss: 1.2186 - val_accuracy: 0.6861\n",
      "Epoch 10/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.5472 - accuracy: 0.8290\n",
      "Epoch 10: val_accuracy improved from 0.68608 to 0.69020, saving model to models\\lstm.h5\n",
      "107/107 [==============================] - 23s 214ms/step - loss: 0.5472 - accuracy: 0.8290 - val_loss: 1.1866 - val_accuracy: 0.6902\n",
      "Epoch 11/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.4843 - accuracy: 0.8468\n",
      "Epoch 11: val_accuracy did not improve from 0.69020\n",
      "107/107 [==============================] - 27s 250ms/step - loss: 0.4843 - accuracy: 0.8468 - val_loss: 1.3019 - val_accuracy: 0.6803\n",
      "Epoch 12/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.4398 - accuracy: 0.8591\n",
      "Epoch 12: val_accuracy improved from 0.69020 to 0.70683, saving model to models\\lstm.h5\n",
      "107/107 [==============================] - 22s 207ms/step - loss: 0.4398 - accuracy: 0.8591 - val_loss: 1.2505 - val_accuracy: 0.7068\n",
      "Epoch 13/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.3897 - accuracy: 0.8806\n",
      "Epoch 13: val_accuracy did not improve from 0.70683\n",
      "107/107 [==============================] - 20s 189ms/step - loss: 0.3897 - accuracy: 0.8806 - val_loss: 1.2619 - val_accuracy: 0.6878\n",
      "Epoch 14/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.3466 - accuracy: 0.8871\n",
      "Epoch 14: val_accuracy did not improve from 0.70683\n",
      "107/107 [==============================] - 21s 193ms/step - loss: 0.3466 - accuracy: 0.8871 - val_loss: 1.3531 - val_accuracy: 0.6961\n",
      "Epoch 15/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.3138 - accuracy: 0.9015\n",
      "Epoch 15: val_accuracy did not improve from 0.70683\n",
      "107/107 [==============================] - 21s 201ms/step - loss: 0.3138 - accuracy: 0.9015 - val_loss: 1.3819 - val_accuracy: 0.6933\n",
      "Epoch 16/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.2830 - accuracy: 0.9074\n",
      "Epoch 16: val_accuracy did not improve from 0.70683\n",
      "107/107 [==============================] - 22s 205ms/step - loss: 0.2830 - accuracy: 0.9074 - val_loss: 1.4102 - val_accuracy: 0.7064\n",
      "Epoch 17/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.2713 - accuracy: 0.9150\n",
      "Epoch 17: val_accuracy improved from 0.70683 to 0.71124, saving model to models\\lstm.h5\n",
      "107/107 [==============================] - 20s 186ms/step - loss: 0.2713 - accuracy: 0.9150 - val_loss: 1.3682 - val_accuracy: 0.7112\n",
      "Epoch 18/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.2581 - accuracy: 0.9204\n",
      "Epoch 18: val_accuracy did not improve from 0.71124\n",
      "107/107 [==============================] - 18s 173ms/step - loss: 0.2581 - accuracy: 0.9204 - val_loss: 1.4882 - val_accuracy: 0.6827\n",
      "Epoch 19/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.2406 - accuracy: 0.9195\n",
      "Epoch 19: val_accuracy did not improve from 0.71124\n",
      "107/107 [==============================] - 19s 177ms/step - loss: 0.2406 - accuracy: 0.9195 - val_loss: 1.4055 - val_accuracy: 0.7043\n",
      "Epoch 20/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.2138 - accuracy: 0.9302\n",
      "Epoch 20: val_accuracy did not improve from 0.71124\n",
      "107/107 [==============================] - 18s 169ms/step - loss: 0.2138 - accuracy: 0.9302 - val_loss: 1.4889 - val_accuracy: 0.6971\n",
      "Epoch 1/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 2.5111 - accuracy: 0.2424\n",
      "Epoch 1: val_accuracy improved from -inf to 0.57252, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 34s 445ms/step - loss: 2.5111 - accuracy: 0.2424 - val_loss: 2.1664 - val_accuracy: 0.5725\n",
      "Epoch 2/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.8213 - accuracy: 0.5268\n",
      "Epoch 2: val_accuracy improved from 0.57252 to 0.60768, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 18s 332ms/step - loss: 1.8213 - accuracy: 0.5268 - val_loss: 1.7281 - val_accuracy: 0.6077\n",
      "Epoch 3/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.4473 - accuracy: 0.6363\n",
      "Epoch 3: val_accuracy improved from 0.60768 to 0.63695, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 18s 333ms/step - loss: 1.4473 - accuracy: 0.6363 - val_loss: 1.4841 - val_accuracy: 0.6370\n",
      "Epoch 4/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.2659 - accuracy: 0.6628\n",
      "Epoch 4: val_accuracy improved from 0.63695 to 0.64622, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 18s 328ms/step - loss: 1.2659 - accuracy: 0.6628 - val_loss: 1.3811 - val_accuracy: 0.6462\n",
      "Epoch 5/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.1558 - accuracy: 0.6770\n",
      "Epoch 5: val_accuracy improved from 0.64622 to 0.65299, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 16s 301ms/step - loss: 1.1558 - accuracy: 0.6770 - val_loss: 1.2541 - val_accuracy: 0.6530\n",
      "Epoch 6/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.0259 - accuracy: 0.7075\n",
      "Epoch 6: val_accuracy improved from 0.65299 to 0.66328, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 16s 302ms/step - loss: 1.0259 - accuracy: 0.7075 - val_loss: 1.2289 - val_accuracy: 0.6633\n",
      "Epoch 7/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.8927 - accuracy: 0.7362\n",
      "Epoch 7: val_accuracy improved from 0.66328 to 0.66637, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 17s 307ms/step - loss: 0.8927 - accuracy: 0.7362 - val_loss: 1.2915 - val_accuracy: 0.6664\n",
      "Epoch 8/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.7933 - accuracy: 0.7598\n",
      "Epoch 8: val_accuracy improved from 0.66637 to 0.67240, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 19s 358ms/step - loss: 0.7933 - accuracy: 0.7598 - val_loss: 1.2166 - val_accuracy: 0.6724\n",
      "Epoch 9/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.7308 - accuracy: 0.7820\n",
      "Epoch 9: val_accuracy improved from 0.67240 to 0.68241, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 22s 402ms/step - loss: 0.7308 - accuracy: 0.7820 - val_loss: 1.3464 - val_accuracy: 0.6824\n",
      "Epoch 10/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.6752 - accuracy: 0.7928\n",
      "Epoch 10: val_accuracy did not improve from 0.68241\n",
      "54/54 [==============================] - 21s 390ms/step - loss: 0.6752 - accuracy: 0.7928 - val_loss: 1.3046 - val_accuracy: 0.6739\n",
      "Epoch 11/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.5508 - accuracy: 0.8303\n",
      "Epoch 11: val_accuracy did not improve from 0.68241\n",
      "54/54 [==============================] - 22s 406ms/step - loss: 0.5508 - accuracy: 0.8303 - val_loss: 1.3494 - val_accuracy: 0.6820\n",
      "Epoch 12/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.4965 - accuracy: 0.8471\n",
      "Epoch 12: val_accuracy improved from 0.68241 to 0.68491, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 21s 395ms/step - loss: 0.4965 - accuracy: 0.8471 - val_loss: 1.3382 - val_accuracy: 0.6849\n",
      "Epoch 13/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.4503 - accuracy: 0.8614\n",
      "Epoch 13: val_accuracy improved from 0.68491 to 0.69756, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 21s 395ms/step - loss: 0.4503 - accuracy: 0.8614 - val_loss: 1.3104 - val_accuracy: 0.6976\n",
      "Epoch 14/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.3981 - accuracy: 0.8767\n",
      "Epoch 14: val_accuracy did not improve from 0.69756\n",
      "54/54 [==============================] - 21s 394ms/step - loss: 0.3981 - accuracy: 0.8767 - val_loss: 1.4092 - val_accuracy: 0.6823\n",
      "Epoch 15/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.3732 - accuracy: 0.8797\n",
      "Epoch 15: val_accuracy improved from 0.69756 to 0.69991, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 22s 404ms/step - loss: 0.3732 - accuracy: 0.8797 - val_loss: 1.3689 - val_accuracy: 0.6999\n",
      "Epoch 16/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.3351 - accuracy: 0.8973\n",
      "Epoch 16: val_accuracy did not improve from 0.69991\n",
      "54/54 [==============================] - 21s 393ms/step - loss: 0.3351 - accuracy: 0.8973 - val_loss: 1.4771 - val_accuracy: 0.6895\n",
      "Epoch 17/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.3011 - accuracy: 0.9071\n",
      "Epoch 17: val_accuracy did not improve from 0.69991\n",
      "54/54 [==============================] - 17s 308ms/step - loss: 0.3011 - accuracy: 0.9071 - val_loss: 1.4824 - val_accuracy: 0.6855\n",
      "Epoch 18/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.2872 - accuracy: 0.9090\n",
      "Epoch 18: val_accuracy improved from 0.69991 to 0.70021, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 16s 288ms/step - loss: 0.2872 - accuracy: 0.9090 - val_loss: 1.4353 - val_accuracy: 0.7002\n",
      "Epoch 19/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.2460 - accuracy: 0.9222\n",
      "Epoch 19: val_accuracy improved from 0.70021 to 0.70271, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 17s 315ms/step - loss: 0.2460 - accuracy: 0.9222 - val_loss: 1.5220 - val_accuracy: 0.7027\n",
      "Epoch 20/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.2209 - accuracy: 0.9267\n",
      "Epoch 20: val_accuracy improved from 0.70271 to 0.70888, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 18s 326ms/step - loss: 0.2209 - accuracy: 0.9267 - val_loss: 1.5380 - val_accuracy: 0.7089\n",
      "Epoch 1/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 1.6817 - accuracy: 0.5827\n",
      "Epoch 1: val_accuracy improved from -inf to 0.62092, saving model to models\\lstm.h5\n",
      "214/214 [==============================] - 43s 156ms/step - loss: 1.6817 - accuracy: 0.5827 - val_loss: 1.6147 - val_accuracy: 0.6209\n",
      "Epoch 2/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 1.5155 - accuracy: 0.6231\n",
      "Epoch 2: val_accuracy did not improve from 0.62092\n",
      "214/214 [==============================] - 24s 114ms/step - loss: 1.5155 - accuracy: 0.6231 - val_loss: 1.4732 - val_accuracy: 0.6209\n",
      "Epoch 3/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 1.4510 - accuracy: 0.6249\n",
      "Epoch 3: val_accuracy did not improve from 0.62092\n",
      "214/214 [==============================] - 26s 121ms/step - loss: 1.4510 - accuracy: 0.6249 - val_loss: 1.4626 - val_accuracy: 0.6199\n",
      "Epoch 4/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 1.4099 - accuracy: 0.6227\n",
      "Epoch 4: val_accuracy improved from 0.62092 to 0.62136, saving model to models\\lstm.h5\n",
      "214/214 [==============================] - 27s 128ms/step - loss: 1.4099 - accuracy: 0.6227 - val_loss: 1.5184 - val_accuracy: 0.6214\n",
      "Epoch 5/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 1.3919 - accuracy: 0.6269\n",
      "Epoch 5: val_accuracy did not improve from 0.62136\n",
      "214/214 [==============================] - 27s 125ms/step - loss: 1.3919 - accuracy: 0.6269 - val_loss: 1.4604 - val_accuracy: 0.6205\n",
      "Epoch 6/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 1.3747 - accuracy: 0.6282\n",
      "Epoch 6: val_accuracy improved from 0.62136 to 0.62415, saving model to models\\lstm.h5\n",
      "214/214 [==============================] - 24s 111ms/step - loss: 1.3747 - accuracy: 0.6282 - val_loss: 1.4075 - val_accuracy: 0.6242\n",
      "Epoch 7/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 1.3685 - accuracy: 0.6246\n",
      "Epoch 7: val_accuracy did not improve from 0.62415\n",
      "214/214 [==============================] - 26s 120ms/step - loss: 1.3685 - accuracy: 0.6246 - val_loss: 1.4216 - val_accuracy: 0.6202\n",
      "Epoch 8/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 1.3857 - accuracy: 0.6246\n",
      "Epoch 8: val_accuracy did not improve from 0.62415\n",
      "214/214 [==============================] - 25s 119ms/step - loss: 1.3857 - accuracy: 0.6246 - val_loss: 1.4495 - val_accuracy: 0.6056\n",
      "Epoch 9/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 1.3956 - accuracy: 0.6246\n",
      "Epoch 9: val_accuracy did not improve from 0.62415\n",
      "214/214 [==============================] - 26s 121ms/step - loss: 1.3956 - accuracy: 0.6246 - val_loss: 1.4521 - val_accuracy: 0.6228\n",
      "Epoch 10/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 1.4136 - accuracy: 0.6255\n",
      "Epoch 10: val_accuracy did not improve from 0.62415\n",
      "214/214 [==============================] - 26s 122ms/step - loss: 1.4136 - accuracy: 0.6255 - val_loss: 1.4465 - val_accuracy: 0.6228\n",
      "Epoch 11/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 1.4188 - accuracy: 0.6227\n",
      "Epoch 11: val_accuracy did not improve from 0.62415\n",
      "214/214 [==============================] - 25s 119ms/step - loss: 1.4188 - accuracy: 0.6227 - val_loss: 1.4699 - val_accuracy: 0.6209\n",
      "Epoch 1/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.7411 - accuracy: 0.5589\n",
      "Epoch 1: val_accuracy improved from -inf to 0.62092, saving model to models\\lstm.h5\n",
      "107/107 [==============================] - 31s 206ms/step - loss: 1.7411 - accuracy: 0.5589 - val_loss: 1.5052 - val_accuracy: 0.6209\n",
      "Epoch 2/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.4691 - accuracy: 0.6230\n",
      "Epoch 2: val_accuracy improved from 0.62092 to 0.62165, saving model to models\\lstm.h5\n",
      "107/107 [==============================] - 18s 165ms/step - loss: 1.4691 - accuracy: 0.6230 - val_loss: 1.4928 - val_accuracy: 0.6217\n",
      "Epoch 3/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.3579 - accuracy: 0.6328\n",
      "Epoch 3: val_accuracy improved from 0.62165 to 0.62901, saving model to models\\lstm.h5\n",
      "107/107 [==============================] - 18s 164ms/step - loss: 1.3579 - accuracy: 0.6328 - val_loss: 1.3981 - val_accuracy: 0.6290\n",
      "Epoch 4/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.2828 - accuracy: 0.6388\n",
      "Epoch 4: val_accuracy improved from 0.62901 to 0.63269, saving model to models\\lstm.h5\n",
      "107/107 [==============================] - 18s 164ms/step - loss: 1.2828 - accuracy: 0.6388 - val_loss: 1.3239 - val_accuracy: 0.6327\n",
      "Epoch 5/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.2508 - accuracy: 0.6395\n",
      "Epoch 5: val_accuracy improved from 0.63269 to 0.63357, saving model to models\\lstm.h5\n",
      "107/107 [==============================] - 18s 164ms/step - loss: 1.2508 - accuracy: 0.6395 - val_loss: 1.2820 - val_accuracy: 0.6336\n",
      "Epoch 6/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.2017 - accuracy: 0.6459\n",
      "Epoch 6: val_accuracy did not improve from 0.63357\n",
      "107/107 [==============================] - 18s 165ms/step - loss: 1.2017 - accuracy: 0.6459 - val_loss: 1.6303 - val_accuracy: 0.5127\n",
      "Epoch 7/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.1822 - accuracy: 0.6508\n",
      "Epoch 7: val_accuracy improved from 0.63357 to 0.64298, saving model to models\\lstm.h5\n",
      "107/107 [==============================] - 18s 167ms/step - loss: 1.1822 - accuracy: 0.6508 - val_loss: 1.2796 - val_accuracy: 0.6430\n",
      "Epoch 8/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.1579 - accuracy: 0.6574\n",
      "Epoch 8: val_accuracy improved from 0.64298 to 0.64784, saving model to models\\lstm.h5\n",
      "107/107 [==============================] - 18s 167ms/step - loss: 1.1579 - accuracy: 0.6574 - val_loss: 1.2906 - val_accuracy: 0.6478\n",
      "Epoch 9/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.1592 - accuracy: 0.6597\n",
      "Epoch 9: val_accuracy did not improve from 0.64784\n",
      "107/107 [==============================] - 18s 168ms/step - loss: 1.1592 - accuracy: 0.6597 - val_loss: 1.3391 - val_accuracy: 0.6174\n",
      "Epoch 10/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.1504 - accuracy: 0.6628\n",
      "Epoch 10: val_accuracy improved from 0.64784 to 0.65034, saving model to models\\lstm.h5\n",
      "107/107 [==============================] - 18s 169ms/step - loss: 1.1504 - accuracy: 0.6628 - val_loss: 1.1965 - val_accuracy: 0.6503\n",
      "Epoch 11/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.1216 - accuracy: 0.6619\n",
      "Epoch 11: val_accuracy did not improve from 0.65034\n",
      "107/107 [==============================] - 18s 164ms/step - loss: 1.1216 - accuracy: 0.6619 - val_loss: 1.3288 - val_accuracy: 0.6006\n",
      "Epoch 12/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.1215 - accuracy: 0.6634\n",
      "Epoch 12: val_accuracy improved from 0.65034 to 0.65122, saving model to models\\lstm.h5\n",
      "107/107 [==============================] - 18s 170ms/step - loss: 1.1215 - accuracy: 0.6634 - val_loss: 1.2106 - val_accuracy: 0.6512\n",
      "Epoch 13/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.1097 - accuracy: 0.6673\n",
      "Epoch 13: val_accuracy did not improve from 0.65122\n",
      "107/107 [==============================] - 18s 171ms/step - loss: 1.1097 - accuracy: 0.6673 - val_loss: 1.2388 - val_accuracy: 0.6439\n",
      "Epoch 14/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.1096 - accuracy: 0.6682\n",
      "Epoch 14: val_accuracy did not improve from 0.65122\n",
      "107/107 [==============================] - 17s 163ms/step - loss: 1.1096 - accuracy: 0.6682 - val_loss: 1.2397 - val_accuracy: 0.6418\n",
      "Epoch 15/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.0777 - accuracy: 0.6755\n",
      "Epoch 15: val_accuracy did not improve from 0.65122\n",
      "107/107 [==============================] - 17s 163ms/step - loss: 1.0777 - accuracy: 0.6755 - val_loss: 1.2780 - val_accuracy: 0.6409\n",
      "Epoch 16/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.0650 - accuracy: 0.6811\n",
      "Epoch 16: val_accuracy improved from 0.65122 to 0.66417, saving model to models\\lstm.h5\n",
      "107/107 [==============================] - 18s 165ms/step - loss: 1.0650 - accuracy: 0.6811 - val_loss: 1.2378 - val_accuracy: 0.6642\n",
      "Epoch 17/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.0621 - accuracy: 0.6813\n",
      "Epoch 17: val_accuracy did not improve from 0.66417\n",
      "107/107 [==============================] - 17s 161ms/step - loss: 1.0621 - accuracy: 0.6813 - val_loss: 1.1621 - val_accuracy: 0.6603\n",
      "Epoch 18/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.0634 - accuracy: 0.6802\n",
      "Epoch 18: val_accuracy did not improve from 0.66417\n",
      "107/107 [==============================] - 17s 163ms/step - loss: 1.0634 - accuracy: 0.6802 - val_loss: 1.1579 - val_accuracy: 0.6517\n",
      "Epoch 19/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.0289 - accuracy: 0.6890\n",
      "Epoch 19: val_accuracy did not improve from 0.66417\n",
      "107/107 [==============================] - 18s 172ms/step - loss: 1.0289 - accuracy: 0.6890 - val_loss: 1.1530 - val_accuracy: 0.6514\n",
      "Epoch 20/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.0317 - accuracy: 0.6822\n",
      "Epoch 20: val_accuracy did not improve from 0.66417\n",
      "107/107 [==============================] - 18s 169ms/step - loss: 1.0317 - accuracy: 0.6822 - val_loss: 1.2318 - val_accuracy: 0.6508\n",
      "Epoch 1/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.8128 - accuracy: 0.5131\n",
      "Epoch 1: val_accuracy improved from -inf to 0.62092, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 32s 440ms/step - loss: 1.8128 - accuracy: 0.5131 - val_loss: 1.4913 - val_accuracy: 0.6209\n",
      "Epoch 2/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.4388 - accuracy: 0.6217\n",
      "Epoch 2: val_accuracy did not improve from 0.62092\n",
      "54/54 [==============================] - 22s 403ms/step - loss: 1.4388 - accuracy: 0.6217 - val_loss: 1.5141 - val_accuracy: 0.6209\n",
      "Epoch 3/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.3245 - accuracy: 0.6379\n",
      "Epoch 3: val_accuracy improved from 0.62092 to 0.62504, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 22s 407ms/step - loss: 1.3245 - accuracy: 0.6379 - val_loss: 1.4021 - val_accuracy: 0.6250\n",
      "Epoch 4/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.1894 - accuracy: 0.6594\n",
      "Epoch 4: val_accuracy improved from 0.62504 to 0.63533, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 22s 417ms/step - loss: 1.1894 - accuracy: 0.6594 - val_loss: 1.2499 - val_accuracy: 0.6353\n",
      "Epoch 5/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.1094 - accuracy: 0.6729\n",
      "Epoch 5: val_accuracy improved from 0.63533 to 0.64048, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 20s 369ms/step - loss: 1.1094 - accuracy: 0.6729 - val_loss: 1.2860 - val_accuracy: 0.6405\n",
      "Epoch 6/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.0417 - accuracy: 0.6819\n",
      "Epoch 6: val_accuracy improved from 0.64048 to 0.66358, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 20s 365ms/step - loss: 1.0417 - accuracy: 0.6819 - val_loss: 1.1541 - val_accuracy: 0.6636\n",
      "Epoch 7/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.9998 - accuracy: 0.6929\n",
      "Epoch 7: val_accuracy did not improve from 0.66358\n",
      "54/54 [==============================] - 21s 396ms/step - loss: 0.9998 - accuracy: 0.6929 - val_loss: 1.2197 - val_accuracy: 0.6443\n",
      "Epoch 8/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.9707 - accuracy: 0.7034\n",
      "Epoch 8: val_accuracy did not improve from 0.66358\n",
      "54/54 [==============================] - 21s 391ms/step - loss: 0.9707 - accuracy: 0.7034 - val_loss: 1.3639 - val_accuracy: 0.5747\n",
      "Epoch 9/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.9107 - accuracy: 0.7178\n",
      "Epoch 9: val_accuracy did not improve from 0.66358\n",
      "54/54 [==============================] - 22s 410ms/step - loss: 0.9107 - accuracy: 0.7178 - val_loss: 1.1238 - val_accuracy: 0.6580\n",
      "Epoch 10/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.8726 - accuracy: 0.7317\n",
      "Epoch 10: val_accuracy improved from 0.66358 to 0.66726, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 21s 400ms/step - loss: 0.8726 - accuracy: 0.7317 - val_loss: 1.2307 - val_accuracy: 0.6673\n",
      "Epoch 11/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.8419 - accuracy: 0.7390\n",
      "Epoch 11: val_accuracy did not improve from 0.66726\n",
      "54/54 [==============================] - 22s 404ms/step - loss: 0.8419 - accuracy: 0.7390 - val_loss: 1.3634 - val_accuracy: 0.6284\n",
      "Epoch 12/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.8400 - accuracy: 0.7421\n",
      "Epoch 12: val_accuracy improved from 0.66726 to 0.67623, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 21s 399ms/step - loss: 0.8400 - accuracy: 0.7421 - val_loss: 1.2524 - val_accuracy: 0.6762\n",
      "Epoch 13/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.8114 - accuracy: 0.7492\n",
      "Epoch 13: val_accuracy did not improve from 0.67623\n",
      "54/54 [==============================] - 23s 423ms/step - loss: 0.8114 - accuracy: 0.7492 - val_loss: 1.2269 - val_accuracy: 0.6733\n",
      "Epoch 14/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.7921 - accuracy: 0.7561\n",
      "Epoch 14: val_accuracy improved from 0.67623 to 0.68623, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 19s 358ms/step - loss: 0.7921 - accuracy: 0.7561 - val_loss: 1.1541 - val_accuracy: 0.6862\n",
      "Epoch 15/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.7910 - accuracy: 0.7489\n",
      "Epoch 15: val_accuracy did not improve from 0.68623\n",
      "54/54 [==============================] - 16s 302ms/step - loss: 0.7910 - accuracy: 0.7489 - val_loss: 1.1600 - val_accuracy: 0.6455\n",
      "Epoch 16/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.7731 - accuracy: 0.7637\n",
      "Epoch 16: val_accuracy did not improve from 0.68623\n",
      "54/54 [==============================] - 16s 300ms/step - loss: 0.7731 - accuracy: 0.7637 - val_loss: 1.1501 - val_accuracy: 0.6726\n",
      "Epoch 17/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.7641 - accuracy: 0.7655\n",
      "Epoch 17: val_accuracy did not improve from 0.68623\n",
      "54/54 [==============================] - 16s 305ms/step - loss: 0.7641 - accuracy: 0.7655 - val_loss: 1.1507 - val_accuracy: 0.6805\n",
      "Epoch 18/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.7466 - accuracy: 0.7718\n",
      "Epoch 18: val_accuracy did not improve from 0.68623\n",
      "54/54 [==============================] - 16s 306ms/step - loss: 0.7466 - accuracy: 0.7718 - val_loss: 1.2146 - val_accuracy: 0.6855\n",
      "Epoch 19/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.7374 - accuracy: 0.7699\n",
      "Epoch 19: val_accuracy did not improve from 0.68623\n",
      "54/54 [==============================] - 16s 305ms/step - loss: 0.7374 - accuracy: 0.7699 - val_loss: 1.1594 - val_accuracy: 0.6728\n",
      "Epoch 1/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 1.6643 - accuracy: 0.6101\n",
      "Epoch 1: val_accuracy improved from -inf to 0.62092, saving model to models\\lstm.h5\n",
      "214/214 [==============================] - 37s 133ms/step - loss: 1.6643 - accuracy: 0.6101 - val_loss: 1.6079 - val_accuracy: 0.6209\n",
      "Epoch 2/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 1.5704 - accuracy: 0.6241\n",
      "Epoch 2: val_accuracy did not improve from 0.62092\n",
      "214/214 [==============================] - 24s 111ms/step - loss: 1.5704 - accuracy: 0.6241 - val_loss: 1.6902 - val_accuracy: 0.6209\n",
      "Epoch 3/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 1.5863 - accuracy: 0.6234\n",
      "Epoch 3: val_accuracy did not improve from 0.62092\n",
      "214/214 [==============================] - 25s 118ms/step - loss: 1.5863 - accuracy: 0.6234 - val_loss: 2.0175 - val_accuracy: 0.6209\n",
      "Epoch 4/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 1.6021 - accuracy: 0.6233\n",
      "Epoch 4: val_accuracy did not improve from 0.62092\n",
      "214/214 [==============================] - 28s 129ms/step - loss: 1.6021 - accuracy: 0.6233 - val_loss: 4.5641 - val_accuracy: 0.0388\n",
      "Epoch 5/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 1.5981 - accuracy: 0.6243\n",
      "Epoch 5: val_accuracy did not improve from 0.62092\n",
      "214/214 [==============================] - 27s 128ms/step - loss: 1.5981 - accuracy: 0.6243 - val_loss: 1.7779 - val_accuracy: 0.6209\n",
      "Epoch 6/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 1.5898 - accuracy: 0.6244\n",
      "Epoch 6: val_accuracy did not improve from 0.62092\n",
      "214/214 [==============================] - 28s 129ms/step - loss: 1.5898 - accuracy: 0.6244 - val_loss: 1.5781 - val_accuracy: 0.6209\n",
      "Epoch 1/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.6879 - accuracy: 0.6028\n",
      "Epoch 1: val_accuracy improved from -inf to 0.62092, saving model to models\\lstm.h5\n",
      "107/107 [==============================] - 38s 232ms/step - loss: 1.6879 - accuracy: 0.6028 - val_loss: 1.5682 - val_accuracy: 0.6209\n",
      "Epoch 2/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.5646 - accuracy: 0.6231\n",
      "Epoch 2: val_accuracy did not improve from 0.62092\n",
      "107/107 [==============================] - 18s 172ms/step - loss: 1.5646 - accuracy: 0.6231 - val_loss: 1.6162 - val_accuracy: 0.6209\n",
      "Epoch 3/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.5637 - accuracy: 0.6240\n",
      "Epoch 3: val_accuracy did not improve from 0.62092\n",
      "107/107 [==============================] - 17s 164ms/step - loss: 1.5637 - accuracy: 0.6240 - val_loss: 1.6076 - val_accuracy: 0.6209\n",
      "Epoch 4/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.5572 - accuracy: 0.6243\n",
      "Epoch 4: val_accuracy did not improve from 0.62092\n",
      "107/107 [==============================] - 17s 158ms/step - loss: 1.5572 - accuracy: 0.6243 - val_loss: 1.5774 - val_accuracy: 0.6209\n",
      "Epoch 5/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.5498 - accuracy: 0.6240\n",
      "Epoch 5: val_accuracy did not improve from 0.62092\n",
      "107/107 [==============================] - 18s 168ms/step - loss: 1.5498 - accuracy: 0.6240 - val_loss: 1.5496 - val_accuracy: 0.6209\n",
      "Epoch 6/20\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.5560 - accuracy: 0.6243\n",
      "Epoch 6: val_accuracy did not improve from 0.62092\n",
      "107/107 [==============================] - 17s 161ms/step - loss: 1.5560 - accuracy: 0.6243 - val_loss: 7.4111 - val_accuracy: 0.0397\n",
      "Epoch 1/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.7479 - accuracy: 0.5876\n",
      "Epoch 1: val_accuracy improved from -inf to 0.62092, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 25s 308ms/step - loss: 1.7479 - accuracy: 0.5876 - val_loss: 1.5509 - val_accuracy: 0.6209\n",
      "Epoch 2/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.5546 - accuracy: 0.6241\n",
      "Epoch 2: val_accuracy did not improve from 0.62092\n",
      "54/54 [==============================] - 14s 265ms/step - loss: 1.5546 - accuracy: 0.6241 - val_loss: 1.5784 - val_accuracy: 0.6209\n",
      "Epoch 3/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.5513 - accuracy: 0.6243\n",
      "Epoch 3: val_accuracy did not improve from 0.62092\n",
      "54/54 [==============================] - 14s 266ms/step - loss: 1.5513 - accuracy: 0.6243 - val_loss: 1.5529 - val_accuracy: 0.6209\n",
      "Epoch 4/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.5463 - accuracy: 0.6243\n",
      "Epoch 4: val_accuracy did not improve from 0.62092\n",
      "54/54 [==============================] - 15s 276ms/step - loss: 1.5463 - accuracy: 0.6243 - val_loss: 1.5498 - val_accuracy: 0.6209\n",
      "Epoch 5/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.5435 - accuracy: 0.6244\n",
      "Epoch 5: val_accuracy did not improve from 0.62092\n",
      "54/54 [==============================] - 15s 277ms/step - loss: 1.5435 - accuracy: 0.6244 - val_loss: 1.5689 - val_accuracy: 0.6209\n",
      "Epoch 6/20\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.5441 - accuracy: 0.6243\n",
      "Epoch 6: val_accuracy did not improve from 0.62092\n",
      "54/54 [==============================] - 15s 285ms/step - loss: 1.5441 - accuracy: 0.6243 - val_loss: 1.5640 - val_accuracy: 0.6209\n",
      "Epoch 1/30\n",
      "214/214 [==============================] - ETA: 0s - loss: 2.0952 - accuracy: 0.3846\n",
      "Epoch 1: val_accuracy improved from -inf to 0.62563, saving model to models\\lstm.h5\n",
      "214/214 [==============================] - 27s 85ms/step - loss: 2.0952 - accuracy: 0.3846 - val_loss: 1.4540 - val_accuracy: 0.6256\n",
      "Epoch 2/30\n",
      "213/214 [============================>.] - ETA: 0s - loss: 1.4603 - accuracy: 0.6159\n",
      "Epoch 2: val_accuracy improved from 0.62563 to 0.62695, saving model to models\\lstm.h5\n",
      "214/214 [==============================] - 18s 82ms/step - loss: 1.4593 - accuracy: 0.6159 - val_loss: 1.3548 - val_accuracy: 0.6269\n",
      "Epoch 3/30\n",
      "213/214 [============================>.] - ETA: 0s - loss: 1.2570 - accuracy: 0.6466\n",
      "Epoch 3: val_accuracy did not improve from 0.62695\n",
      "214/214 [==============================] - 17s 79ms/step - loss: 1.2576 - accuracy: 0.6464 - val_loss: 1.2872 - val_accuracy: 0.6262\n",
      "Epoch 4/30\n",
      "214/214 [==============================] - ETA: 0s - loss: 1.0986 - accuracy: 0.6752\n",
      "Epoch 4: val_accuracy did not improve from 0.62695\n",
      "214/214 [==============================] - 18s 83ms/step - loss: 1.0986 - accuracy: 0.6752 - val_loss: 1.2410 - val_accuracy: 0.6252\n",
      "Epoch 5/30\n",
      "213/214 [============================>.] - ETA: 0s - loss: 0.9523 - accuracy: 0.7095\n",
      "Epoch 5: val_accuracy improved from 0.62695 to 0.66328, saving model to models\\lstm.h5\n",
      "214/214 [==============================] - 17s 80ms/step - loss: 0.9531 - accuracy: 0.7093 - val_loss: 1.1631 - val_accuracy: 0.6633\n",
      "Epoch 6/30\n",
      "213/214 [============================>.] - ETA: 0s - loss: 0.8328 - accuracy: 0.7421\n",
      "Epoch 6: val_accuracy did not improve from 0.66328\n",
      "214/214 [==============================] - 17s 79ms/step - loss: 0.8321 - accuracy: 0.7421 - val_loss: 1.1051 - val_accuracy: 0.6630\n",
      "Epoch 7/30\n",
      "213/214 [============================>.] - ETA: 0s - loss: 0.7310 - accuracy: 0.7722\n",
      "Epoch 7: val_accuracy improved from 0.66328 to 0.69638, saving model to models\\lstm.h5\n",
      "214/214 [==============================] - 17s 80ms/step - loss: 0.7326 - accuracy: 0.7718 - val_loss: 1.0939 - val_accuracy: 0.6964\n",
      "Epoch 8/30\n",
      "214/214 [==============================] - ETA: 0s - loss: 0.6583 - accuracy: 0.7912\n",
      "Epoch 8: val_accuracy did not improve from 0.69638\n",
      "214/214 [==============================] - 17s 81ms/step - loss: 0.6583 - accuracy: 0.7912 - val_loss: 1.0942 - val_accuracy: 0.6849\n",
      "Epoch 9/30\n",
      "213/214 [============================>.] - ETA: 0s - loss: 0.5890 - accuracy: 0.8135\n",
      "Epoch 9: val_accuracy did not improve from 0.69638\n",
      "214/214 [==============================] - 17s 80ms/step - loss: 0.5890 - accuracy: 0.8135 - val_loss: 1.1103 - val_accuracy: 0.6790\n",
      "Epoch 10/30\n",
      "213/214 [============================>.] - ETA: 0s - loss: 0.5295 - accuracy: 0.8358\n",
      "Epoch 10: val_accuracy improved from 0.69638 to 0.70035, saving model to models\\lstm.h5\n",
      "214/214 [==============================] - 17s 81ms/step - loss: 0.5291 - accuracy: 0.8361 - val_loss: 1.1568 - val_accuracy: 0.7004\n",
      "Epoch 11/30\n",
      "213/214 [============================>.] - ETA: 0s - loss: 0.4586 - accuracy: 0.8539\n",
      "Epoch 11: val_accuracy improved from 0.70035 to 0.71094, saving model to models\\lstm.h5\n",
      "214/214 [==============================] - 17s 81ms/step - loss: 0.4595 - accuracy: 0.8537 - val_loss: 1.1020 - val_accuracy: 0.7109\n",
      "Epoch 12/30\n",
      "213/214 [============================>.] - ETA: 0s - loss: 0.4183 - accuracy: 0.8652\n",
      "Epoch 12: val_accuracy did not improve from 0.71094\n",
      "214/214 [==============================] - 17s 79ms/step - loss: 0.4192 - accuracy: 0.8647 - val_loss: 1.1606 - val_accuracy: 0.6834\n",
      "Epoch 13/30\n",
      "214/214 [==============================] - ETA: 0s - loss: 0.3872 - accuracy: 0.8759\n",
      "Epoch 13: val_accuracy did not improve from 0.71094\n",
      "214/214 [==============================] - 18s 82ms/step - loss: 0.3872 - accuracy: 0.8759 - val_loss: 1.1672 - val_accuracy: 0.7021\n",
      "Epoch 14/30\n",
      "213/214 [============================>.] - ETA: 0s - loss: 0.3649 - accuracy: 0.8839\n",
      "Epoch 14: val_accuracy did not improve from 0.71094\n",
      "214/214 [==============================] - 17s 79ms/step - loss: 0.3647 - accuracy: 0.8838 - val_loss: 1.2081 - val_accuracy: 0.6893\n",
      "Epoch 15/30\n",
      "213/214 [============================>.] - ETA: 0s - loss: 0.3361 - accuracy: 0.8947\n",
      "Epoch 15: val_accuracy improved from 0.71094 to 0.71550, saving model to models\\lstm.h5\n",
      "214/214 [==============================] - 18s 83ms/step - loss: 0.3360 - accuracy: 0.8947 - val_loss: 1.2911 - val_accuracy: 0.7155\n",
      "Epoch 16/30\n",
      "213/214 [============================>.] - ETA: 0s - loss: 0.2993 - accuracy: 0.9049\n",
      "Epoch 16: val_accuracy did not improve from 0.71550\n",
      "214/214 [==============================] - 17s 80ms/step - loss: 0.2989 - accuracy: 0.9050 - val_loss: 1.2358 - val_accuracy: 0.7043\n",
      "Epoch 17/30\n",
      "214/214 [==============================] - ETA: 0s - loss: 0.2731 - accuracy: 0.9134\n",
      "Epoch 17: val_accuracy did not improve from 0.71550\n",
      "214/214 [==============================] - 20s 94ms/step - loss: 0.2731 - accuracy: 0.9134 - val_loss: 1.2615 - val_accuracy: 0.7062\n",
      "Epoch 18/30\n",
      "214/214 [==============================] - ETA: 0s - loss: 0.2651 - accuracy: 0.9157\n",
      "Epoch 18: val_accuracy did not improve from 0.71550\n",
      "214/214 [==============================] - 20s 92ms/step - loss: 0.2651 - accuracy: 0.9157 - val_loss: 1.3513 - val_accuracy: 0.6849\n",
      "Epoch 19/30\n",
      "214/214 [==============================] - ETA: 0s - loss: 0.2496 - accuracy: 0.9195\n",
      "Epoch 19: val_accuracy improved from 0.71550 to 0.72271, saving model to models\\lstm.h5\n",
      "214/214 [==============================] - 20s 93ms/step - loss: 0.2496 - accuracy: 0.9195 - val_loss: 1.3435 - val_accuracy: 0.7227\n",
      "Epoch 20/30\n",
      "214/214 [==============================] - ETA: 0s - loss: 0.2435 - accuracy: 0.9238\n",
      "Epoch 20: val_accuracy did not improve from 0.72271\n",
      "214/214 [==============================] - 20s 93ms/step - loss: 0.2435 - accuracy: 0.9238 - val_loss: 1.2585 - val_accuracy: 0.7173\n",
      "Epoch 21/30\n",
      "214/214 [==============================] - ETA: 0s - loss: 0.2238 - accuracy: 0.9283\n",
      "Epoch 21: val_accuracy did not improve from 0.72271\n",
      "214/214 [==============================] - 20s 93ms/step - loss: 0.2238 - accuracy: 0.9283 - val_loss: 1.2994 - val_accuracy: 0.7152\n",
      "Epoch 22/30\n",
      "213/214 [============================>.] - ETA: 0s - loss: 0.1886 - accuracy: 0.9401\n",
      "Epoch 22: val_accuracy did not improve from 0.72271\n",
      "214/214 [==============================] - 18s 83ms/step - loss: 0.1886 - accuracy: 0.9402 - val_loss: 1.3077 - val_accuracy: 0.7064\n",
      "Epoch 23/30\n",
      "214/214 [==============================] - ETA: 0s - loss: 0.1860 - accuracy: 0.9393\n",
      "Epoch 23: val_accuracy improved from 0.72271 to 0.72830, saving model to models\\lstm.h5\n",
      "214/214 [==============================] - 18s 83ms/step - loss: 0.1860 - accuracy: 0.9393 - val_loss: 1.4121 - val_accuracy: 0.7283\n",
      "Epoch 24/30\n",
      "214/214 [==============================] - ETA: 0s - loss: 0.2007 - accuracy: 0.9365\n",
      "Epoch 24: val_accuracy did not improve from 0.72830\n",
      "214/214 [==============================] - 19s 87ms/step - loss: 0.2007 - accuracy: 0.9365 - val_loss: 1.4177 - val_accuracy: 0.6974\n",
      "Epoch 25/30\n",
      "214/214 [==============================] - ETA: 0s - loss: 0.1768 - accuracy: 0.9424\n",
      "Epoch 25: val_accuracy did not improve from 0.72830\n",
      "214/214 [==============================] - 20s 92ms/step - loss: 0.1768 - accuracy: 0.9424 - val_loss: 1.4762 - val_accuracy: 0.7134\n",
      "Epoch 26/30\n",
      "214/214 [==============================] - ETA: 0s - loss: 0.1688 - accuracy: 0.9459\n",
      "Epoch 26: val_accuracy did not improve from 0.72830\n",
      "214/214 [==============================] - 20s 92ms/step - loss: 0.1688 - accuracy: 0.9459 - val_loss: 1.3989 - val_accuracy: 0.7142\n",
      "Epoch 27/30\n",
      "214/214 [==============================] - ETA: 0s - loss: 0.1657 - accuracy: 0.9472\n",
      "Epoch 27: val_accuracy did not improve from 0.72830\n",
      "214/214 [==============================] - 20s 93ms/step - loss: 0.1657 - accuracy: 0.9472 - val_loss: 1.3862 - val_accuracy: 0.7167\n",
      "Epoch 28/30\n",
      "214/214 [==============================] - ETA: 0s - loss: 0.1899 - accuracy: 0.9399\n",
      "Epoch 28: val_accuracy did not improve from 0.72830\n",
      "214/214 [==============================] - 20s 93ms/step - loss: 0.1899 - accuracy: 0.9399 - val_loss: 1.4090 - val_accuracy: 0.7108\n",
      "Epoch 1/30\n",
      "107/107 [==============================] - ETA: 0s - loss: 2.2589 - accuracy: 0.3573\n",
      "Epoch 1: val_accuracy improved from -inf to 0.61930, saving model to models\\lstm.h5\n",
      "107/107 [==============================] - 29s 169ms/step - loss: 2.2589 - accuracy: 0.3573 - val_loss: 1.7249 - val_accuracy: 0.6193\n",
      "Epoch 2/30\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.5659 - accuracy: 0.6165\n",
      "Epoch 2: val_accuracy improved from 0.61930 to 0.63578, saving model to models\\lstm.h5\n",
      "107/107 [==============================] - 14s 134ms/step - loss: 1.5659 - accuracy: 0.6165 - val_loss: 1.4368 - val_accuracy: 0.6358\n",
      "Epoch 3/30\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.3322 - accuracy: 0.6530\n",
      "Epoch 3: val_accuracy improved from 0.63578 to 0.64563, saving model to models\\lstm.h5\n",
      "107/107 [==============================] - 14s 135ms/step - loss: 1.3322 - accuracy: 0.6530 - val_loss: 1.3181 - val_accuracy: 0.6456\n",
      "Epoch 4/30\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.1791 - accuracy: 0.6692\n",
      "Epoch 4: val_accuracy improved from 0.64563 to 0.65284, saving model to models\\lstm.h5\n",
      "107/107 [==============================] - 14s 131ms/step - loss: 1.1791 - accuracy: 0.6692 - val_loss: 1.2420 - val_accuracy: 0.6528\n",
      "Epoch 5/30\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.0315 - accuracy: 0.7002\n",
      "Epoch 5: val_accuracy improved from 0.65284 to 0.67387, saving model to models\\lstm.h5\n",
      "107/107 [==============================] - 15s 139ms/step - loss: 1.0315 - accuracy: 0.7002 - val_loss: 1.1621 - val_accuracy: 0.6739\n",
      "Epoch 6/30\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.8973 - accuracy: 0.7323\n",
      "Epoch 6: val_accuracy did not improve from 0.67387\n",
      "107/107 [==============================] - 15s 143ms/step - loss: 0.8973 - accuracy: 0.7323 - val_loss: 1.1762 - val_accuracy: 0.6689\n",
      "Epoch 7/30\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.7997 - accuracy: 0.7608\n",
      "Epoch 7: val_accuracy improved from 0.67387 to 0.68594, saving model to models\\lstm.h5\n",
      "107/107 [==============================] - 15s 139ms/step - loss: 0.7997 - accuracy: 0.7608 - val_loss: 1.2193 - val_accuracy: 0.6859\n",
      "Epoch 8/30\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.6951 - accuracy: 0.7925\n",
      "Epoch 8: val_accuracy did not improve from 0.68594\n",
      "107/107 [==============================] - 14s 134ms/step - loss: 0.6951 - accuracy: 0.7925 - val_loss: 1.2226 - val_accuracy: 0.6848\n",
      "Epoch 9/30\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.6749 - accuracy: 0.7906\n",
      "Epoch 9: val_accuracy improved from 0.68594 to 0.69462, saving model to models\\lstm.h5\n",
      "107/107 [==============================] - 15s 137ms/step - loss: 0.6749 - accuracy: 0.7906 - val_loss: 1.1449 - val_accuracy: 0.6946\n",
      "Epoch 10/30\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.5643 - accuracy: 0.8263\n",
      "Epoch 10: val_accuracy did not improve from 0.69462\n",
      "107/107 [==============================] - 15s 137ms/step - loss: 0.5643 - accuracy: 0.8263 - val_loss: 1.2578 - val_accuracy: 0.6892\n",
      "Epoch 11/30\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.4818 - accuracy: 0.8492\n",
      "Epoch 11: val_accuracy improved from 0.69462 to 0.70153, saving model to models\\lstm.h5\n",
      "107/107 [==============================] - 15s 142ms/step - loss: 0.4818 - accuracy: 0.8492 - val_loss: 1.2102 - val_accuracy: 0.7015\n",
      "Epoch 12/30\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.4582 - accuracy: 0.8593\n",
      "Epoch 12: val_accuracy improved from 0.70153 to 0.70359, saving model to models\\lstm.h5\n",
      "107/107 [==============================] - 15s 141ms/step - loss: 0.4582 - accuracy: 0.8593 - val_loss: 1.2037 - val_accuracy: 0.7036\n",
      "Epoch 13/30\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.4147 - accuracy: 0.8727\n",
      "Epoch 13: val_accuracy did not improve from 0.70359\n",
      "107/107 [==============================] - 15s 140ms/step - loss: 0.4147 - accuracy: 0.8727 - val_loss: 1.3369 - val_accuracy: 0.7027\n",
      "Epoch 14/30\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.3953 - accuracy: 0.8718\n",
      "Epoch 14: val_accuracy did not improve from 0.70359\n",
      "107/107 [==============================] - 15s 139ms/step - loss: 0.3953 - accuracy: 0.8718 - val_loss: 1.3153 - val_accuracy: 0.6834\n",
      "Epoch 15/30\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.3330 - accuracy: 0.8961\n",
      "Epoch 15: val_accuracy did not improve from 0.70359\n",
      "107/107 [==============================] - 15s 142ms/step - loss: 0.3330 - accuracy: 0.8961 - val_loss: 1.2848 - val_accuracy: 0.7006\n",
      "Epoch 16/30\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.3034 - accuracy: 0.9020\n",
      "Epoch 16: val_accuracy did not improve from 0.70359\n",
      "107/107 [==============================] - 15s 141ms/step - loss: 0.3034 - accuracy: 0.9020 - val_loss: 1.3225 - val_accuracy: 0.7002\n",
      "Epoch 17/30\n",
      "107/107 [==============================] - ETA: 0s - loss: 0.2755 - accuracy: 0.9127\n",
      "Epoch 17: val_accuracy did not improve from 0.70359\n",
      "107/107 [==============================] - 15s 136ms/step - loss: 0.2755 - accuracy: 0.9127 - val_loss: 1.4095 - val_accuracy: 0.6851\n",
      "Epoch 1/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 2.5396 - accuracy: 0.2173\n",
      "Epoch 1: val_accuracy improved from -inf to 0.62107, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 24s 306ms/step - loss: 2.5396 - accuracy: 0.2173 - val_loss: 2.0121 - val_accuracy: 0.6211\n",
      "Epoch 2/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.8721 - accuracy: 0.4948\n",
      "Epoch 2: val_accuracy improved from 0.62107 to 0.62474, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 16s 295ms/step - loss: 1.8721 - accuracy: 0.4948 - val_loss: 1.5476 - val_accuracy: 0.6247\n",
      "Epoch 3/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.4454 - accuracy: 0.6334\n",
      "Epoch 3: val_accuracy improved from 0.62474 to 0.63357, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 15s 281ms/step - loss: 1.4454 - accuracy: 0.6334 - val_loss: 1.4191 - val_accuracy: 0.6336\n",
      "Epoch 4/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.2466 - accuracy: 0.6657\n",
      "Epoch 4: val_accuracy improved from 0.63357 to 0.64122, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 14s 267ms/step - loss: 1.2466 - accuracy: 0.6657 - val_loss: 1.3256 - val_accuracy: 0.6412\n",
      "Epoch 5/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.1063 - accuracy: 0.6928\n",
      "Epoch 5: val_accuracy improved from 0.64122 to 0.65490, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 14s 269ms/step - loss: 1.1063 - accuracy: 0.6928 - val_loss: 1.2342 - val_accuracy: 0.6549\n",
      "Epoch 6/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.9768 - accuracy: 0.7195\n",
      "Epoch 6: val_accuracy improved from 0.65490 to 0.67049, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 15s 272ms/step - loss: 0.9768 - accuracy: 0.7195 - val_loss: 1.2060 - val_accuracy: 0.6705\n",
      "Epoch 7/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.8600 - accuracy: 0.7485\n",
      "Epoch 7: val_accuracy improved from 0.67049 to 0.67976, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 15s 277ms/step - loss: 0.8600 - accuracy: 0.7485 - val_loss: 1.1961 - val_accuracy: 0.6798\n",
      "Epoch 8/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.7720 - accuracy: 0.7716\n",
      "Epoch 8: val_accuracy improved from 0.67976 to 0.68947, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 14s 268ms/step - loss: 0.7720 - accuracy: 0.7716 - val_loss: 1.1940 - val_accuracy: 0.6895\n",
      "Epoch 9/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.6732 - accuracy: 0.8001\n",
      "Epoch 9: val_accuracy did not improve from 0.68947\n",
      "54/54 [==============================] - 14s 265ms/step - loss: 0.6732 - accuracy: 0.8001 - val_loss: 1.2566 - val_accuracy: 0.6893\n",
      "Epoch 10/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.5983 - accuracy: 0.8192\n",
      "Epoch 10: val_accuracy did not improve from 0.68947\n",
      "54/54 [==============================] - 15s 271ms/step - loss: 0.5983 - accuracy: 0.8192 - val_loss: 1.3120 - val_accuracy: 0.6858\n",
      "Epoch 11/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.5528 - accuracy: 0.8326\n",
      "Epoch 11: val_accuracy did not improve from 0.68947\n",
      "54/54 [==============================] - 14s 269ms/step - loss: 0.5528 - accuracy: 0.8326 - val_loss: 1.3278 - val_accuracy: 0.6865\n",
      "Epoch 12/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.4848 - accuracy: 0.8553\n",
      "Epoch 12: val_accuracy improved from 0.68947 to 0.69594, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 15s 276ms/step - loss: 0.4848 - accuracy: 0.8553 - val_loss: 1.3966 - val_accuracy: 0.6959\n",
      "Epoch 13/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.4415 - accuracy: 0.8622\n",
      "Epoch 13: val_accuracy improved from 0.69594 to 0.70124, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 15s 275ms/step - loss: 0.4415 - accuracy: 0.8622 - val_loss: 1.3274 - val_accuracy: 0.7012\n",
      "Epoch 14/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.3995 - accuracy: 0.8765\n",
      "Epoch 14: val_accuracy did not improve from 0.70124\n",
      "54/54 [==============================] - 15s 282ms/step - loss: 0.3995 - accuracy: 0.8765 - val_loss: 1.4467 - val_accuracy: 0.6917\n",
      "Epoch 15/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.3432 - accuracy: 0.8985\n",
      "Epoch 15: val_accuracy did not improve from 0.70124\n",
      "54/54 [==============================] - 15s 273ms/step - loss: 0.3432 - accuracy: 0.8985 - val_loss: 1.5182 - val_accuracy: 0.6740\n",
      "Epoch 16/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.3083 - accuracy: 0.9012\n",
      "Epoch 16: val_accuracy did not improve from 0.70124\n",
      "54/54 [==============================] - 15s 272ms/step - loss: 0.3083 - accuracy: 0.9012 - val_loss: 1.5600 - val_accuracy: 0.6902\n",
      "Epoch 17/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.2952 - accuracy: 0.9059\n",
      "Epoch 17: val_accuracy did not improve from 0.70124\n",
      "54/54 [==============================] - 15s 273ms/step - loss: 0.2952 - accuracy: 0.9059 - val_loss: 1.5311 - val_accuracy: 0.6914\n",
      "Epoch 18/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.2650 - accuracy: 0.9178\n",
      "Epoch 18: val_accuracy improved from 0.70124 to 0.70344, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 16s 290ms/step - loss: 0.2650 - accuracy: 0.9178 - val_loss: 1.4931 - val_accuracy: 0.7034\n",
      "Epoch 19/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.2446 - accuracy: 0.9222\n",
      "Epoch 19: val_accuracy did not improve from 0.70344\n",
      "54/54 [==============================] - 16s 299ms/step - loss: 0.2446 - accuracy: 0.9222 - val_loss: 1.5158 - val_accuracy: 0.7023\n",
      "Epoch 20/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.2320 - accuracy: 0.9287\n",
      "Epoch 20: val_accuracy improved from 0.70344 to 0.71006, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 15s 272ms/step - loss: 0.2320 - accuracy: 0.9287 - val_loss: 1.4343 - val_accuracy: 0.7101\n",
      "Epoch 21/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.2108 - accuracy: 0.9331\n",
      "Epoch 21: val_accuracy improved from 0.71006 to 0.71168, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 15s 270ms/step - loss: 0.2108 - accuracy: 0.9331 - val_loss: 1.5368 - val_accuracy: 0.7117\n",
      "Epoch 22/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.1904 - accuracy: 0.9405\n",
      "Epoch 22: val_accuracy improved from 0.71168 to 0.71212, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 17s 312ms/step - loss: 0.1904 - accuracy: 0.9405 - val_loss: 1.5888 - val_accuracy: 0.7121\n",
      "Epoch 23/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.1861 - accuracy: 0.9415\n",
      "Epoch 23: val_accuracy did not improve from 0.71212\n",
      "54/54 [==============================] - 19s 355ms/step - loss: 0.1861 - accuracy: 0.9415 - val_loss: 1.4709 - val_accuracy: 0.7081\n",
      "Epoch 24/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.1755 - accuracy: 0.9460\n",
      "Epoch 24: val_accuracy improved from 0.71212 to 0.71477, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 19s 361ms/step - loss: 0.1755 - accuracy: 0.9460 - val_loss: 1.5457 - val_accuracy: 0.7148\n",
      "Epoch 25/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.1612 - accuracy: 0.9511\n",
      "Epoch 25: val_accuracy did not improve from 0.71477\n",
      "54/54 [==============================] - 18s 341ms/step - loss: 0.1612 - accuracy: 0.9511 - val_loss: 1.5970 - val_accuracy: 0.7031\n",
      "Epoch 26/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.1430 - accuracy: 0.9525\n",
      "Epoch 26: val_accuracy did not improve from 0.71477\n",
      "54/54 [==============================] - 18s 337ms/step - loss: 0.1430 - accuracy: 0.9525 - val_loss: 1.5671 - val_accuracy: 0.7067\n",
      "Epoch 27/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.1472 - accuracy: 0.9541\n",
      "Epoch 27: val_accuracy did not improve from 0.71477\n",
      "54/54 [==============================] - 18s 338ms/step - loss: 0.1472 - accuracy: 0.9541 - val_loss: 1.6797 - val_accuracy: 0.7112\n",
      "Epoch 28/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.1172 - accuracy: 0.9612\n",
      "Epoch 28: val_accuracy did not improve from 0.71477\n",
      "54/54 [==============================] - 20s 366ms/step - loss: 0.1172 - accuracy: 0.9612 - val_loss: 1.6611 - val_accuracy: 0.7145\n",
      "Epoch 29/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.1107 - accuracy: 0.9665\n",
      "Epoch 29: val_accuracy did not improve from 0.71477\n",
      "54/54 [==============================] - 19s 352ms/step - loss: 0.1107 - accuracy: 0.9665 - val_loss: 1.6472 - val_accuracy: 0.7083\n",
      "Epoch 1/30\n",
      "214/214 [==============================] - ETA: 0s - loss: 1.6759 - accuracy: 0.5858\n",
      "Epoch 1: val_accuracy improved from -inf to 0.62092, saving model to models\\lstm.h5\n",
      "214/214 [==============================] - 44s 129ms/step - loss: 1.6759 - accuracy: 0.5858 - val_loss: 1.5275 - val_accuracy: 0.6209\n",
      "Epoch 2/30\n",
      "214/214 [==============================] - ETA: 0s - loss: 1.5115 - accuracy: 0.6237\n",
      "Epoch 2: val_accuracy did not improve from 0.62092\n",
      "214/214 [==============================] - 22s 101ms/step - loss: 1.5115 - accuracy: 0.6237 - val_loss: 1.5842 - val_accuracy: 0.6209\n",
      "Epoch 3/30\n",
      "214/214 [==============================] - ETA: 0s - loss: 1.4457 - accuracy: 0.6266\n",
      "Epoch 3: val_accuracy improved from 0.62092 to 0.62916, saving model to models\\lstm.h5\n",
      "214/214 [==============================] - 24s 110ms/step - loss: 1.4457 - accuracy: 0.6266 - val_loss: 1.4304 - val_accuracy: 0.6292\n",
      "Epoch 4/30\n",
      "214/214 [==============================] - ETA: 0s - loss: 1.4155 - accuracy: 0.6293\n",
      "Epoch 4: val_accuracy improved from 0.62916 to 0.63077, saving model to models\\lstm.h5\n",
      "214/214 [==============================] - 24s 114ms/step - loss: 1.4155 - accuracy: 0.6293 - val_loss: 1.4879 - val_accuracy: 0.6308\n",
      "Epoch 5/30\n",
      "214/214 [==============================] - ETA: 0s - loss: 1.3846 - accuracy: 0.6351\n",
      "Epoch 5: val_accuracy did not improve from 0.63077\n",
      "214/214 [==============================] - 24s 111ms/step - loss: 1.3846 - accuracy: 0.6351 - val_loss: 1.4738 - val_accuracy: 0.6014\n",
      "Epoch 6/30\n",
      "214/214 [==============================] - ETA: 0s - loss: 1.3514 - accuracy: 0.6383\n",
      "Epoch 6: val_accuracy did not improve from 0.63077\n",
      "214/214 [==============================] - 24s 112ms/step - loss: 1.3514 - accuracy: 0.6383 - val_loss: 1.4266 - val_accuracy: 0.6066\n",
      "Epoch 7/30\n",
      "214/214 [==============================] - ETA: 0s - loss: 1.3402 - accuracy: 0.6347\n",
      "Epoch 7: val_accuracy did not improve from 0.63077\n",
      "214/214 [==============================] - 26s 120ms/step - loss: 1.3402 - accuracy: 0.6347 - val_loss: 1.4351 - val_accuracy: 0.6299\n",
      "Epoch 8/30\n",
      "214/214 [==============================] - ETA: 0s - loss: 1.3410 - accuracy: 0.6351\n",
      "Epoch 8: val_accuracy did not improve from 0.63077\n",
      "214/214 [==============================] - 23s 107ms/step - loss: 1.3410 - accuracy: 0.6351 - val_loss: 1.4724 - val_accuracy: 0.6280\n",
      "Epoch 9/30\n",
      "214/214 [==============================] - ETA: 0s - loss: 1.3232 - accuracy: 0.6342\n",
      "Epoch 9: val_accuracy did not improve from 0.63077\n",
      "214/214 [==============================] - 26s 121ms/step - loss: 1.3232 - accuracy: 0.6342 - val_loss: 1.4029 - val_accuracy: 0.6169\n",
      "Epoch 1/30\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.7269 - accuracy: 0.5533\n",
      "Epoch 1: val_accuracy improved from -inf to 0.62092, saving model to models\\lstm.h5\n",
      "107/107 [==============================] - 43s 242ms/step - loss: 1.7269 - accuracy: 0.5533 - val_loss: 1.5552 - val_accuracy: 0.6209\n",
      "Epoch 2/30\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.4559 - accuracy: 0.6265\n",
      "Epoch 2: val_accuracy improved from 0.62092 to 0.62386, saving model to models\\lstm.h5\n",
      "107/107 [==============================] - 28s 265ms/step - loss: 1.4559 - accuracy: 0.6265 - val_loss: 1.4549 - val_accuracy: 0.6239\n",
      "Epoch 3/30\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.3592 - accuracy: 0.6335\n",
      "Epoch 3: val_accuracy improved from 0.62386 to 0.62754, saving model to models\\lstm.h5\n",
      "107/107 [==============================] - 30s 285ms/step - loss: 1.3592 - accuracy: 0.6335 - val_loss: 1.4002 - val_accuracy: 0.6275\n",
      "Epoch 4/30\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.3040 - accuracy: 0.6424\n",
      "Epoch 4: val_accuracy improved from 0.62754 to 0.63416, saving model to models\\lstm.h5\n",
      "107/107 [==============================] - 25s 238ms/step - loss: 1.3040 - accuracy: 0.6424 - val_loss: 1.3755 - val_accuracy: 0.6342\n",
      "Epoch 5/30\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.2582 - accuracy: 0.6515\n",
      "Epoch 5: val_accuracy improved from 0.63416 to 0.63607, saving model to models\\lstm.h5\n",
      "107/107 [==============================] - 29s 270ms/step - loss: 1.2582 - accuracy: 0.6515 - val_loss: 1.3247 - val_accuracy: 0.6361\n",
      "Epoch 6/30\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.2159 - accuracy: 0.6612\n",
      "Epoch 6: val_accuracy did not improve from 0.63607\n",
      "107/107 [==============================] - 28s 267ms/step - loss: 1.2159 - accuracy: 0.6612 - val_loss: 1.6441 - val_accuracy: 0.4947\n",
      "Epoch 7/30\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.1964 - accuracy: 0.6576\n",
      "Epoch 7: val_accuracy improved from 0.63607 to 0.64475, saving model to models\\lstm.h5\n",
      "107/107 [==============================] - 26s 245ms/step - loss: 1.1964 - accuracy: 0.6576 - val_loss: 1.3514 - val_accuracy: 0.6447\n",
      "Epoch 8/30\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.1745 - accuracy: 0.6641\n",
      "Epoch 8: val_accuracy did not improve from 0.64475\n",
      "107/107 [==============================] - 30s 285ms/step - loss: 1.1745 - accuracy: 0.6641 - val_loss: 1.3255 - val_accuracy: 0.6440\n",
      "Epoch 9/30\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.1761 - accuracy: 0.6587\n",
      "Epoch 9: val_accuracy did not improve from 0.64475\n",
      "107/107 [==============================] - 32s 295ms/step - loss: 1.1761 - accuracy: 0.6587 - val_loss: 1.3052 - val_accuracy: 0.6320\n",
      "Epoch 10/30\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.1780 - accuracy: 0.6632\n",
      "Epoch 10: val_accuracy did not improve from 0.64475\n",
      "107/107 [==============================] - 25s 238ms/step - loss: 1.1780 - accuracy: 0.6632 - val_loss: 1.2800 - val_accuracy: 0.6383\n",
      "Epoch 11/30\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.1355 - accuracy: 0.6695\n",
      "Epoch 11: val_accuracy improved from 0.64475 to 0.64578, saving model to models\\lstm.h5\n",
      "107/107 [==============================] - 29s 276ms/step - loss: 1.1355 - accuracy: 0.6695 - val_loss: 1.2676 - val_accuracy: 0.6458\n",
      "Epoch 12/30\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.1494 - accuracy: 0.6667\n",
      "Epoch 12: val_accuracy did not improve from 0.64578\n",
      "107/107 [==============================] - 29s 270ms/step - loss: 1.1494 - accuracy: 0.6667 - val_loss: 1.4811 - val_accuracy: 0.5515\n",
      "Epoch 13/30\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.1529 - accuracy: 0.6626\n",
      "Epoch 13: val_accuracy did not improve from 0.64578\n",
      "107/107 [==============================] - 29s 268ms/step - loss: 1.1529 - accuracy: 0.6626 - val_loss: 1.2822 - val_accuracy: 0.6290\n",
      "Epoch 14/30\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.1455 - accuracy: 0.6682\n",
      "Epoch 14: val_accuracy did not improve from 0.64578\n",
      "107/107 [==============================] - 29s 269ms/step - loss: 1.1455 - accuracy: 0.6682 - val_loss: 1.3339 - val_accuracy: 0.6277\n",
      "Epoch 15/30\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.1451 - accuracy: 0.6669\n",
      "Epoch 15: val_accuracy did not improve from 0.64578\n",
      "107/107 [==============================] - 29s 268ms/step - loss: 1.1451 - accuracy: 0.6669 - val_loss: 1.3055 - val_accuracy: 0.6221\n",
      "Epoch 16/30\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.1338 - accuracy: 0.6683\n",
      "Epoch 16: val_accuracy did not improve from 0.64578\n",
      "107/107 [==============================] - 28s 262ms/step - loss: 1.1338 - accuracy: 0.6683 - val_loss: 1.2914 - val_accuracy: 0.6437\n",
      "Epoch 1/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.8122 - accuracy: 0.5226\n",
      "Epoch 1: val_accuracy improved from -inf to 0.62092, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 67s 605ms/step - loss: 1.8122 - accuracy: 0.5226 - val_loss: 1.5030 - val_accuracy: 0.6209\n",
      "Epoch 2/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.4609 - accuracy: 0.6269\n",
      "Epoch 2: val_accuracy did not improve from 0.62092\n",
      "54/54 [==============================] - 23s 436ms/step - loss: 1.4609 - accuracy: 0.6269 - val_loss: 1.5028 - val_accuracy: 0.6209\n",
      "Epoch 3/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.3646 - accuracy: 0.6420\n",
      "Epoch 3: val_accuracy improved from 0.62092 to 0.62489, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 24s 450ms/step - loss: 1.3646 - accuracy: 0.6420 - val_loss: 1.3649 - val_accuracy: 0.6249\n",
      "Epoch 4/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.2557 - accuracy: 0.6518\n",
      "Epoch 4: val_accuracy did not improve from 0.62489\n",
      "54/54 [==============================] - 23s 430ms/step - loss: 1.2557 - accuracy: 0.6518 - val_loss: 1.4566 - val_accuracy: 0.6243\n",
      "Epoch 5/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.2043 - accuracy: 0.6600\n",
      "Epoch 5: val_accuracy did not improve from 0.62489\n",
      "54/54 [==============================] - 24s 455ms/step - loss: 1.2043 - accuracy: 0.6600 - val_loss: 1.3167 - val_accuracy: 0.6175\n",
      "Epoch 6/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.1215 - accuracy: 0.6727\n",
      "Epoch 6: val_accuracy improved from 0.62489 to 0.64034, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 24s 451ms/step - loss: 1.1215 - accuracy: 0.6727 - val_loss: 1.2521 - val_accuracy: 0.6403\n",
      "Epoch 7/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.0676 - accuracy: 0.6863\n",
      "Epoch 7: val_accuracy improved from 0.64034 to 0.65578, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 24s 450ms/step - loss: 1.0676 - accuracy: 0.6863 - val_loss: 1.2174 - val_accuracy: 0.6558\n",
      "Epoch 8/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.0547 - accuracy: 0.6888\n",
      "Epoch 8: val_accuracy did not improve from 0.65578\n",
      "54/54 [==============================] - 24s 445ms/step - loss: 1.0547 - accuracy: 0.6888 - val_loss: 1.2267 - val_accuracy: 0.6475\n",
      "Epoch 9/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.0039 - accuracy: 0.6985\n",
      "Epoch 9: val_accuracy did not improve from 0.65578\n",
      "54/54 [==============================] - 24s 453ms/step - loss: 1.0039 - accuracy: 0.6985 - val_loss: 1.2743 - val_accuracy: 0.6536\n",
      "Epoch 10/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.9685 - accuracy: 0.7106\n",
      "Epoch 10: val_accuracy improved from 0.65578 to 0.65872, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 24s 446ms/step - loss: 0.9685 - accuracy: 0.7106 - val_loss: 1.1715 - val_accuracy: 0.6587\n",
      "Epoch 11/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.9425 - accuracy: 0.7110\n",
      "Epoch 11: val_accuracy did not improve from 0.65872\n",
      "54/54 [==============================] - 24s 448ms/step - loss: 0.9425 - accuracy: 0.7110 - val_loss: 1.2959 - val_accuracy: 0.6112\n",
      "Epoch 12/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.9393 - accuracy: 0.7118\n",
      "Epoch 12: val_accuracy improved from 0.65872 to 0.65961, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 24s 447ms/step - loss: 0.9393 - accuracy: 0.7118 - val_loss: 1.1641 - val_accuracy: 0.6596\n",
      "Epoch 13/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.9152 - accuracy: 0.7118\n",
      "Epoch 13: val_accuracy did not improve from 0.65961\n",
      "54/54 [==============================] - 24s 444ms/step - loss: 0.9152 - accuracy: 0.7118 - val_loss: 1.1605 - val_accuracy: 0.6543\n",
      "Epoch 14/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.8878 - accuracy: 0.7254\n",
      "Epoch 14: val_accuracy did not improve from 0.65961\n",
      "54/54 [==============================] - 25s 460ms/step - loss: 0.8878 - accuracy: 0.7254 - val_loss: 1.3115 - val_accuracy: 0.6055\n",
      "Epoch 15/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.8879 - accuracy: 0.7245\n",
      "Epoch 15: val_accuracy did not improve from 0.65961\n",
      "54/54 [==============================] - 25s 460ms/step - loss: 0.8879 - accuracy: 0.7245 - val_loss: 1.1975 - val_accuracy: 0.6447\n",
      "Epoch 16/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.8998 - accuracy: 0.7229\n",
      "Epoch 16: val_accuracy improved from 0.65961 to 0.67490, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 25s 463ms/step - loss: 0.8998 - accuracy: 0.7229 - val_loss: 1.1285 - val_accuracy: 0.6749\n",
      "Epoch 17/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.8801 - accuracy: 0.7327\n",
      "Epoch 17: val_accuracy did not improve from 0.67490\n",
      "54/54 [==============================] - 24s 442ms/step - loss: 0.8801 - accuracy: 0.7327 - val_loss: 1.1644 - val_accuracy: 0.6731\n",
      "Epoch 18/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.8965 - accuracy: 0.7233\n",
      "Epoch 18: val_accuracy did not improve from 0.67490\n",
      "54/54 [==============================] - 23s 431ms/step - loss: 0.8965 - accuracy: 0.7233 - val_loss: 1.2202 - val_accuracy: 0.6364\n",
      "Epoch 19/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.8787 - accuracy: 0.7330\n",
      "Epoch 19: val_accuracy did not improve from 0.67490\n",
      "54/54 [==============================] - 24s 439ms/step - loss: 0.8787 - accuracy: 0.7330 - val_loss: 1.3208 - val_accuracy: 0.5978\n",
      "Epoch 20/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.8454 - accuracy: 0.7391\n",
      "Epoch 20: val_accuracy did not improve from 0.67490\n",
      "54/54 [==============================] - 23s 423ms/step - loss: 0.8454 - accuracy: 0.7391 - val_loss: 1.2091 - val_accuracy: 0.6464\n",
      "Epoch 21/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 0.8444 - accuracy: 0.7447\n",
      "Epoch 21: val_accuracy did not improve from 0.67490\n",
      "54/54 [==============================] - 21s 390ms/step - loss: 0.8444 - accuracy: 0.7447 - val_loss: 1.1684 - val_accuracy: 0.6571\n",
      "Epoch 1/30\n",
      "214/214 [==============================] - ETA: 0s - loss: 1.6963 - accuracy: 0.6045\n",
      "Epoch 1: val_accuracy improved from -inf to 0.62092, saving model to models\\lstm.h5\n",
      "214/214 [==============================] - 65s 196ms/step - loss: 1.6963 - accuracy: 0.6045 - val_loss: 1.5564 - val_accuracy: 0.6209\n",
      "Epoch 2/30\n",
      "214/214 [==============================] - ETA: 0s - loss: 1.6071 - accuracy: 0.6224\n",
      "Epoch 2: val_accuracy did not improve from 0.62092\n",
      "214/214 [==============================] - 32s 149ms/step - loss: 1.6071 - accuracy: 0.6224 - val_loss: 1.6048 - val_accuracy: 0.6209\n",
      "Epoch 3/30\n",
      "214/214 [==============================] - ETA: 0s - loss: 1.6069 - accuracy: 0.6237\n",
      "Epoch 3: val_accuracy did not improve from 0.62092\n",
      "214/214 [==============================] - 31s 147ms/step - loss: 1.6069 - accuracy: 0.6237 - val_loss: 1.6981 - val_accuracy: 0.6209\n",
      "Epoch 4/30\n",
      "214/214 [==============================] - ETA: 0s - loss: 1.6270 - accuracy: 0.6211\n",
      "Epoch 4: val_accuracy did not improve from 0.62092\n",
      "214/214 [==============================] - 32s 149ms/step - loss: 1.6270 - accuracy: 0.6211 - val_loss: 1.6445 - val_accuracy: 0.6209\n",
      "Epoch 5/30\n",
      "214/214 [==============================] - ETA: 0s - loss: 1.6182 - accuracy: 0.6234\n",
      "Epoch 5: val_accuracy did not improve from 0.62092\n",
      "214/214 [==============================] - 31s 143ms/step - loss: 1.6182 - accuracy: 0.6234 - val_loss: 1.9304 - val_accuracy: 0.6209\n",
      "Epoch 6/30\n",
      "214/214 [==============================] - ETA: 0s - loss: 1.6211 - accuracy: 0.6225\n",
      "Epoch 6: val_accuracy did not improve from 0.62092\n",
      "214/214 [==============================] - 33s 153ms/step - loss: 1.6211 - accuracy: 0.6225 - val_loss: 2.2440 - val_accuracy: 0.0382\n",
      "Epoch 1/30\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.7064 - accuracy: 0.6013\n",
      "Epoch 1: val_accuracy improved from -inf to 0.62092, saving model to models\\lstm.h5\n",
      "107/107 [==============================] - 70s 302ms/step - loss: 1.7064 - accuracy: 0.6013 - val_loss: 1.5849 - val_accuracy: 0.6209\n",
      "Epoch 2/30\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.5735 - accuracy: 0.6240\n",
      "Epoch 2: val_accuracy did not improve from 0.62092\n",
      "107/107 [==============================] - 27s 256ms/step - loss: 1.5735 - accuracy: 0.6240 - val_loss: 1.5548 - val_accuracy: 0.6209\n",
      "Epoch 3/30\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.5599 - accuracy: 0.6228\n",
      "Epoch 3: val_accuracy did not improve from 0.62092\n",
      "107/107 [==============================] - 25s 237ms/step - loss: 1.5599 - accuracy: 0.6228 - val_loss: 1.5938 - val_accuracy: 0.6209\n",
      "Epoch 4/30\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.5691 - accuracy: 0.6240\n",
      "Epoch 4: val_accuracy did not improve from 0.62092\n",
      "107/107 [==============================] - 22s 202ms/step - loss: 1.5691 - accuracy: 0.6240 - val_loss: 1.8336 - val_accuracy: 0.5971\n",
      "Epoch 5/30\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.5696 - accuracy: 0.6241\n",
      "Epoch 5: val_accuracy did not improve from 0.62092\n",
      "107/107 [==============================] - 23s 212ms/step - loss: 1.5696 - accuracy: 0.6241 - val_loss: 1.6078 - val_accuracy: 0.6209\n",
      "Epoch 6/30\n",
      "107/107 [==============================] - ETA: 0s - loss: 1.5709 - accuracy: 0.6243\n",
      "Epoch 6: val_accuracy did not improve from 0.62092\n",
      "107/107 [==============================] - 26s 248ms/step - loss: 1.5709 - accuracy: 0.6243 - val_loss: 1.5867 - val_accuracy: 0.6209\n",
      "Epoch 1/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.7226 - accuracy: 0.5955\n",
      "Epoch 1: val_accuracy improved from -inf to 0.62092, saving model to models\\lstm.h5\n",
      "54/54 [==============================] - 64s 513ms/step - loss: 1.7226 - accuracy: 0.5955 - val_loss: 1.5536 - val_accuracy: 0.6209\n",
      "Epoch 2/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.5529 - accuracy: 0.6241\n",
      "Epoch 2: val_accuracy did not improve from 0.62092\n",
      "54/54 [==============================] - 23s 431ms/step - loss: 1.5529 - accuracy: 0.6241 - val_loss: 1.5481 - val_accuracy: 0.6209\n",
      "Epoch 3/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.5455 - accuracy: 0.6241\n",
      "Epoch 3: val_accuracy did not improve from 0.62092\n",
      "54/54 [==============================] - 22s 416ms/step - loss: 1.5455 - accuracy: 0.6241 - val_loss: 1.5659 - val_accuracy: 0.6209\n",
      "Epoch 4/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.5456 - accuracy: 0.6244\n",
      "Epoch 4: val_accuracy did not improve from 0.62092\n",
      "54/54 [==============================] - 23s 427ms/step - loss: 1.5456 - accuracy: 0.6244 - val_loss: 1.5456 - val_accuracy: 0.6209\n",
      "Epoch 5/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.5443 - accuracy: 0.6244\n",
      "Epoch 5: val_accuracy did not improve from 0.62092\n",
      "54/54 [==============================] - 23s 435ms/step - loss: 1.5443 - accuracy: 0.6244 - val_loss: 1.5520 - val_accuracy: 0.6209\n",
      "Epoch 6/30\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.5437 - accuracy: 0.6244\n",
      "Epoch 6: val_accuracy did not improve from 0.62092\n",
      "54/54 [==============================] - 23s 432ms/step - loss: 1.5437 - accuracy: 0.6244 - val_loss: 1.5480 - val_accuracy: 0.6209\n",
      "Epoch 1/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 1.9755 - accuracy: 0.4380\n",
      "Epoch 1: val_accuracy improved from -inf to 0.63239, saving model to models\\lstm.h5\n",
      "214/214 [==============================] - 83s 300ms/step - loss: 1.9755 - accuracy: 0.4380 - val_loss: 1.4044 - val_accuracy: 0.6324\n",
      "Epoch 2/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 1.3321 - accuracy: 0.6407\n",
      "Epoch 2: val_accuracy improved from 0.63239 to 0.65799, saving model to models\\lstm.h5\n",
      "214/214 [==============================] - 61s 284ms/step - loss: 1.3321 - accuracy: 0.6407 - val_loss: 1.2838 - val_accuracy: 0.6580\n",
      "Epoch 3/20\n",
      "214/214 [==============================] - ETA: 0s - loss: 1.0876 - accuracy: 0.6821\n",
      "Epoch 3: val_accuracy improved from 0.65799 to 0.67991, saving model to models\\lstm.h5\n",
      "214/214 [==============================] - 61s 286ms/step - loss: 1.0876 - accuracy: 0.6821 - val_loss: 1.1004 - val_accuracy: 0.6799\n",
      "Epoch 4/20\n",
      "145/214 [===================>..........] - ETA: 15s - loss: 0.9066 - accuracy: 0.7222"
     ]
    }
   ],
   "source": [
    "res = pd.DataFrame(columns=['lstm_units', 'dropout_rate', 'learning_rate', 'epoch', 'batch', 'loss_max','accuracy_max','val_loss_max', 'val_accuracy_max'])\n",
    "\n",
    "for lstm_unit in [64,128]:\n",
    "    for epoch in [20, 30]:\n",
    "        for lr in [0.001, 0.01, 0.1]:\n",
    "            for batch in [32,64,128]:\n",
    "                model = Lstm(lstm_units=lstm_unit, dropout_rate=0.2, learning_rate=lr, num_classes=11, batch_size=batch, epoch=epoch)\n",
    "                model.train(label_detection_training, label_detection_validation)\n",
    "                res = np.concatenate((res, pd.DataFrame([[lstm_unit,0.2, lr, epoch, batch, model.history.history['loss'][-1], model.history.history['accuracy'][-1], model.history.history['val_loss'][-1], model.history.history['val_accuracy'][-1]]], \n",
    "                                                                        columns=['lstm_units', 'dropout_rate', 'learning_rate', 'epoch', 'batch', 'loss_max','accuracy_max','val_loss_max', 'val_accuracy_max'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(res,columns=['num_heads', 'dropout_rate', 'learning_rate', 'epoch', 'batch', 'num_layer', 'loss_max','accuracy_max','val_loss_max', 'val_accuracy_max']).to_pickle('transformer_wyniki_.pkl')\n",
    "pd.DataFrame(res,columns=['lstm_units', 'dropout_rate', 'learning_rate', 'epoch', 'batch', 'loss_max','accuracy_max','val_loss_max', 'val_accuracy_max']).to_pickle('results/lstm_wyniki_.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.columns=['lstm_units', 'dropout_rate', 'epoch', 'batch', 'loss', 'loss_max', 'accuracy', 'accuracy_max', 'val_loss', 'val_loss_max', 'val_accuracy', 'val_accuracy_max']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lstm_units</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>batch</th>\n",
       "      <th>loss</th>\n",
       "      <th>loss_max</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_max</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_loss_max</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_accuracy_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>20</td>\n",
       "      <td>64</td>\n",
       "      <td>0.434148</td>\n",
       "      <td>[2.4646902084350586, 1.4764158725738525, 1.160...</td>\n",
       "      <td>0.870311</td>\n",
       "      <td>[0.3031783699989319, 0.5757989287376404, 0.666...</td>\n",
       "      <td>0.736218</td>\n",
       "      <td>[1.6360548734664917, 1.2466334104537964, 1.031...</td>\n",
       "      <td>0.816564</td>\n",
       "      <td>[0.5272138714790344, 0.6362165212631226, 0.707...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lstm_units  ...                                   val_accuracy_max\n",
       "4         64  ...  [0.5272138714790344, 0.6362165212631226, 0.707...\n",
       "\n",
       "[1 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[results['val_accuracy'] == results['val_accuracy'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Lstm(64, 0.2, 20, 32, 0.001, (39,44), 30, 'models\\\\lstm_mod.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "213/213 [==============================] - ETA: 0s - loss: 2.7642 - accuracy: 0.3926\n",
      "Epoch 1: accuracy improved from -inf to 0.39262, saving model to models\\lstm_mod.h5\n",
      "213/213 [==============================] - 17s 46ms/step - loss: 2.7642 - accuracy: 0.3926\n",
      "Epoch 2/20\n",
      "213/213 [==============================] - ETA: 0s - loss: 1.5931 - accuracy: 0.6222\n",
      "Epoch 2: accuracy improved from 0.39262 to 0.62224, saving model to models\\lstm_mod.h5\n",
      "213/213 [==============================] - 10s 44ms/step - loss: 1.5931 - accuracy: 0.6222\n",
      "Epoch 3/20\n",
      "212/213 [============================>.] - ETA: 0s - loss: 1.2429 - accuracy: 0.6555\n",
      "Epoch 3: accuracy improved from 0.62224 to 0.65593, saving model to models\\lstm_mod.h5\n",
      "213/213 [==============================] - 9s 44ms/step - loss: 1.2420 - accuracy: 0.6559\n",
      "Epoch 4/20\n",
      "213/213 [==============================] - ETA: 0s - loss: 1.0566 - accuracy: 0.6890\n",
      "Epoch 4: accuracy improved from 0.65593 to 0.68903, saving model to models\\lstm_mod.h5\n",
      "213/213 [==============================] - 9s 44ms/step - loss: 1.0566 - accuracy: 0.6890\n",
      "Epoch 5/20\n",
      "213/213 [==============================] - ETA: 0s - loss: 0.9269 - accuracy: 0.7214\n",
      "Epoch 5: accuracy improved from 0.68903 to 0.72139, saving model to models\\lstm_mod.h5\n",
      "213/213 [==============================] - 10s 45ms/step - loss: 0.9269 - accuracy: 0.7214\n",
      "Epoch 6/20\n",
      "213/213 [==============================] - ETA: 0s - loss: 0.8182 - accuracy: 0.7501\n",
      "Epoch 6: accuracy improved from 0.72139 to 0.75007, saving model to models\\lstm_mod.h5\n",
      "213/213 [==============================] - 10s 45ms/step - loss: 0.8182 - accuracy: 0.7501\n",
      "Epoch 7/20\n",
      "213/213 [==============================] - ETA: 0s - loss: 0.7227 - accuracy: 0.7761\n",
      "Epoch 7: accuracy improved from 0.75007 to 0.77611, saving model to models\\lstm_mod.h5\n",
      "213/213 [==============================] - 10s 45ms/step - loss: 0.7227 - accuracy: 0.7761\n",
      "Epoch 8/20\n",
      "212/213 [============================>.] - ETA: 0s - loss: 0.6456 - accuracy: 0.7927\n",
      "Epoch 8: accuracy improved from 0.77611 to 0.79288, saving model to models\\lstm_mod.h5\n",
      "213/213 [==============================] - 10s 46ms/step - loss: 0.6455 - accuracy: 0.7929\n",
      "Epoch 9/20\n",
      "212/213 [============================>.] - ETA: 0s - loss: 0.5614 - accuracy: 0.8194\n",
      "Epoch 9: accuracy improved from 0.79288 to 0.81921, saving model to models\\lstm_mod.h5\n",
      "213/213 [==============================] - 11s 50ms/step - loss: 0.5612 - accuracy: 0.8192\n",
      "Epoch 10/20\n",
      "212/213 [============================>.] - ETA: 0s - loss: 0.5452 - accuracy: 0.8280\n",
      "Epoch 10: accuracy improved from 0.81921 to 0.82804, saving model to models\\lstm_mod.h5\n",
      "213/213 [==============================] - 11s 51ms/step - loss: 0.5453 - accuracy: 0.8280\n",
      "Epoch 11/20\n",
      "213/213 [==============================] - ETA: 0s - loss: 0.4609 - accuracy: 0.8503\n",
      "Epoch 11: accuracy improved from 0.82804 to 0.85025, saving model to models\\lstm_mod.h5\n",
      "213/213 [==============================] - 11s 50ms/step - loss: 0.4609 - accuracy: 0.8503\n",
      "Epoch 12/20\n",
      "213/213 [==============================] - ETA: 0s - loss: 0.4287 - accuracy: 0.8629\n",
      "Epoch 12: accuracy improved from 0.85025 to 0.86290, saving model to models\\lstm_mod.h5\n",
      "213/213 [==============================] - 11s 50ms/step - loss: 0.4287 - accuracy: 0.8629\n",
      "Epoch 13/20\n",
      "212/213 [============================>.] - ETA: 0s - loss: 0.3898 - accuracy: 0.8797\n",
      "Epoch 13: accuracy improved from 0.86290 to 0.87982, saving model to models\\lstm_mod.h5\n",
      "213/213 [==============================] - 11s 53ms/step - loss: 0.3902 - accuracy: 0.8798\n",
      "Epoch 14/20\n",
      "212/213 [============================>.] - ETA: 0s - loss: 0.3392 - accuracy: 0.8921\n",
      "Epoch 14: accuracy improved from 0.87982 to 0.89188, saving model to models\\lstm_mod.h5\n",
      "213/213 [==============================] - 11s 52ms/step - loss: 0.3407 - accuracy: 0.8919\n",
      "Epoch 15/20\n",
      "212/213 [============================>.] - ETA: 0s - loss: 0.3259 - accuracy: 0.8946\n",
      "Epoch 15: accuracy improved from 0.89188 to 0.89453, saving model to models\\lstm_mod.h5\n",
      "213/213 [==============================] - 11s 52ms/step - loss: 0.3264 - accuracy: 0.8945\n",
      "Epoch 16/20\n",
      "212/213 [============================>.] - ETA: 0s - loss: 0.2897 - accuracy: 0.9105\n",
      "Epoch 16: accuracy improved from 0.89453 to 0.91041, saving model to models\\lstm_mod.h5\n",
      "213/213 [==============================] - 11s 53ms/step - loss: 0.2904 - accuracy: 0.9104\n",
      "Epoch 17/20\n",
      "212/213 [============================>.] - ETA: 0s - loss: 0.2833 - accuracy: 0.9099\n",
      "Epoch 17: accuracy did not improve from 0.91041\n",
      "213/213 [==============================] - 11s 53ms/step - loss: 0.2829 - accuracy: 0.9101\n",
      "Epoch 18/20\n",
      "212/213 [============================>.] - ETA: 0s - loss: 0.2645 - accuracy: 0.9161\n",
      "Epoch 18: accuracy improved from 0.91041 to 0.91600, saving model to models\\lstm_mod.h5\n",
      "213/213 [==============================] - 11s 53ms/step - loss: 0.2652 - accuracy: 0.9160\n",
      "Epoch 19/20\n",
      "212/213 [============================>.] - ETA: 0s - loss: 0.2306 - accuracy: 0.9259\n",
      "Epoch 19: accuracy improved from 0.91600 to 0.92571, saving model to models\\lstm_mod.h5\n",
      "213/213 [==============================] - 11s 53ms/step - loss: 0.2310 - accuracy: 0.9257\n",
      "Epoch 20/20\n",
      "212/213 [============================>.] - ETA: 0s - loss: 0.2138 - accuracy: 0.9331\n",
      "Epoch 20: accuracy improved from 0.92571 to 0.93322, saving model to models\\lstm_mod.h5\n",
      "213/213 [==============================] - 12s 57ms/step - loss: 0.2135 - accuracy: 0.9332\n"
     ]
    }
   ],
   "source": [
    "model.train(label_detection_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense, Bidirectional, TimeDistributed, BatchNormalization\n",
    "from dataset import LABELS\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from dataset import label_detection_training, label_detection_validation, silence_detection_training, silence_detection_validation\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import TensorflowDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle('extracted_features\\\\features_training.pkl')\n",
    "y_train = np.array([x[1] for x in train])\n",
    "labels = list(np.unique(y_train))\n",
    "train = TensorflowDataset('extracted_features\\\\features_training.pkl', labels=labels).dataset\n",
    "train = train.shuffle(len(train), reshuffle_each_iteration=True)\n",
    "val = TensorflowDataset('extracted_features\\\\features_validation.pkl', labels=labels).dataset\n",
    "val = val.shuffle(len(val), reshuffle_each_iteration=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['lstm_units', 'dropout_rate', 'epoch', 'batch', 'loss', 'loss_max', 'accuracy', 'accuracy_max', 'val_loss', 'val_loss_max', 'val_accuracy', 'val_accuracy_max'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57923"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.read_pickle('extracted_features\\\\features_training.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model with 64 units, 0.2 dropout rate, 10 epochs and 32 batch size\n",
      "Epoch 1/10\n",
      "1811/1811 [==============================] - 218s 109ms/step - loss: 2.4271 - accuracy: 0.3132 - val_loss: 1.5653 - val_accuracy: 0.5462\n",
      "Epoch 2/10\n",
      "1811/1811 [==============================] - 159s 87ms/step - loss: 1.4517 - accuracy: 0.5814 - val_loss: 1.1923 - val_accuracy: 0.6553\n",
      "Epoch 3/10\n",
      "1811/1811 [==============================] - 167s 92ms/step - loss: 1.1520 - accuracy: 0.6685 - val_loss: 1.0082 - val_accuracy: 0.7170\n",
      "Epoch 4/10\n",
      "1811/1811 [==============================] - 183s 101ms/step - loss: 1.0003 - accuracy: 0.7115 - val_loss: 0.9068 - val_accuracy: 0.7343\n",
      "Epoch 5/10\n",
      "1811/1811 [==============================] - 180s 99ms/step - loss: 0.8990 - accuracy: 0.7417 - val_loss: 0.9288 - val_accuracy: 0.7396\n",
      "Epoch 6/10\n",
      "1811/1811 [==============================] - 182s 100ms/step - loss: 0.8240 - accuracy: 0.7619 - val_loss: 0.8555 - val_accuracy: 0.7611\n",
      "Epoch 7/10\n",
      "1811/1811 [==============================] - 181s 100ms/step - loss: 0.7710 - accuracy: 0.7767 - val_loss: 0.8312 - val_accuracy: 0.7702\n",
      "Epoch 8/10\n",
      "1811/1811 [==============================] - 182s 100ms/step - loss: 0.7267 - accuracy: 0.7895 - val_loss: 0.7934 - val_accuracy: 0.7777\n",
      "Epoch 9/10\n",
      "1811/1811 [==============================] - 193s 107ms/step - loss: 0.6943 - accuracy: 0.7999 - val_loss: 0.7510 - val_accuracy: 0.7951\n",
      "Epoch 10/10\n",
      "1811/1811 [==============================] - 206s 113ms/step - loss: 0.6609 - accuracy: 0.8072 - val_loss: 0.7606 - val_accuracy: 0.7955\n",
      "Running model with 64 units, 0.2 dropout rate, 10 epochs and 64 batch size\n",
      "Epoch 1/10\n",
      "906/906 [==============================] - 195s 181ms/step - loss: 2.4885 - accuracy: 0.3005 - val_loss: 1.6191 - val_accuracy: 0.5310\n",
      "Epoch 2/10\n",
      "906/906 [==============================] - 157s 173ms/step - loss: 1.4613 - accuracy: 0.5799 - val_loss: 1.1752 - val_accuracy: 0.6642\n",
      "Epoch 3/10\n",
      "906/906 [==============================] - 144s 158ms/step - loss: 1.1222 - accuracy: 0.6759 - val_loss: 1.0141 - val_accuracy: 0.7127\n",
      "Epoch 4/10\n",
      "906/906 [==============================] - 144s 159ms/step - loss: 0.9522 - accuracy: 0.7248 - val_loss: 0.9100 - val_accuracy: 0.7373\n",
      "Epoch 5/10\n",
      "906/906 [==============================] - 130s 143ms/step - loss: 0.8579 - accuracy: 0.7507 - val_loss: 0.8765 - val_accuracy: 0.7542\n",
      "Epoch 6/10\n",
      "906/906 [==============================] - 131s 145ms/step - loss: 0.7907 - accuracy: 0.7715 - val_loss: 0.8293 - val_accuracy: 0.7658\n",
      "Epoch 7/10\n",
      "906/906 [==============================] - 130s 143ms/step - loss: 0.7166 - accuracy: 0.7908 - val_loss: 0.7941 - val_accuracy: 0.7751\n",
      "Epoch 8/10\n",
      "906/906 [==============================] - 131s 144ms/step - loss: 0.6710 - accuracy: 0.8030 - val_loss: 0.8095 - val_accuracy: 0.7732\n",
      "Epoch 9/10\n",
      "906/906 [==============================] - 130s 144ms/step - loss: 0.6382 - accuracy: 0.8106 - val_loss: 0.7781 - val_accuracy: 0.7880\n",
      "Epoch 10/10\n",
      "906/906 [==============================] - 130s 143ms/step - loss: 0.6002 - accuracy: 0.8236 - val_loss: 0.7659 - val_accuracy: 0.7905\n",
      "Running model with 64 units, 0.2 dropout rate, 20 epochs and 32 batch size\n",
      "Epoch 1/20\n",
      "1811/1811 [==============================] - 202s 102ms/step - loss: 2.3512 - accuracy: 0.3354 - val_loss: 1.5099 - val_accuracy: 0.5597\n",
      "Epoch 2/20\n",
      "1811/1811 [==============================] - 171s 94ms/step - loss: 1.3959 - accuracy: 0.5999 - val_loss: 1.1395 - val_accuracy: 0.6802\n",
      "Epoch 3/20\n",
      "1811/1811 [==============================] - 172s 95ms/step - loss: 1.1104 - accuracy: 0.6819 - val_loss: 1.0019 - val_accuracy: 0.7132\n",
      "Epoch 4/20\n",
      "1811/1811 [==============================] - 174s 96ms/step - loss: 0.9653 - accuracy: 0.7231 - val_loss: 0.9118 - val_accuracy: 0.7448\n",
      "Epoch 5/20\n",
      "1811/1811 [==============================] - 173s 96ms/step - loss: 0.8767 - accuracy: 0.7490 - val_loss: 0.8685 - val_accuracy: 0.7599\n",
      "Epoch 6/20\n",
      "1811/1811 [==============================] - 175s 96ms/step - loss: 0.8132 - accuracy: 0.7653 - val_loss: 0.8413 - val_accuracy: 0.7693\n",
      "Epoch 7/20\n",
      "1811/1811 [==============================] - 176s 97ms/step - loss: 0.7643 - accuracy: 0.7804 - val_loss: 0.7937 - val_accuracy: 0.7811\n",
      "Epoch 8/20\n",
      "1811/1811 [==============================] - 180s 99ms/step - loss: 0.7142 - accuracy: 0.7942 - val_loss: 0.7716 - val_accuracy: 0.7882\n",
      "Epoch 9/20\n",
      "1811/1811 [==============================] - 184s 101ms/step - loss: 0.6812 - accuracy: 0.8041 - val_loss: 0.7966 - val_accuracy: 0.7801\n",
      "Epoch 10/20\n",
      "1811/1811 [==============================] - 190s 105ms/step - loss: 0.6510 - accuracy: 0.8111 - val_loss: 0.7837 - val_accuracy: 0.7916\n",
      "Epoch 11/20\n",
      "1811/1811 [==============================] - 190s 105ms/step - loss: 0.6208 - accuracy: 0.8206 - val_loss: 0.7309 - val_accuracy: 0.7988\n",
      "Epoch 12/20\n",
      "1811/1811 [==============================] - 194s 107ms/step - loss: 0.5985 - accuracy: 0.8266 - val_loss: 0.7361 - val_accuracy: 0.7999\n",
      "Epoch 13/20\n",
      "1811/1811 [==============================] - 198s 109ms/step - loss: 0.5756 - accuracy: 0.8332 - val_loss: 0.7206 - val_accuracy: 0.8061\n",
      "Epoch 14/20\n",
      "1811/1811 [==============================] - 196s 108ms/step - loss: 0.5598 - accuracy: 0.8393 - val_loss: 0.7367 - val_accuracy: 0.8029\n",
      "Epoch 15/20\n",
      "1811/1811 [==============================] - 200s 110ms/step - loss: 0.5344 - accuracy: 0.8445 - val_loss: 0.7284 - val_accuracy: 0.8010\n",
      "Epoch 16/20\n",
      "1811/1811 [==============================] - 219s 121ms/step - loss: 0.5257 - accuracy: 0.8474 - val_loss: 0.7300 - val_accuracy: 0.8111\n",
      "Epoch 17/20\n",
      "1811/1811 [==============================] - 222s 122ms/step - loss: 0.5041 - accuracy: 0.8523 - val_loss: 0.6965 - val_accuracy: 0.8127\n",
      "Epoch 18/20\n",
      "1811/1811 [==============================] - 228s 126ms/step - loss: 0.4937 - accuracy: 0.8562 - val_loss: 0.7070 - val_accuracy: 0.8130\n",
      "Epoch 19/20\n",
      "1811/1811 [==============================] - 235s 130ms/step - loss: 0.4784 - accuracy: 0.8593 - val_loss: 0.7119 - val_accuracy: 0.8169\n",
      "Epoch 20/20\n",
      "1811/1811 [==============================] - 241s 133ms/step - loss: 0.4597 - accuracy: 0.8654 - val_loss: 0.7083 - val_accuracy: 0.8163\n",
      "Running model with 64 units, 0.2 dropout rate, 20 epochs and 64 batch size\n",
      "Epoch 1/20\n",
      "906/906 [==============================] - 196s 190ms/step - loss: 2.4647 - accuracy: 0.3032 - val_loss: 1.6361 - val_accuracy: 0.5272\n",
      "Epoch 2/20\n",
      "906/906 [==============================] - 155s 171ms/step - loss: 1.4764 - accuracy: 0.5758 - val_loss: 1.2466 - val_accuracy: 0.6362\n",
      "Epoch 3/20\n",
      "906/906 [==============================] - 142s 156ms/step - loss: 1.1610 - accuracy: 0.6660 - val_loss: 1.0312 - val_accuracy: 0.7077\n",
      "Epoch 4/20\n",
      "906/906 [==============================] - 142s 157ms/step - loss: 0.9783 - accuracy: 0.7166 - val_loss: 0.9678 - val_accuracy: 0.7336\n",
      "Epoch 5/20\n",
      "906/906 [==============================] - 141s 155ms/step - loss: 0.8681 - accuracy: 0.7484 - val_loss: 0.8724 - val_accuracy: 0.7513\n",
      "Epoch 6/20\n",
      "906/906 [==============================] - 146s 161ms/step - loss: 0.7951 - accuracy: 0.7668 - val_loss: 0.8759 - val_accuracy: 0.7577\n",
      "Epoch 7/20\n",
      "906/906 [==============================] - 145s 160ms/step - loss: 0.7404 - accuracy: 0.7847 - val_loss: 0.7931 - val_accuracy: 0.7749\n",
      "Epoch 8/20\n",
      "906/906 [==============================] - 146s 161ms/step - loss: 0.6924 - accuracy: 0.7978 - val_loss: 0.8210 - val_accuracy: 0.7792\n",
      "Epoch 9/20\n",
      "906/906 [==============================] - 146s 161ms/step - loss: 0.6798 - accuracy: 0.8019 - val_loss: 0.7811 - val_accuracy: 0.7796\n",
      "Epoch 10/20\n",
      "906/906 [==============================] - 145s 160ms/step - loss: 0.6237 - accuracy: 0.8174 - val_loss: 0.7763 - val_accuracy: 0.7860\n",
      "Epoch 11/20\n",
      "906/906 [==============================] - 145s 160ms/step - loss: 0.5917 - accuracy: 0.8265 - val_loss: 0.7537 - val_accuracy: 0.7930\n",
      "Epoch 12/20\n",
      "906/906 [==============================] - 146s 161ms/step - loss: 0.5610 - accuracy: 0.8346 - val_loss: 0.7447 - val_accuracy: 0.7974\n",
      "Epoch 13/20\n",
      "906/906 [==============================] - 146s 161ms/step - loss: 0.5437 - accuracy: 0.8395 - val_loss: 0.7550 - val_accuracy: 0.8008\n",
      "Epoch 14/20\n",
      "906/906 [==============================] - 146s 162ms/step - loss: 0.5174 - accuracy: 0.8467 - val_loss: 0.7332 - val_accuracy: 0.8085\n",
      "Epoch 15/20\n",
      "906/906 [==============================] - 149s 165ms/step - loss: 0.5028 - accuracy: 0.8501 - val_loss: 0.7581 - val_accuracy: 0.8021\n",
      "Epoch 16/20\n",
      "906/906 [==============================] - 149s 164ms/step - loss: 0.5045 - accuracy: 0.8499 - val_loss: 0.7818 - val_accuracy: 0.8019\n",
      "Epoch 17/20\n",
      "906/906 [==============================] - 149s 165ms/step - loss: 0.4798 - accuracy: 0.8580 - val_loss: 0.7687 - val_accuracy: 0.8099\n",
      "Epoch 18/20\n",
      "906/906 [==============================] - 150s 165ms/step - loss: 0.4641 - accuracy: 0.8604 - val_loss: 0.7724 - val_accuracy: 0.8071\n",
      "Epoch 19/20\n",
      "906/906 [==============================] - 149s 165ms/step - loss: 0.4395 - accuracy: 0.8701 - val_loss: 0.7665 - val_accuracy: 0.8095\n",
      "Epoch 20/20\n",
      "906/906 [==============================] - 149s 164ms/step - loss: 0.4341 - accuracy: 0.8703 - val_loss: 0.7362 - val_accuracy: 0.8166\n",
      "Running model with 64 units, 0.4 dropout rate, 10 epochs and 32 batch size\n",
      "Epoch 1/10\n",
      "1811/1811 [==============================] - 295s 153ms/step - loss: 2.8703 - accuracy: 0.1959 - val_loss: 2.0042 - val_accuracy: 0.4179\n",
      "Epoch 2/10\n",
      "1811/1811 [==============================] - 288s 159ms/step - loss: 1.9049 - accuracy: 0.4504 - val_loss: 1.4960 - val_accuracy: 0.5721\n",
      "Epoch 3/10\n",
      "1811/1811 [==============================] - 289s 159ms/step - loss: 1.5276 - accuracy: 0.5626 - val_loss: 1.2571 - val_accuracy: 0.6412\n",
      "Epoch 4/10\n",
      "1811/1811 [==============================] - 297s 164ms/step - loss: 1.3307 - accuracy: 0.6239 - val_loss: 1.2024 - val_accuracy: 0.6706\n",
      "Epoch 5/10\n",
      "1811/1811 [==============================] - 313s 173ms/step - loss: 1.2068 - accuracy: 0.6603 - val_loss: 1.0343 - val_accuracy: 0.7093\n",
      "Epoch 6/10\n",
      "1811/1811 [==============================] - 339s 187ms/step - loss: 1.1144 - accuracy: 0.6882 - val_loss: 1.0484 - val_accuracy: 0.7158\n",
      "Epoch 7/10\n",
      "1811/1811 [==============================] - 333s 184ms/step - loss: 1.0497 - accuracy: 0.7063 - val_loss: 1.0144 - val_accuracy: 0.7282\n",
      "Epoch 8/10\n",
      "1811/1811 [==============================] - 318s 176ms/step - loss: 0.9992 - accuracy: 0.7203 - val_loss: 1.0292 - val_accuracy: 0.7277\n",
      "Epoch 9/10\n",
      "1811/1811 [==============================] - 329s 181ms/step - loss: 0.9536 - accuracy: 0.7311 - val_loss: 0.9564 - val_accuracy: 0.7448\n",
      "Epoch 10/10\n",
      "1811/1811 [==============================] - 335s 185ms/step - loss: 0.9225 - accuracy: 0.7423 - val_loss: 0.9438 - val_accuracy: 0.7551\n",
      "Running model with 64 units, 0.4 dropout rate, 10 epochs and 64 batch size\n",
      "Epoch 1/10\n",
      "906/906 [==============================] - 201s 202ms/step - loss: 3.0298 - accuracy: 0.1684 - val_loss: 2.0706 - val_accuracy: 0.3885\n",
      "Epoch 2/10\n",
      "906/906 [==============================] - 178s 197ms/step - loss: 1.9738 - accuracy: 0.4342 - val_loss: 1.5751 - val_accuracy: 0.5460\n",
      "Epoch 3/10\n",
      "906/906 [==============================] - 179s 197ms/step - loss: 1.5500 - accuracy: 0.5585 - val_loss: 1.3093 - val_accuracy: 0.6287\n",
      "Epoch 4/10\n",
      "906/906 [==============================] - 179s 198ms/step - loss: 1.3110 - accuracy: 0.6294 - val_loss: 1.1724 - val_accuracy: 0.6758\n",
      "Epoch 5/10\n",
      "906/906 [==============================] - 178s 197ms/step - loss: 1.1698 - accuracy: 0.6700 - val_loss: 1.0574 - val_accuracy: 0.7034\n",
      "Epoch 6/10\n",
      "906/906 [==============================] - 178s 196ms/step - loss: 1.0697 - accuracy: 0.6978 - val_loss: 1.0003 - val_accuracy: 0.7240\n",
      "Epoch 7/10\n",
      "906/906 [==============================] - 179s 197ms/step - loss: 1.0050 - accuracy: 0.7158 - val_loss: 0.9467 - val_accuracy: 0.7473\n",
      "Epoch 8/10\n",
      "906/906 [==============================] - 176s 195ms/step - loss: 0.9535 - accuracy: 0.7318 - val_loss: 0.9690 - val_accuracy: 0.7430\n",
      "Epoch 9/10\n",
      "906/906 [==============================] - 173s 191ms/step - loss: 0.9002 - accuracy: 0.7481 - val_loss: 0.9273 - val_accuracy: 0.7571\n",
      "Epoch 10/10\n",
      "906/906 [==============================] - 174s 192ms/step - loss: 0.8624 - accuracy: 0.7577 - val_loss: 0.9510 - val_accuracy: 0.7557\n",
      "Running model with 64 units, 0.4 dropout rate, 20 epochs and 32 batch size\n",
      "Epoch 1/20\n",
      "1811/1811 [==============================] - 378s 200ms/step - loss: 2.8722 - accuracy: 0.1976 - val_loss: 1.9758 - val_accuracy: 0.4259\n",
      "Epoch 2/20\n",
      "1811/1811 [==============================] - 380s 210ms/step - loss: 1.8928 - accuracy: 0.4520 - val_loss: 1.4281 - val_accuracy: 0.5837\n",
      "Epoch 3/20\n",
      "1811/1811 [==============================] - 390s 215ms/step - loss: 1.5408 - accuracy: 0.5597 - val_loss: 1.2735 - val_accuracy: 0.6437\n",
      "Epoch 4/20\n",
      "1811/1811 [==============================] - 387s 214ms/step - loss: 1.3381 - accuracy: 0.6230 - val_loss: 1.1302 - val_accuracy: 0.6842\n",
      "Epoch 5/20\n",
      "1811/1811 [==============================] - 388s 214ms/step - loss: 1.2103 - accuracy: 0.6587 - val_loss: 1.0444 - val_accuracy: 0.7115\n",
      "Epoch 6/20\n",
      "1811/1811 [==============================] - 398s 220ms/step - loss: 1.1175 - accuracy: 0.6845 - val_loss: 1.0384 - val_accuracy: 0.7161\n",
      "Epoch 7/20\n",
      "1811/1811 [==============================] - 424s 234ms/step - loss: 1.0529 - accuracy: 0.7047 - val_loss: 1.0182 - val_accuracy: 0.7342\n",
      "Epoch 8/20\n",
      "1811/1811 [==============================] - 430s 237ms/step - loss: 0.9945 - accuracy: 0.7219 - val_loss: 0.9475 - val_accuracy: 0.7449\n",
      "Epoch 9/20\n",
      "1811/1811 [==============================] - 385s 213ms/step - loss: 0.9527 - accuracy: 0.7324 - val_loss: 0.9105 - val_accuracy: 0.7588\n",
      "Epoch 10/20\n",
      "1811/1811 [==============================] - 385s 212ms/step - loss: 0.9154 - accuracy: 0.7443 - val_loss: 0.9463 - val_accuracy: 0.7564\n",
      "Epoch 11/20\n",
      "1811/1811 [==============================] - 383s 212ms/step - loss: 0.8826 - accuracy: 0.7519 - val_loss: 0.8953 - val_accuracy: 0.7710\n",
      "Epoch 12/20\n",
      "1811/1811 [==============================] - 382s 211ms/step - loss: 0.8483 - accuracy: 0.7625 - val_loss: 0.8936 - val_accuracy: 0.7655\n",
      "Epoch 13/20\n",
      "1811/1811 [==============================] - 382s 211ms/step - loss: 0.8264 - accuracy: 0.7701 - val_loss: 0.8615 - val_accuracy: 0.7779\n",
      "Epoch 14/20\n",
      "1811/1811 [==============================] - 380s 209ms/step - loss: 0.8018 - accuracy: 0.7771 - val_loss: 0.8662 - val_accuracy: 0.7814\n",
      "Epoch 15/20\n",
      "1811/1811 [==============================] - 371s 205ms/step - loss: 0.7768 - accuracy: 0.7821 - val_loss: 0.8780 - val_accuracy: 0.7751\n",
      "Epoch 16/20\n",
      "1811/1811 [==============================] - 372s 205ms/step - loss: 0.7673 - accuracy: 0.7861 - val_loss: 0.8705 - val_accuracy: 0.7810\n",
      "Epoch 17/20\n",
      "1811/1811 [==============================] - 374s 206ms/step - loss: 0.7433 - accuracy: 0.7934 - val_loss: 0.8134 - val_accuracy: 0.7907\n",
      "Epoch 18/20\n",
      "1811/1811 [==============================] - 375s 207ms/step - loss: 0.7239 - accuracy: 0.7975 - val_loss: 0.7981 - val_accuracy: 0.7896\n",
      "Epoch 19/20\n",
      "1811/1811 [==============================] - 373s 206ms/step - loss: 0.7137 - accuracy: 0.7997 - val_loss: 0.8127 - val_accuracy: 0.7882\n",
      "Epoch 20/20\n",
      "1811/1811 [==============================] - 375s 207ms/step - loss: 0.6955 - accuracy: 0.8061 - val_loss: 0.8091 - val_accuracy: 0.7948\n",
      "Running model with 64 units, 0.4 dropout rate, 20 epochs and 64 batch size\n",
      "Epoch 1/20\n",
      "906/906 [==============================] - 208s 214ms/step - loss: 3.0261 - accuracy: 0.1641 - val_loss: 2.1682 - val_accuracy: 0.3620\n",
      "Epoch 2/20\n",
      "906/906 [==============================] - 189s 208ms/step - loss: 1.9942 - accuracy: 0.4240 - val_loss: 1.5454 - val_accuracy: 0.5490\n",
      "Epoch 3/20\n",
      "906/906 [==============================] - 187s 206ms/step - loss: 1.5555 - accuracy: 0.5563 - val_loss: 1.2716 - val_accuracy: 0.6449\n",
      "Epoch 4/20\n",
      "906/906 [==============================] - 187s 207ms/step - loss: 1.3245 - accuracy: 0.6250 - val_loss: 1.1841 - val_accuracy: 0.6740\n",
      "Epoch 5/20\n",
      "906/906 [==============================] - 189s 208ms/step - loss: 1.1936 - accuracy: 0.6624 - val_loss: 1.1093 - val_accuracy: 0.6918\n",
      "Epoch 6/20\n",
      "906/906 [==============================] - 187s 206ms/step - loss: 1.0807 - accuracy: 0.6940 - val_loss: 1.0075 - val_accuracy: 0.7255\n",
      "Epoch 7/20\n",
      "906/906 [==============================] - 187s 206ms/step - loss: 1.0084 - accuracy: 0.7152 - val_loss: 1.0010 - val_accuracy: 0.7336\n",
      "Epoch 8/20\n",
      "906/906 [==============================] - 189s 208ms/step - loss: 0.9558 - accuracy: 0.7298 - val_loss: 0.9436 - val_accuracy: 0.7495\n",
      "Epoch 9/20\n",
      "906/906 [==============================] - 193s 213ms/step - loss: 0.9044 - accuracy: 0.7440 - val_loss: 0.9275 - val_accuracy: 0.7540\n",
      "Epoch 10/20\n",
      "906/906 [==============================] - 208s 229ms/step - loss: 0.8690 - accuracy: 0.7527 - val_loss: 0.9427 - val_accuracy: 0.7526\n",
      "Epoch 11/20\n",
      "906/906 [==============================] - 215s 237ms/step - loss: 0.8360 - accuracy: 0.7634 - val_loss: 0.9180 - val_accuracy: 0.7714\n",
      "Epoch 12/20\n",
      "906/906 [==============================] - 208s 229ms/step - loss: 0.8014 - accuracy: 0.7737 - val_loss: 0.8594 - val_accuracy: 0.7723\n",
      "Epoch 13/20\n",
      "906/906 [==============================] - 209s 231ms/step - loss: 0.7738 - accuracy: 0.7819 - val_loss: 0.8833 - val_accuracy: 0.7730\n",
      "Epoch 14/20\n",
      "906/906 [==============================] - 214s 236ms/step - loss: 0.7528 - accuracy: 0.7877 - val_loss: 0.8771 - val_accuracy: 0.7771\n",
      "Epoch 15/20\n",
      "906/906 [==============================] - 214s 236ms/step - loss: 0.7467 - accuracy: 0.7883 - val_loss: 0.9235 - val_accuracy: 0.7818\n",
      "Epoch 16/20\n",
      "906/906 [==============================] - 214s 236ms/step - loss: 0.7092 - accuracy: 0.7987 - val_loss: 0.8100 - val_accuracy: 0.7936\n",
      "Epoch 17/20\n",
      "906/906 [==============================] - 217s 239ms/step - loss: 0.6985 - accuracy: 0.8030 - val_loss: 0.8410 - val_accuracy: 0.7870\n",
      "Epoch 18/20\n",
      "906/906 [==============================] - 220s 243ms/step - loss: 0.6805 - accuracy: 0.8073 - val_loss: 0.8455 - val_accuracy: 0.7852\n",
      "Epoch 19/20\n",
      "906/906 [==============================] - 221s 244ms/step - loss: 0.6642 - accuracy: 0.8118 - val_loss: 0.8113 - val_accuracy: 0.7927\n",
      "Epoch 20/20\n",
      "906/906 [==============================] - 214s 236ms/step - loss: 0.6470 - accuracy: 0.8156 - val_loss: 0.8291 - val_accuracy: 0.7880\n",
      "Running model with 128 units, 0.2 dropout rate, 10 epochs and 32 batch size\n",
      "Epoch 1/10\n",
      "1811/1811 [==============================] - 668s 360ms/step - loss: 1.9494 - accuracy: 0.4494 - val_loss: 1.1921 - val_accuracy: 0.6574\n",
      "Epoch 2/10\n",
      "1811/1811 [==============================] - 646s 357ms/step - loss: 1.0881 - accuracy: 0.6869 - val_loss: 0.9664 - val_accuracy: 0.7254\n",
      "Epoch 3/10\n",
      "1811/1811 [==============================] - 652s 360ms/step - loss: 0.8788 - accuracy: 0.7457 - val_loss: 0.8291 - val_accuracy: 0.7677\n",
      "Epoch 4/10\n",
      "1811/1811 [==============================] - 653s 360ms/step - loss: 0.7712 - accuracy: 0.7764 - val_loss: 0.8340 - val_accuracy: 0.7627\n",
      "Epoch 5/10\n",
      "1811/1811 [==============================] - 654s 361ms/step - loss: 0.6929 - accuracy: 0.7998 - val_loss: 0.7899 - val_accuracy: 0.7798\n",
      "Epoch 6/10\n",
      " 390/1811 [=====>........................] - ETA: 7:04 - loss: 0.6014 - accuracy: 0.8266"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\deep\\Deep_Learning\\RNN\\models_lstm.ipynb Cell 6\u001b[0m in \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/deep/Deep_Learning/RNN/models_lstm.ipynb#W5sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/deep/Deep_Learning/RNN/models_lstm.ipynb#W5sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m# Train the model with your training set and validate it with your validation set\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/deep/Deep_Learning/RNN/models_lstm.ipynb#W5sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train\u001b[39m.\u001b[39;49mbatch(batch_size), epochs\u001b[39m=\u001b[39;49mepoch, validation_data\u001b[39m=\u001b[39;49mval\u001b[39m.\u001b[39;49mbatch(batch_size))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/deep/Deep_Learning/RNN/models_lstm.ipynb#W5sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m results \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((results, pd\u001b[39m.\u001b[39mDataFrame([[lstm_units, dropout_rate, epoch, batch_size, history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m], history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m], history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m], history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m]]], \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/deep/Deep_Learning/RNN/models_lstm.ipynb#W5sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m                                                 columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mlstm_units\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdropout_rate\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mloss_max\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39maccuracy_max\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mval_loss_max\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mval_accuracy_max\u001b[39m\u001b[39m'\u001b[39m])), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1642\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1643\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1644\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1648\u001b[0m ):\n\u001b[0;32m   1649\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1650\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1652\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    909\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    910\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    911\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 912\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_no_variable_creation_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    915\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m     args,\n\u001b[0;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1750\u001b[0m     executing_eagerly)\n\u001b[0;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set your model's hyperparameters\n",
    "for lstm_units in [64, 128]:\n",
    "    for dropout_rate in [0.2, 0.4]:\n",
    "            for epoch in [10, 20]:\n",
    "                  for batch_size in [32, 64]:\n",
    "                        print(f'Running model with {lstm_units} units, {dropout_rate} dropout rate, {epoch} epochs and {batch_size} batch size')\n",
    "\n",
    "                        num_classes = len(np.unique(labels))  # Number of unique classes in your dataset\n",
    "\n",
    "                        input_shape = (39, 44)\n",
    "\n",
    "                        model = Sequential([\n",
    "                            Bidirectional(LSTM(lstm_units, return_sequences=True), input_shape=input_shape),\n",
    "                            BatchNormalization(),\n",
    "                            Dropout(dropout_rate),\n",
    "                            Bidirectional(LSTM(lstm_units, return_sequences=True)),\n",
    "                            BatchNormalization(),\n",
    "                            Dropout(dropout_rate),\n",
    "                            LSTM(lstm_units, return_sequences=True),\n",
    "                            BatchNormalization(),\n",
    "                            Dropout(dropout_rate),\n",
    "                            TimeDistributed(Dense(64, activation='relu')),\n",
    "                            BatchNormalization(),\n",
    "                            Dropout(dropout_rate),\n",
    "                            TimeDistributed(Dense(32, activation='relu')),\n",
    "                            BatchNormalization(),\n",
    "                            Dropout(dropout_rate),\n",
    "                            LSTM(lstm_units),\n",
    "                            BatchNormalization(),\n",
    "                            Dropout(dropout_rate),\n",
    "                            Dense(num_classes, activation='softmax')\n",
    "                        ])\n",
    "\n",
    "\n",
    "                        # Compile the model\n",
    "                        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "                        # Train the model with your training set and validate it with your validation set\n",
    "                        history = model.fit(train.batch(batch_size), epochs=epoch, validation_data=val.batch(batch_size))\n",
    "\n",
    "                        results = np.concatenate((results, pd.DataFrame([[lstm_units, dropout_rate, epoch, batch_size, history.history['loss'][-1], history.history['loss'], history.history['accuracy'][-1], history.history['accuracy'], history.history['val_loss'][-1], history.history['val_loss'], history.history['val_accuracy'][-1], history.history['val_accuracy']]], \n",
    "                                                                        columns=['lstm_units', 'dropout_rate', 'epoch', 'batch', 'loss', 'loss_max', 'accuracy', 'accuracy_max', 'val_loss', 'val_loss_max', 'val_accuracy', 'val_accuracy_max'])), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_f = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>2.370784</td>\n",
       "      <td>[2.370784044265747]</td>\n",
       "      <td>0.333063</td>\n",
       "      <td>[0.3330628573894501]</td>\n",
       "      <td>1.522492</td>\n",
       "      <td>[1.5224920511245728]</td>\n",
       "      <td>0.5584</td>\n",
       "      <td>[0.5583995580673218]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>0.660897</td>\n",
       "      <td>[2.427072286605835, 1.4517465829849243, 1.1519...</td>\n",
       "      <td>0.807175</td>\n",
       "      <td>[0.31317439675331116, 0.581358015537262, 0.668...</td>\n",
       "      <td>0.76055</td>\n",
       "      <td>[1.5653058290481567, 1.1923205852508545, 1.008...</td>\n",
       "      <td>0.795528</td>\n",
       "      <td>[0.546190083026886, 0.655339777469635, 0.71697...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>0.600205</td>\n",
       "      <td>[2.488501787185669, 1.461273193359375, 1.12221...</td>\n",
       "      <td>0.823559</td>\n",
       "      <td>[0.30050238966941833, 0.5798560380935669, 0.67...</td>\n",
       "      <td>0.765887</td>\n",
       "      <td>[1.6190937757492065, 1.1751519441604614, 1.014...</td>\n",
       "      <td>0.790527</td>\n",
       "      <td>[0.5310385227203369, 0.6641659140586853, 0.712...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>0.459687</td>\n",
       "      <td>[2.3511674404144287, 1.395878791809082, 1.1104...</td>\n",
       "      <td>0.865408</td>\n",
       "      <td>[0.3353935480117798, 0.5998998880386353, 0.681...</td>\n",
       "      <td>0.708278</td>\n",
       "      <td>[1.5098788738250732, 1.139453411102295, 1.0019...</td>\n",
       "      <td>0.81627</td>\n",
       "      <td>[0.559723436832428, 0.6802000403404236, 0.7131...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>20</td>\n",
       "      <td>64</td>\n",
       "      <td>0.434148</td>\n",
       "      <td>[2.4646902084350586, 1.4764158725738525, 1.160...</td>\n",
       "      <td>0.870311</td>\n",
       "      <td>[0.3031783699989319, 0.5757989287376404, 0.666...</td>\n",
       "      <td>0.736218</td>\n",
       "      <td>[1.6360548734664917, 1.2466334104537964, 1.031...</td>\n",
       "      <td>0.816564</td>\n",
       "      <td>[0.5272138714790344, 0.6362165212631226, 0.707...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64</td>\n",
       "      <td>0.4</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>0.922474</td>\n",
       "      <td>[2.8702659606933594, 1.9048563241958618, 1.527...</td>\n",
       "      <td>0.74233</td>\n",
       "      <td>[0.19589799642562866, 0.4504428207874298, 0.56...</td>\n",
       "      <td>0.943816</td>\n",
       "      <td>[2.0041897296905518, 1.4960237741470337, 1.257...</td>\n",
       "      <td>0.755075</td>\n",
       "      <td>[0.41791704297065735, 0.5720800161361694, 0.64...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64</td>\n",
       "      <td>0.4</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>0.862444</td>\n",
       "      <td>[3.029785394668579, 1.9737733602523804, 1.5499...</td>\n",
       "      <td>0.757747</td>\n",
       "      <td>[0.16844776272773743, 0.4341798722743988, 0.55...</td>\n",
       "      <td>0.950969</td>\n",
       "      <td>[2.0705583095550537, 1.57509183883667, 1.30928...</td>\n",
       "      <td>0.755663</td>\n",
       "      <td>[0.38849660754203796, 0.5460429787635803, 0.62...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>64</td>\n",
       "      <td>0.4</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>0.695517</td>\n",
       "      <td>[2.872177839279175, 1.8928440809249878, 1.5408...</td>\n",
       "      <td>0.806105</td>\n",
       "      <td>[0.19755537807941437, 0.45203113555908203, 0.5...</td>\n",
       "      <td>0.809129</td>\n",
       "      <td>[1.9758355617523193, 1.4280952215194702, 1.273...</td>\n",
       "      <td>0.794793</td>\n",
       "      <td>[0.42586055397987366, 0.5837010741233826, 0.64...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>64</td>\n",
       "      <td>0.4</td>\n",
       "      <td>20</td>\n",
       "      <td>64</td>\n",
       "      <td>0.647044</td>\n",
       "      <td>[3.02612042427063, 1.9941836595535278, 1.55550...</td>\n",
       "      <td>0.815583</td>\n",
       "      <td>[0.1640971601009369, 0.42404571175575256, 0.55...</td>\n",
       "      <td>0.829114</td>\n",
       "      <td>[2.168159008026123, 1.5454410314559937, 1.2715...</td>\n",
       "      <td>0.788026</td>\n",
       "      <td>[0.3620182275772095, 0.5489850044250488, 0.644...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1   2   3         4   \\\n",
       "0  64  0.2   1  32  2.370784   \n",
       "1  64  0.2  10  32  0.660897   \n",
       "2  64  0.2  10  64  0.600205   \n",
       "3  64  0.2  20  32  0.459687   \n",
       "4  64  0.2  20  64  0.434148   \n",
       "5  64  0.4  10  32  0.922474   \n",
       "6  64  0.4  10  64  0.862444   \n",
       "7  64  0.4  20  32  0.695517   \n",
       "8  64  0.4  20  64  0.647044   \n",
       "\n",
       "                                                  5         6   \\\n",
       "0                                [2.370784044265747]  0.333063   \n",
       "1  [2.427072286605835, 1.4517465829849243, 1.1519...  0.807175   \n",
       "2  [2.488501787185669, 1.461273193359375, 1.12221...  0.823559   \n",
       "3  [2.3511674404144287, 1.395878791809082, 1.1104...  0.865408   \n",
       "4  [2.4646902084350586, 1.4764158725738525, 1.160...  0.870311   \n",
       "5  [2.8702659606933594, 1.9048563241958618, 1.527...   0.74233   \n",
       "6  [3.029785394668579, 1.9737733602523804, 1.5499...  0.757747   \n",
       "7  [2.872177839279175, 1.8928440809249878, 1.5408...  0.806105   \n",
       "8  [3.02612042427063, 1.9941836595535278, 1.55550...  0.815583   \n",
       "\n",
       "                                                  7         8   \\\n",
       "0                               [0.3330628573894501]  1.522492   \n",
       "1  [0.31317439675331116, 0.581358015537262, 0.668...   0.76055   \n",
       "2  [0.30050238966941833, 0.5798560380935669, 0.67...  0.765887   \n",
       "3  [0.3353935480117798, 0.5998998880386353, 0.681...  0.708278   \n",
       "4  [0.3031783699989319, 0.5757989287376404, 0.666...  0.736218   \n",
       "5  [0.19589799642562866, 0.4504428207874298, 0.56...  0.943816   \n",
       "6  [0.16844776272773743, 0.4341798722743988, 0.55...  0.950969   \n",
       "7  [0.19755537807941437, 0.45203113555908203, 0.5...  0.809129   \n",
       "8  [0.1640971601009369, 0.42404571175575256, 0.55...  0.829114   \n",
       "\n",
       "                                                  9         10  \\\n",
       "0                               [1.5224920511245728]    0.5584   \n",
       "1  [1.5653058290481567, 1.1923205852508545, 1.008...  0.795528   \n",
       "2  [1.6190937757492065, 1.1751519441604614, 1.014...  0.790527   \n",
       "3  [1.5098788738250732, 1.139453411102295, 1.0019...   0.81627   \n",
       "4  [1.6360548734664917, 1.2466334104537964, 1.031...  0.816564   \n",
       "5  [2.0041897296905518, 1.4960237741470337, 1.257...  0.755075   \n",
       "6  [2.0705583095550537, 1.57509183883667, 1.30928...  0.755663   \n",
       "7  [1.9758355617523193, 1.4280952215194702, 1.273...  0.794793   \n",
       "8  [2.168159008026123, 1.5454410314559937, 1.2715...  0.788026   \n",
       "\n",
       "                                                  11  \n",
       "0                               [0.5583995580673218]  \n",
       "1  [0.546190083026886, 0.655339777469635, 0.71697...  \n",
       "2  [0.5310385227203369, 0.6641659140586853, 0.712...  \n",
       "3  [0.559723436832428, 0.6802000403404236, 0.7131...  \n",
       "4  [0.5272138714790344, 0.6362165212631226, 0.707...  \n",
       "5  [0.41791704297065735, 0.5720800161361694, 0.64...  \n",
       "6  [0.38849660754203796, 0.5460429787635803, 0.62...  \n",
       "7  [0.42586055397987366, 0.5837010741233826, 0.64...  \n",
       "8  [0.3620182275772095, 0.5489850044250488, 0.644...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_f.to_pickle('results\\\\model_lstm_final_version.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "214/214 [==============================] - 24s 79ms/step - loss: 7.0679 - accuracy: 0.0974 - val_loss: 4.0350 - val_accuracy: 0.1478\n",
      "Epoch 2/10\n",
      "214/214 [==============================] - 16s 74ms/step - loss: 2.9956 - accuracy: 0.2135 - val_loss: 2.5939 - val_accuracy: 0.2307\n",
      "Epoch 3/10\n",
      "214/214 [==============================] - 16s 75ms/step - loss: 2.3891 - accuracy: 0.2976 - val_loss: 2.3668 - val_accuracy: 0.3070\n",
      "Epoch 4/10\n",
      "214/214 [==============================] - 16s 77ms/step - loss: 2.1566 - accuracy: 0.3582 - val_loss: 2.2170 - val_accuracy: 0.3557\n",
      "Epoch 5/10\n",
      "214/214 [==============================] - 16s 77ms/step - loss: 1.9021 - accuracy: 0.4253 - val_loss: 2.1590 - val_accuracy: 0.3886\n",
      "Epoch 6/10\n",
      "214/214 [==============================] - 17s 82ms/step - loss: 1.7554 - accuracy: 0.4759 - val_loss: 2.0464 - val_accuracy: 0.4235\n",
      "Epoch 7/10\n",
      "214/214 [==============================] - 17s 78ms/step - loss: 1.5497 - accuracy: 0.5342 - val_loss: 2.0235 - val_accuracy: 0.4553\n",
      "Epoch 8/10\n",
      "214/214 [==============================] - 17s 80ms/step - loss: 1.4081 - accuracy: 0.5743 - val_loss: 1.9285 - val_accuracy: 0.4707\n",
      "Epoch 9/10\n",
      "214/214 [==============================] - 16s 77ms/step - loss: 1.2639 - accuracy: 0.6206 - val_loss: 1.9814 - val_accuracy: 0.4769\n",
      "Epoch 10/10\n",
      "214/214 [==============================] - 16s 76ms/step - loss: 1.1530 - accuracy: 0.6538 - val_loss: 1.9833 - val_accuracy: 0.4921\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 19s 129ms/step - loss: 8.1597 - accuracy: 0.0670 - val_loss: 7.3030 - val_accuracy: 0.0815\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 14s 128ms/step - loss: 4.6201 - accuracy: 0.1165 - val_loss: 3.5234 - val_accuracy: 0.1293\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 14s 129ms/step - loss: 2.9787 - accuracy: 0.1899 - val_loss: 2.8644 - val_accuracy: 0.2061\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 14s 130ms/step - loss: 2.5482 - accuracy: 0.2533 - val_loss: 2.6199 - val_accuracy: 0.2454\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 14s 134ms/step - loss: 2.2535 - accuracy: 0.3261 - val_loss: 2.4200 - val_accuracy: 0.2998\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 14s 132ms/step - loss: 2.0015 - accuracy: 0.3940 - val_loss: 2.4180 - val_accuracy: 0.3503\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 13s 126ms/step - loss: 1.8026 - accuracy: 0.4549 - val_loss: 2.2331 - val_accuracy: 0.3885\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 14s 131ms/step - loss: 1.6417 - accuracy: 0.5005 - val_loss: 2.2714 - val_accuracy: 0.3973\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 14s 132ms/step - loss: 1.4811 - accuracy: 0.5469 - val_loss: 2.2330 - val_accuracy: 0.4207\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 13s 126ms/step - loss: 1.3481 - accuracy: 0.5832 - val_loss: 2.1527 - val_accuracy: 0.4328\n",
      "Epoch 1/10\n",
      "54/54 [==============================] - 20s 262ms/step - loss: 8.5656 - accuracy: 0.0683 - val_loss: 8.6474 - val_accuracy: 0.0731\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 6.7229 - accuracy: 0.1065 - val_loss: 7.3296 - val_accuracy: 0.0908\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 14s 263ms/step - loss: 4.1290 - accuracy: 0.1513 - val_loss: 4.2149 - val_accuracy: 0.1414\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 2.9740 - accuracy: 0.2066 - val_loss: 3.1875 - val_accuracy: 0.1730\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 14s 265ms/step - loss: 2.5382 - accuracy: 0.2676 - val_loss: 2.8308 - val_accuracy: 0.2193\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 14s 266ms/step - loss: 2.2748 - accuracy: 0.3197 - val_loss: 2.6625 - val_accuracy: 0.2690\n",
      "Epoch 7/10\n",
      "54/54 [==============================] - 15s 272ms/step - loss: 2.0755 - accuracy: 0.3766 - val_loss: 2.6192 - val_accuracy: 0.2854\n",
      "Epoch 8/10\n",
      "54/54 [==============================] - 15s 275ms/step - loss: 1.8885 - accuracy: 0.4215 - val_loss: 2.5402 - val_accuracy: 0.3173\n",
      "Epoch 9/10\n",
      "54/54 [==============================] - 15s 277ms/step - loss: 1.6941 - accuracy: 0.4732 - val_loss: 2.4512 - val_accuracy: 0.3578\n",
      "Epoch 10/10\n",
      "54/54 [==============================] - 15s 271ms/step - loss: 1.5866 - accuracy: 0.5096 - val_loss: 2.4329 - val_accuracy: 0.3747\n",
      "Epoch 1/20\n",
      "214/214 [==============================] - 27s 93ms/step - loss: 6.9976 - accuracy: 0.0746 - val_loss: 4.1619 - val_accuracy: 0.0987\n",
      "Epoch 2/20\n",
      "214/214 [==============================] - 19s 90ms/step - loss: 3.1049 - accuracy: 0.1567 - val_loss: 2.7697 - val_accuracy: 0.1881\n",
      "Epoch 3/20\n",
      "214/214 [==============================] - 18s 84ms/step - loss: 2.6071 - accuracy: 0.2279 - val_loss: 2.5867 - val_accuracy: 0.2411\n",
      "Epoch 4/20\n",
      "214/214 [==============================] - 18s 86ms/step - loss: 2.3011 - accuracy: 0.3121 - val_loss: 2.5347 - val_accuracy: 0.2823\n",
      "Epoch 5/20\n",
      "214/214 [==============================] - 20s 94ms/step - loss: 2.0655 - accuracy: 0.3871 - val_loss: 2.2193 - val_accuracy: 0.3538\n",
      "Epoch 6/20\n",
      "214/214 [==============================] - 24s 112ms/step - loss: 1.8670 - accuracy: 0.4420 - val_loss: 2.2733 - val_accuracy: 0.3807\n",
      "Epoch 7/20\n",
      "214/214 [==============================] - 24s 114ms/step - loss: 1.6989 - accuracy: 0.4957 - val_loss: 2.1128 - val_accuracy: 0.4209\n",
      "Epoch 8/20\n",
      "214/214 [==============================] - 25s 115ms/step - loss: 1.5359 - accuracy: 0.5435 - val_loss: 2.1348 - val_accuracy: 0.4300\n",
      "Epoch 9/20\n",
      "214/214 [==============================] - 24s 114ms/step - loss: 1.3788 - accuracy: 0.5830 - val_loss: 2.0927 - val_accuracy: 0.4416\n",
      "Epoch 10/20\n",
      "214/214 [==============================] - 24s 113ms/step - loss: 1.3009 - accuracy: 0.6102 - val_loss: 2.0433 - val_accuracy: 0.4766\n",
      "Epoch 11/20\n",
      "214/214 [==============================] - 20s 95ms/step - loss: 1.1647 - accuracy: 0.6516 - val_loss: 2.1197 - val_accuracy: 0.4819\n",
      "Epoch 12/20\n",
      "214/214 [==============================] - 23s 107ms/step - loss: 1.0269 - accuracy: 0.6882 - val_loss: 2.0099 - val_accuracy: 0.4979\n",
      "Epoch 13/20\n",
      "214/214 [==============================] - 25s 115ms/step - loss: 0.9724 - accuracy: 0.7030 - val_loss: 2.1107 - val_accuracy: 0.4932\n",
      "Epoch 14/20\n",
      "214/214 [==============================] - 26s 120ms/step - loss: 0.9154 - accuracy: 0.7150 - val_loss: 2.1318 - val_accuracy: 0.5007\n",
      "Epoch 15/20\n",
      "214/214 [==============================] - 26s 120ms/step - loss: 0.8471 - accuracy: 0.7422 - val_loss: 2.1437 - val_accuracy: 0.4943\n",
      "Epoch 16/20\n",
      "214/214 [==============================] - 25s 117ms/step - loss: 0.7899 - accuracy: 0.7563 - val_loss: 2.1848 - val_accuracy: 0.5090\n",
      "Epoch 17/20\n",
      "214/214 [==============================] - 24s 114ms/step - loss: 0.7355 - accuracy: 0.7789 - val_loss: 2.0544 - val_accuracy: 0.5199\n",
      "Epoch 18/20\n",
      "214/214 [==============================] - 24s 112ms/step - loss: 0.6723 - accuracy: 0.7879 - val_loss: 2.2667 - val_accuracy: 0.5184\n",
      "Epoch 19/20\n",
      "214/214 [==============================] - 24s 114ms/step - loss: 0.6669 - accuracy: 0.7966 - val_loss: 2.1855 - val_accuracy: 0.5394\n",
      "Epoch 20/20\n",
      "214/214 [==============================] - 24s 114ms/step - loss: 0.5972 - accuracy: 0.8094 - val_loss: 2.1903 - val_accuracy: 0.5337\n",
      "Epoch 1/20\n",
      "107/107 [==============================] - 34s 209ms/step - loss: 8.2656 - accuracy: 0.0715 - val_loss: 7.6677 - val_accuracy: 0.0830\n",
      "Epoch 2/20\n",
      "107/107 [==============================] - 15s 145ms/step - loss: 4.6485 - accuracy: 0.1437 - val_loss: 3.3839 - val_accuracy: 0.1587\n",
      "Epoch 3/20\n",
      "107/107 [==============================] - 19s 174ms/step - loss: 2.7805 - accuracy: 0.2361 - val_loss: 2.7547 - val_accuracy: 0.2376\n",
      "Epoch 4/20\n",
      "107/107 [==============================] - 26s 240ms/step - loss: 2.3154 - accuracy: 0.3137 - val_loss: 2.6240 - val_accuracy: 0.2702\n",
      "Epoch 5/20\n",
      "107/107 [==============================] - 25s 234ms/step - loss: 2.0444 - accuracy: 0.3743 - val_loss: 2.3347 - val_accuracy: 0.3219\n",
      "Epoch 6/20\n",
      "107/107 [==============================] - 26s 241ms/step - loss: 1.8619 - accuracy: 0.4341 - val_loss: 2.3996 - val_accuracy: 0.3555\n",
      "Epoch 7/20\n",
      "107/107 [==============================] - 24s 222ms/step - loss: 1.6742 - accuracy: 0.4832 - val_loss: 2.2945 - val_accuracy: 0.3786\n",
      "Epoch 8/20\n",
      "107/107 [==============================] - 26s 247ms/step - loss: 1.5153 - accuracy: 0.5314 - val_loss: 2.3106 - val_accuracy: 0.4035\n",
      "Epoch 9/20\n",
      "107/107 [==============================] - 26s 240ms/step - loss: 1.3778 - accuracy: 0.5748 - val_loss: 2.2447 - val_accuracy: 0.4294\n",
      "Epoch 10/20\n",
      "107/107 [==============================] - 27s 251ms/step - loss: 1.2629 - accuracy: 0.6067 - val_loss: 2.2621 - val_accuracy: 0.4362\n",
      "Epoch 11/20\n",
      "107/107 [==============================] - 25s 239ms/step - loss: 1.1386 - accuracy: 0.6465 - val_loss: 2.4361 - val_accuracy: 0.4344\n",
      "Epoch 12/20\n",
      "107/107 [==============================] - 25s 231ms/step - loss: 1.0243 - accuracy: 0.6772 - val_loss: 2.1989 - val_accuracy: 0.4666\n",
      "Epoch 13/20\n",
      "107/107 [==============================] - 25s 232ms/step - loss: 0.9611 - accuracy: 0.6999 - val_loss: 2.3378 - val_accuracy: 0.4594\n",
      "Epoch 14/20\n",
      "107/107 [==============================] - 22s 205ms/step - loss: 0.8740 - accuracy: 0.7270 - val_loss: 2.2546 - val_accuracy: 0.4803\n",
      "Epoch 15/20\n",
      "107/107 [==============================] - 26s 242ms/step - loss: 0.8037 - accuracy: 0.7492 - val_loss: 2.3939 - val_accuracy: 0.4741\n",
      "Epoch 16/20\n",
      "107/107 [==============================] - 25s 238ms/step - loss: 0.7143 - accuracy: 0.7740 - val_loss: 2.4012 - val_accuracy: 0.4971\n",
      "Epoch 17/20\n",
      "107/107 [==============================] - 26s 240ms/step - loss: 0.6938 - accuracy: 0.7802 - val_loss: 2.4125 - val_accuracy: 0.4854\n",
      "Epoch 18/20\n",
      "107/107 [==============================] - 25s 235ms/step - loss: 0.6484 - accuracy: 0.7895 - val_loss: 2.3975 - val_accuracy: 0.4951\n",
      "Epoch 19/20\n",
      "107/107 [==============================] - 25s 233ms/step - loss: 0.5791 - accuracy: 0.8174 - val_loss: 2.4468 - val_accuracy: 0.5016\n",
      "Epoch 20/20\n",
      "107/107 [==============================] - 25s 234ms/step - loss: 0.5732 - accuracy: 0.8140 - val_loss: 2.5099 - val_accuracy: 0.4971\n",
      "Epoch 1/20\n",
      "54/54 [==============================] - 55s 426ms/step - loss: 8.6456 - accuracy: 0.0639 - val_loss: 8.6110 - val_accuracy: 0.0934\n",
      "Epoch 2/20\n",
      "54/54 [==============================] - 18s 341ms/step - loss: 7.1500 - accuracy: 0.1527 - val_loss: 6.9634 - val_accuracy: 0.1383\n",
      "Epoch 3/20\n",
      "54/54 [==============================] - 23s 433ms/step - loss: 4.2134 - accuracy: 0.2026 - val_loss: 4.0020 - val_accuracy: 0.1826\n",
      "Epoch 4/20\n",
      "54/54 [==============================] - 26s 478ms/step - loss: 2.7190 - accuracy: 0.2824 - val_loss: 2.9305 - val_accuracy: 0.2221\n",
      "Epoch 5/20\n",
      "54/54 [==============================] - 25s 473ms/step - loss: 2.2556 - accuracy: 0.3463 - val_loss: 2.6296 - val_accuracy: 0.2852\n",
      "Epoch 6/20\n",
      "54/54 [==============================] - 22s 415ms/step - loss: 1.9787 - accuracy: 0.4056 - val_loss: 2.4977 - val_accuracy: 0.3147\n",
      "Epoch 7/20\n",
      "54/54 [==============================] - 24s 451ms/step - loss: 1.7729 - accuracy: 0.4563 - val_loss: 2.4587 - val_accuracy: 0.3582\n",
      "Epoch 8/20\n",
      "54/54 [==============================] - 24s 444ms/step - loss: 1.6062 - accuracy: 0.5163 - val_loss: 2.3804 - val_accuracy: 0.3723\n",
      "Epoch 9/20\n",
      "54/54 [==============================] - 20s 379ms/step - loss: 1.4455 - accuracy: 0.5523 - val_loss: 2.4712 - val_accuracy: 0.3909\n",
      "Epoch 10/20\n",
      "54/54 [==============================] - 20s 377ms/step - loss: 1.3261 - accuracy: 0.5915 - val_loss: 2.4856 - val_accuracy: 0.4100\n",
      "Epoch 11/20\n",
      "54/54 [==============================] - 22s 419ms/step - loss: 1.2026 - accuracy: 0.6263 - val_loss: 2.4964 - val_accuracy: 0.4148\n",
      "Epoch 12/20\n",
      "54/54 [==============================] - 23s 438ms/step - loss: 1.1190 - accuracy: 0.6582 - val_loss: 2.5527 - val_accuracy: 0.4103\n",
      "Epoch 13/20\n",
      "54/54 [==============================] - 25s 466ms/step - loss: 1.0109 - accuracy: 0.6841 - val_loss: 2.4919 - val_accuracy: 0.4401\n",
      "Epoch 14/20\n",
      "54/54 [==============================] - 21s 386ms/step - loss: 0.9556 - accuracy: 0.6990 - val_loss: 2.4979 - val_accuracy: 0.4453\n",
      "Epoch 15/20\n",
      "54/54 [==============================] - 25s 457ms/step - loss: 0.8737 - accuracy: 0.7289 - val_loss: 2.4132 - val_accuracy: 0.4618\n",
      "Epoch 16/20\n",
      "54/54 [==============================] - 25s 466ms/step - loss: 0.8092 - accuracy: 0.7454 - val_loss: 2.5038 - val_accuracy: 0.4670\n",
      "Epoch 17/20\n",
      "54/54 [==============================] - 24s 455ms/step - loss: 0.7457 - accuracy: 0.7621 - val_loss: 2.5719 - val_accuracy: 0.4648\n",
      "Epoch 18/20\n",
      "54/54 [==============================] - 25s 460ms/step - loss: 0.7130 - accuracy: 0.7741 - val_loss: 2.5424 - val_accuracy: 0.4728\n",
      "Epoch 19/20\n",
      "54/54 [==============================] - 25s 463ms/step - loss: 0.6925 - accuracy: 0.7804 - val_loss: 2.5761 - val_accuracy: 0.4779\n",
      "Epoch 20/20\n",
      "54/54 [==============================] - 25s 457ms/step - loss: 0.6198 - accuracy: 0.8045 - val_loss: 2.5163 - val_accuracy: 0.4900\n",
      "Epoch 1/30\n",
      "214/214 [==============================] - 66s 134ms/step - loss: 6.9826 - accuracy: 0.0828 - val_loss: 3.9669 - val_accuracy: 0.1340\n",
      "Epoch 2/30\n",
      "214/214 [==============================] - 21s 100ms/step - loss: 3.0718 - accuracy: 0.1678 - val_loss: 2.6871 - val_accuracy: 0.2121\n",
      "Epoch 3/30\n",
      "214/214 [==============================] - 25s 117ms/step - loss: 2.5010 - accuracy: 0.2508 - val_loss: 2.5020 - val_accuracy: 0.2727\n",
      "Epoch 4/30\n",
      "214/214 [==============================] - 27s 127ms/step - loss: 2.2247 - accuracy: 0.3343 - val_loss: 2.3381 - val_accuracy: 0.3252\n",
      "Epoch 5/30\n",
      "214/214 [==============================] - 26s 124ms/step - loss: 1.9977 - accuracy: 0.4097 - val_loss: 2.2083 - val_accuracy: 0.3678\n",
      "Epoch 6/30\n",
      "214/214 [==============================] - 25s 117ms/step - loss: 1.7954 - accuracy: 0.4644 - val_loss: 2.1485 - val_accuracy: 0.3961\n",
      "Epoch 7/30\n",
      "214/214 [==============================] - 28s 129ms/step - loss: 1.6058 - accuracy: 0.5168 - val_loss: 2.0914 - val_accuracy: 0.4251\n",
      "Epoch 8/30\n",
      "214/214 [==============================] - 27s 127ms/step - loss: 1.4673 - accuracy: 0.5555 - val_loss: 2.0391 - val_accuracy: 0.4503\n",
      "Epoch 9/30\n",
      "214/214 [==============================] - 27s 128ms/step - loss: 1.3345 - accuracy: 0.5930 - val_loss: 1.9640 - val_accuracy: 0.4653\n",
      "Epoch 10/30\n",
      "214/214 [==============================] - 27s 128ms/step - loss: 1.2026 - accuracy: 0.6369 - val_loss: 1.9732 - val_accuracy: 0.4812\n",
      "Epoch 11/30\n",
      "214/214 [==============================] - 27s 127ms/step - loss: 1.1275 - accuracy: 0.6505 - val_loss: 1.9848 - val_accuracy: 0.4926\n",
      "Epoch 12/30\n",
      "214/214 [==============================] - 25s 115ms/step - loss: 1.0156 - accuracy: 0.6939 - val_loss: 1.9866 - val_accuracy: 0.5050\n",
      "Epoch 13/30\n",
      "214/214 [==============================] - 28s 130ms/step - loss: 0.9491 - accuracy: 0.7138 - val_loss: 1.9992 - val_accuracy: 0.5046\n",
      "Epoch 14/30\n",
      "214/214 [==============================] - 28s 130ms/step - loss: 0.8727 - accuracy: 0.7393 - val_loss: 2.0771 - val_accuracy: 0.5106\n",
      "Epoch 15/30\n",
      "214/214 [==============================] - 28s 129ms/step - loss: 0.8163 - accuracy: 0.7497 - val_loss: 2.0610 - val_accuracy: 0.5199\n",
      "Epoch 16/30\n",
      "214/214 [==============================] - 28s 130ms/step - loss: 0.7585 - accuracy: 0.7745 - val_loss: 2.0668 - val_accuracy: 0.5337\n",
      "Epoch 17/30\n",
      "214/214 [==============================] - 28s 130ms/step - loss: 0.7104 - accuracy: 0.7829 - val_loss: 2.1186 - val_accuracy: 0.5306\n",
      "Epoch 18/30\n",
      "214/214 [==============================] - 28s 130ms/step - loss: 0.6489 - accuracy: 0.7985 - val_loss: 2.1550 - val_accuracy: 0.5246\n",
      "Epoch 19/30\n",
      "214/214 [==============================] - 28s 130ms/step - loss: 0.6426 - accuracy: 0.7987 - val_loss: 2.0900 - val_accuracy: 0.5437\n",
      "Epoch 20/30\n",
      "214/214 [==============================] - 25s 118ms/step - loss: 0.6031 - accuracy: 0.8143 - val_loss: 2.2478 - val_accuracy: 0.5212\n",
      "Epoch 21/30\n",
      "214/214 [==============================] - 22s 102ms/step - loss: 0.5634 - accuracy: 0.8259 - val_loss: 2.2508 - val_accuracy: 0.5365\n",
      "Epoch 22/30\n",
      "214/214 [==============================] - 22s 101ms/step - loss: 0.5289 - accuracy: 0.8320 - val_loss: 2.2618 - val_accuracy: 0.5413\n",
      "Epoch 23/30\n",
      "214/214 [==============================] - 24s 110ms/step - loss: 0.5091 - accuracy: 0.8478 - val_loss: 2.2378 - val_accuracy: 0.5349\n",
      "Epoch 24/30\n",
      "214/214 [==============================] - 24s 114ms/step - loss: 0.4909 - accuracy: 0.8497 - val_loss: 2.2624 - val_accuracy: 0.5388\n",
      "Epoch 25/30\n",
      "214/214 [==============================] - 24s 112ms/step - loss: 0.4643 - accuracy: 0.8578 - val_loss: 2.2581 - val_accuracy: 0.5480\n",
      "Epoch 26/30\n",
      "214/214 [==============================] - 24s 113ms/step - loss: 0.4388 - accuracy: 0.8639 - val_loss: 2.3735 - val_accuracy: 0.5341\n",
      "Epoch 27/30\n",
      "214/214 [==============================] - 25s 118ms/step - loss: 0.4240 - accuracy: 0.8647 - val_loss: 2.3628 - val_accuracy: 0.5449\n",
      "Epoch 28/30\n",
      "214/214 [==============================] - 25s 118ms/step - loss: 0.4198 - accuracy: 0.8714 - val_loss: 2.3963 - val_accuracy: 0.5437\n",
      "Epoch 29/30\n",
      "214/214 [==============================] - 25s 117ms/step - loss: 0.3986 - accuracy: 0.8761 - val_loss: 2.3051 - val_accuracy: 0.5468\n",
      "Epoch 30/30\n",
      "214/214 [==============================] - 24s 112ms/step - loss: 0.3866 - accuracy: 0.8784 - val_loss: 2.4636 - val_accuracy: 0.5415\n",
      "Epoch 1/30\n",
      "107/107 [==============================] - 39s 223ms/step - loss: 8.3453 - accuracy: 0.0740 - val_loss: 7.7017 - val_accuracy: 0.0986\n",
      "Epoch 2/30\n",
      "107/107 [==============================] - 21s 196ms/step - loss: 4.7049 - accuracy: 0.1463 - val_loss: 3.2921 - val_accuracy: 0.1884\n",
      "Epoch 3/30\n",
      "107/107 [==============================] - 19s 179ms/step - loss: 2.7342 - accuracy: 0.2481 - val_loss: 2.6754 - val_accuracy: 0.2487\n",
      "Epoch 4/30\n",
      "107/107 [==============================] - 21s 193ms/step - loss: 2.3025 - accuracy: 0.3147 - val_loss: 2.4794 - val_accuracy: 0.3016\n",
      "Epoch 5/30\n",
      "107/107 [==============================] - 21s 197ms/step - loss: 2.0252 - accuracy: 0.3810 - val_loss: 2.4558 - val_accuracy: 0.3248\n",
      "Epoch 6/30\n",
      "107/107 [==============================] - 21s 195ms/step - loss: 1.8434 - accuracy: 0.4379 - val_loss: 2.2914 - val_accuracy: 0.3505\n",
      "Epoch 7/30\n",
      "107/107 [==============================] - 21s 196ms/step - loss: 1.6861 - accuracy: 0.4803 - val_loss: 2.2999 - val_accuracy: 0.3860\n",
      "Epoch 8/30\n",
      "107/107 [==============================] - 21s 196ms/step - loss: 1.5082 - accuracy: 0.5260 - val_loss: 2.2567 - val_accuracy: 0.3950\n",
      "Epoch 9/30\n",
      "107/107 [==============================] - 21s 195ms/step - loss: 1.3970 - accuracy: 0.5675 - val_loss: 2.2509 - val_accuracy: 0.4331\n",
      "Epoch 10/30\n",
      "107/107 [==============================] - 21s 195ms/step - loss: 1.2794 - accuracy: 0.6007 - val_loss: 2.2319 - val_accuracy: 0.4379\n",
      "Epoch 11/30\n",
      "107/107 [==============================] - 21s 197ms/step - loss: 1.1586 - accuracy: 0.6411 - val_loss: 2.1868 - val_accuracy: 0.4507\n",
      "Epoch 12/30\n",
      "107/107 [==============================] - 21s 195ms/step - loss: 1.1014 - accuracy: 0.6575 - val_loss: 2.3151 - val_accuracy: 0.4426\n",
      "Epoch 13/30\n",
      "107/107 [==============================] - 21s 195ms/step - loss: 1.0224 - accuracy: 0.6790 - val_loss: 2.1566 - val_accuracy: 0.4732\n",
      "Epoch 14/30\n",
      "107/107 [==============================] - 21s 196ms/step - loss: 0.9432 - accuracy: 0.7119 - val_loss: 2.2165 - val_accuracy: 0.4850\n",
      "Epoch 15/30\n",
      "107/107 [==============================] - 21s 196ms/step - loss: 0.8618 - accuracy: 0.7314 - val_loss: 2.2321 - val_accuracy: 0.4806\n",
      "Epoch 16/30\n",
      "107/107 [==============================] - 21s 197ms/step - loss: 0.7902 - accuracy: 0.7517 - val_loss: 2.1818 - val_accuracy: 0.4910\n",
      "Epoch 17/30\n",
      "107/107 [==============================] - 21s 197ms/step - loss: 0.7168 - accuracy: 0.7710 - val_loss: 2.3100 - val_accuracy: 0.4959\n",
      "Epoch 18/30\n",
      "107/107 [==============================] - 19s 181ms/step - loss: 0.7075 - accuracy: 0.7759 - val_loss: 2.3535 - val_accuracy: 0.4943\n",
      "Epoch 19/30\n",
      "107/107 [==============================] - 17s 157ms/step - loss: 0.6400 - accuracy: 0.7974 - val_loss: 2.3981 - val_accuracy: 0.5099\n",
      "Epoch 20/30\n",
      "107/107 [==============================] - 17s 157ms/step - loss: 0.6184 - accuracy: 0.8061 - val_loss: 2.4101 - val_accuracy: 0.4991\n",
      "Epoch 21/30\n",
      "107/107 [==============================] - 18s 165ms/step - loss: 0.5853 - accuracy: 0.8203 - val_loss: 2.3784 - val_accuracy: 0.5040\n",
      "Epoch 22/30\n",
      "107/107 [==============================] - 19s 176ms/step - loss: 0.5469 - accuracy: 0.8279 - val_loss: 2.3915 - val_accuracy: 0.5087\n",
      "Epoch 23/30\n",
      "107/107 [==============================] - 19s 181ms/step - loss: 0.4961 - accuracy: 0.8440 - val_loss: 2.4948 - val_accuracy: 0.5079\n",
      "Epoch 24/30\n",
      "107/107 [==============================] - 20s 183ms/step - loss: 0.4969 - accuracy: 0.8449 - val_loss: 2.4717 - val_accuracy: 0.5075\n",
      "Epoch 25/30\n",
      "107/107 [==============================] - 19s 180ms/step - loss: 0.4700 - accuracy: 0.8484 - val_loss: 2.4975 - val_accuracy: 0.5091\n",
      "Epoch 26/30\n",
      "107/107 [==============================] - 18s 172ms/step - loss: 0.4308 - accuracy: 0.8641 - val_loss: 2.5310 - val_accuracy: 0.5213\n",
      "Epoch 27/30\n",
      "107/107 [==============================] - 20s 186ms/step - loss: 0.4202 - accuracy: 0.8721 - val_loss: 2.4894 - val_accuracy: 0.5269\n",
      "Epoch 28/30\n",
      "107/107 [==============================] - 20s 188ms/step - loss: 0.3865 - accuracy: 0.8775 - val_loss: 2.5426 - val_accuracy: 0.5199\n",
      "Epoch 29/30\n",
      "107/107 [==============================] - 20s 192ms/step - loss: 0.3695 - accuracy: 0.8824 - val_loss: 2.6710 - val_accuracy: 0.5222\n",
      "Epoch 30/30\n",
      "107/107 [==============================] - 20s 191ms/step - loss: 0.3905 - accuracy: 0.8745 - val_loss: 2.5133 - val_accuracy: 0.5252\n",
      "Epoch 1/30\n",
      "54/54 [==============================] - 57s 545ms/step - loss: 8.6000 - accuracy: 0.0653 - val_loss: 8.5139 - val_accuracy: 0.0800\n",
      "Epoch 2/30\n",
      "54/54 [==============================] - 25s 462ms/step - loss: 6.9185 - accuracy: 0.1042 - val_loss: 6.8641 - val_accuracy: 0.0803\n",
      "Epoch 3/30\n",
      "54/54 [==============================] - 26s 476ms/step - loss: 4.2049 - accuracy: 0.1479 - val_loss: 4.2247 - val_accuracy: 0.1439\n",
      "Epoch 4/30\n",
      "54/54 [==============================] - 25s 458ms/step - loss: 2.9353 - accuracy: 0.2257 - val_loss: 3.1953 - val_accuracy: 0.1968\n",
      "Epoch 5/30\n",
      "54/54 [==============================] - 23s 429ms/step - loss: 2.4678 - accuracy: 0.2793 - val_loss: 2.8471 - val_accuracy: 0.2277\n",
      "Epoch 6/30\n",
      "54/54 [==============================] - 26s 489ms/step - loss: 2.2068 - accuracy: 0.3377 - val_loss: 2.6838 - val_accuracy: 0.2743\n",
      "Epoch 7/30\n",
      "54/54 [==============================] - 25s 470ms/step - loss: 2.0042 - accuracy: 0.3810 - val_loss: 2.6446 - val_accuracy: 0.2966\n",
      "Epoch 8/30\n",
      "54/54 [==============================] - 25s 466ms/step - loss: 1.8553 - accuracy: 0.4183 - val_loss: 2.6893 - val_accuracy: 0.3107\n",
      "Epoch 9/30\n",
      "54/54 [==============================] - 25s 471ms/step - loss: 1.6917 - accuracy: 0.4718 - val_loss: 2.5973 - val_accuracy: 0.3463\n",
      "Epoch 10/30\n",
      "54/54 [==============================] - 25s 465ms/step - loss: 1.5808 - accuracy: 0.5008 - val_loss: 2.5229 - val_accuracy: 0.3695\n",
      "Epoch 11/30\n",
      "54/54 [==============================] - 25s 468ms/step - loss: 1.4383 - accuracy: 0.5393 - val_loss: 2.5869 - val_accuracy: 0.3828\n",
      "Epoch 12/30\n",
      "54/54 [==============================] - 25s 468ms/step - loss: 1.3311 - accuracy: 0.5791 - val_loss: 2.6017 - val_accuracy: 0.4029\n",
      "Epoch 13/30\n",
      "54/54 [==============================] - 25s 463ms/step - loss: 1.2569 - accuracy: 0.6013 - val_loss: 2.6120 - val_accuracy: 0.3995\n",
      "Epoch 14/30\n",
      "54/54 [==============================] - 25s 465ms/step - loss: 1.1607 - accuracy: 0.6320 - val_loss: 2.4814 - val_accuracy: 0.4303\n",
      "Epoch 15/30\n",
      "54/54 [==============================] - 25s 465ms/step - loss: 1.0460 - accuracy: 0.6723 - val_loss: 2.5817 - val_accuracy: 0.4313\n",
      "Epoch 16/30\n",
      "54/54 [==============================] - 26s 493ms/step - loss: 0.9650 - accuracy: 0.6911 - val_loss: 2.6625 - val_accuracy: 0.4404\n",
      "Epoch 17/30\n",
      "54/54 [==============================] - 23s 430ms/step - loss: 0.9062 - accuracy: 0.7140 - val_loss: 2.5529 - val_accuracy: 0.4478\n",
      "Epoch 18/30\n",
      "54/54 [==============================] - 23s 433ms/step - loss: 0.8499 - accuracy: 0.7258 - val_loss: 2.6545 - val_accuracy: 0.4463\n",
      "Epoch 19/30\n",
      "54/54 [==============================] - 26s 489ms/step - loss: 0.7782 - accuracy: 0.7560 - val_loss: 2.7783 - val_accuracy: 0.4453\n",
      "Epoch 20/30\n",
      "54/54 [==============================] - 27s 501ms/step - loss: 0.7489 - accuracy: 0.7620 - val_loss: 2.6383 - val_accuracy: 0.4659\n",
      "Epoch 21/30\n",
      "54/54 [==============================] - 25s 457ms/step - loss: 0.6995 - accuracy: 0.7827 - val_loss: 2.6686 - val_accuracy: 0.4597\n",
      "Epoch 22/30\n",
      "54/54 [==============================] - 26s 490ms/step - loss: 0.6614 - accuracy: 0.7874 - val_loss: 2.6569 - val_accuracy: 0.4706\n",
      "Epoch 23/30\n",
      "54/54 [==============================] - 27s 494ms/step - loss: 0.6012 - accuracy: 0.8097 - val_loss: 2.7619 - val_accuracy: 0.4729\n",
      "Epoch 24/30\n",
      "54/54 [==============================] - 26s 490ms/step - loss: 0.5723 - accuracy: 0.8165 - val_loss: 2.8144 - val_accuracy: 0.4698\n",
      "Epoch 25/30\n",
      "54/54 [==============================] - 26s 488ms/step - loss: 0.5361 - accuracy: 0.8348 - val_loss: 2.7737 - val_accuracy: 0.4772\n",
      "Epoch 26/30\n",
      "54/54 [==============================] - 26s 489ms/step - loss: 0.5038 - accuracy: 0.8416 - val_loss: 2.8504 - val_accuracy: 0.4645\n",
      "Epoch 27/30\n",
      "54/54 [==============================] - 26s 481ms/step - loss: 0.5003 - accuracy: 0.8398 - val_loss: 2.8314 - val_accuracy: 0.4744\n",
      "Epoch 28/30\n",
      "54/54 [==============================] - 21s 398ms/step - loss: 0.4504 - accuracy: 0.8590 - val_loss: 2.8946 - val_accuracy: 0.4701\n",
      "Epoch 29/30\n",
      "54/54 [==============================] - 26s 487ms/step - loss: 0.4290 - accuracy: 0.8639 - val_loss: 2.8793 - val_accuracy: 0.4800\n",
      "Epoch 30/30\n",
      "54/54 [==============================] - 25s 474ms/step - loss: 0.4099 - accuracy: 0.8723 - val_loss: 2.9370 - val_accuracy: 0.4875\n",
      "Epoch 1/40\n",
      "214/214 [==============================] - 52s 152ms/step - loss: 7.0045 - accuracy: 0.0721 - val_loss: 4.4580 - val_accuracy: 0.0897\n",
      "Epoch 2/40\n",
      "214/214 [==============================] - 29s 134ms/step - loss: 3.2134 - accuracy: 0.1399 - val_loss: 2.9023 - val_accuracy: 0.1447\n",
      "Epoch 3/40\n",
      "214/214 [==============================] - 28s 133ms/step - loss: 2.6479 - accuracy: 0.2224 - val_loss: 2.5579 - val_accuracy: 0.2538\n",
      "Epoch 4/40\n",
      "214/214 [==============================] - 28s 133ms/step - loss: 2.3200 - accuracy: 0.3093 - val_loss: 2.4693 - val_accuracy: 0.3010\n",
      "Epoch 5/40\n",
      "214/214 [==============================] - 29s 134ms/step - loss: 2.0898 - accuracy: 0.3778 - val_loss: 2.2810 - val_accuracy: 0.3514\n",
      "Epoch 6/40\n",
      "214/214 [==============================] - 27s 125ms/step - loss: 1.9031 - accuracy: 0.4281 - val_loss: 2.1675 - val_accuracy: 0.3866\n",
      "Epoch 7/40\n",
      "214/214 [==============================] - 28s 129ms/step - loss: 1.7047 - accuracy: 0.4911 - val_loss: 2.1804 - val_accuracy: 0.4073\n",
      "Epoch 8/40\n",
      "214/214 [==============================] - 27s 128ms/step - loss: 1.5170 - accuracy: 0.5421 - val_loss: 2.0845 - val_accuracy: 0.4401\n",
      "Epoch 9/40\n",
      "214/214 [==============================] - 28s 129ms/step - loss: 1.3884 - accuracy: 0.5873 - val_loss: 2.0870 - val_accuracy: 0.4448\n",
      "Epoch 10/40\n",
      "214/214 [==============================] - 26s 123ms/step - loss: 1.2593 - accuracy: 0.6260 - val_loss: 2.0269 - val_accuracy: 0.4679\n",
      "Epoch 11/40\n",
      "214/214 [==============================] - 26s 122ms/step - loss: 1.1328 - accuracy: 0.6547 - val_loss: 2.0572 - val_accuracy: 0.4762\n",
      "Epoch 12/40\n",
      "214/214 [==============================] - 26s 123ms/step - loss: 1.0469 - accuracy: 0.6780 - val_loss: 1.9063 - val_accuracy: 0.5110\n",
      "Epoch 13/40\n",
      "214/214 [==============================] - 26s 124ms/step - loss: 0.9516 - accuracy: 0.7121 - val_loss: 2.0205 - val_accuracy: 0.5137\n",
      "Epoch 14/40\n",
      "214/214 [==============================] - 26s 124ms/step - loss: 0.8729 - accuracy: 0.7317 - val_loss: 1.9865 - val_accuracy: 0.5204\n",
      "Epoch 15/40\n",
      "214/214 [==============================] - 27s 124ms/step - loss: 0.8204 - accuracy: 0.7517 - val_loss: 2.0457 - val_accuracy: 0.5213\n",
      "Epoch 16/40\n",
      "214/214 [==============================] - 26s 123ms/step - loss: 0.7669 - accuracy: 0.7677 - val_loss: 2.0592 - val_accuracy: 0.5324\n",
      "Epoch 17/40\n",
      "214/214 [==============================] - 26s 123ms/step - loss: 0.6986 - accuracy: 0.7833 - val_loss: 2.0364 - val_accuracy: 0.5325\n",
      "Epoch 18/40\n",
      "214/214 [==============================] - 25s 118ms/step - loss: 0.6583 - accuracy: 0.7960 - val_loss: 2.1536 - val_accuracy: 0.5281\n",
      "Epoch 19/40\n",
      "214/214 [==============================] - 25s 115ms/step - loss: 0.6419 - accuracy: 0.8013 - val_loss: 2.0430 - val_accuracy: 0.5471\n",
      "Epoch 20/40\n",
      "214/214 [==============================] - 26s 121ms/step - loss: 0.6027 - accuracy: 0.8143 - val_loss: 2.1327 - val_accuracy: 0.5422\n",
      "Epoch 21/40\n",
      "214/214 [==============================] - 25s 119ms/step - loss: 0.5614 - accuracy: 0.8294 - val_loss: 2.0837 - val_accuracy: 0.5472\n",
      "Epoch 22/40\n",
      "214/214 [==============================] - 27s 125ms/step - loss: 0.5021 - accuracy: 0.8432 - val_loss: 2.1961 - val_accuracy: 0.5393\n",
      "Epoch 23/40\n",
      "214/214 [==============================] - 27s 124ms/step - loss: 0.4929 - accuracy: 0.8470 - val_loss: 2.1795 - val_accuracy: 0.5508\n",
      "Epoch 24/40\n",
      "214/214 [==============================] - 26s 124ms/step - loss: 0.4901 - accuracy: 0.8499 - val_loss: 2.2802 - val_accuracy: 0.5290\n",
      "Epoch 25/40\n",
      "214/214 [==============================] - 27s 125ms/step - loss: 0.4529 - accuracy: 0.8587 - val_loss: 2.2117 - val_accuracy: 0.5560\n",
      "Epoch 26/40\n",
      "214/214 [==============================] - 27s 125ms/step - loss: 0.4331 - accuracy: 0.8623 - val_loss: 2.2687 - val_accuracy: 0.5410\n",
      "Epoch 27/40\n",
      "214/214 [==============================] - 27s 125ms/step - loss: 0.4084 - accuracy: 0.8729 - val_loss: 2.3097 - val_accuracy: 0.5538\n",
      "Epoch 28/40\n",
      "214/214 [==============================] - 26s 124ms/step - loss: 0.3838 - accuracy: 0.8784 - val_loss: 2.3765 - val_accuracy: 0.5549\n",
      "Epoch 29/40\n",
      "214/214 [==============================] - 26s 124ms/step - loss: 0.3904 - accuracy: 0.8799 - val_loss: 2.3722 - val_accuracy: 0.5478\n",
      "Epoch 30/40\n",
      "214/214 [==============================] - 26s 124ms/step - loss: 0.3641 - accuracy: 0.8890 - val_loss: 2.3883 - val_accuracy: 0.5584\n",
      "Epoch 31/40\n",
      "214/214 [==============================] - 26s 123ms/step - loss: 0.3492 - accuracy: 0.8900 - val_loss: 2.3630 - val_accuracy: 0.5588\n",
      "Epoch 32/40\n",
      "214/214 [==============================] - 26s 124ms/step - loss: 0.3376 - accuracy: 0.8966 - val_loss: 2.5140 - val_accuracy: 0.5469\n",
      "Epoch 33/40\n",
      "214/214 [==============================] - 27s 125ms/step - loss: 0.3344 - accuracy: 0.8941 - val_loss: 2.4068 - val_accuracy: 0.5606\n",
      "Epoch 34/40\n",
      "214/214 [==============================] - 27s 125ms/step - loss: 0.3063 - accuracy: 0.9081 - val_loss: 2.4792 - val_accuracy: 0.5512\n",
      "Epoch 35/40\n",
      "214/214 [==============================] - 27s 125ms/step - loss: 0.3366 - accuracy: 0.8971 - val_loss: 2.4066 - val_accuracy: 0.5616\n",
      "Epoch 36/40\n",
      "214/214 [==============================] - 26s 124ms/step - loss: 0.3187 - accuracy: 0.8969 - val_loss: 2.4859 - val_accuracy: 0.5491\n",
      "Epoch 37/40\n",
      "214/214 [==============================] - 28s 129ms/step - loss: 0.3111 - accuracy: 0.9061 - val_loss: 2.4642 - val_accuracy: 0.5543\n",
      "Epoch 38/40\n",
      "214/214 [==============================] - 27s 129ms/step - loss: 0.2938 - accuracy: 0.9113 - val_loss: 2.4591 - val_accuracy: 0.5618\n",
      "Epoch 39/40\n",
      "214/214 [==============================] - 27s 128ms/step - loss: 0.2939 - accuracy: 0.9103 - val_loss: 2.4820 - val_accuracy: 0.5500\n",
      "Epoch 40/40\n",
      "214/214 [==============================] - 26s 122ms/step - loss: 0.2717 - accuracy: 0.9143 - val_loss: 2.4574 - val_accuracy: 0.5637\n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 39s 221ms/step - loss: 8.1101 - accuracy: 0.0730 - val_loss: 7.3631 - val_accuracy: 0.0696\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 20s 190ms/step - loss: 4.3463 - accuracy: 0.1058 - val_loss: 3.3794 - val_accuracy: 0.1078\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 20s 190ms/step - loss: 2.9421 - accuracy: 0.1718 - val_loss: 2.8435 - val_accuracy: 0.1826\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 21s 193ms/step - loss: 2.5287 - accuracy: 0.2417 - val_loss: 2.6736 - val_accuracy: 0.2490\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 20s 190ms/step - loss: 2.2691 - accuracy: 0.3086 - val_loss: 2.5411 - val_accuracy: 0.2886\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 20s 190ms/step - loss: 2.0325 - accuracy: 0.3827 - val_loss: 2.6083 - val_accuracy: 0.3164\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 21s 192ms/step - loss: 1.8455 - accuracy: 0.4325 - val_loss: 2.3357 - val_accuracy: 0.3697\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 21s 193ms/step - loss: 1.6583 - accuracy: 0.4936 - val_loss: 2.3443 - val_accuracy: 0.3988\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 20s 189ms/step - loss: 1.5019 - accuracy: 0.5387 - val_loss: 2.2455 - val_accuracy: 0.4163\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 20s 192ms/step - loss: 1.3425 - accuracy: 0.5906 - val_loss: 2.2073 - val_accuracy: 0.4525\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 20s 189ms/step - loss: 1.2004 - accuracy: 0.6348 - val_loss: 2.1328 - val_accuracy: 0.4707\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 20s 183ms/step - loss: 1.1044 - accuracy: 0.6585 - val_loss: 2.2541 - val_accuracy: 0.4703\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 21s 197ms/step - loss: 1.0044 - accuracy: 0.6916 - val_loss: 2.2206 - val_accuracy: 0.4823\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 21s 195ms/step - loss: 0.9197 - accuracy: 0.7122 - val_loss: 2.2111 - val_accuracy: 0.4934\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 21s 194ms/step - loss: 0.8547 - accuracy: 0.7324 - val_loss: 2.2208 - val_accuracy: 0.5091\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 19s 177ms/step - loss: 0.7866 - accuracy: 0.7536 - val_loss: 2.1739 - val_accuracy: 0.5076\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 20s 189ms/step - loss: 0.7192 - accuracy: 0.7823 - val_loss: 2.2276 - val_accuracy: 0.5131\n",
      "Epoch 18/40\n",
      "107/107 [==============================] - 21s 196ms/step - loss: 0.6609 - accuracy: 0.7988 - val_loss: 2.2888 - val_accuracy: 0.5152\n",
      "Epoch 19/40\n",
      "107/107 [==============================] - 22s 204ms/step - loss: 0.5806 - accuracy: 0.8238 - val_loss: 2.2652 - val_accuracy: 0.5207\n",
      "Epoch 20/40\n",
      "107/107 [==============================] - 22s 205ms/step - loss: 0.5737 - accuracy: 0.8195 - val_loss: 2.2932 - val_accuracy: 0.5231\n",
      "Epoch 21/40\n",
      "107/107 [==============================] - 22s 203ms/step - loss: 0.5137 - accuracy: 0.8399 - val_loss: 2.4048 - val_accuracy: 0.5284\n",
      "Epoch 22/40\n",
      "107/107 [==============================] - 22s 202ms/step - loss: 0.5012 - accuracy: 0.8375 - val_loss: 2.4872 - val_accuracy: 0.5162\n",
      "Epoch 23/40\n",
      "107/107 [==============================] - 22s 202ms/step - loss: 0.4879 - accuracy: 0.8475 - val_loss: 2.5416 - val_accuracy: 0.5122\n",
      "Epoch 24/40\n",
      "107/107 [==============================] - 22s 203ms/step - loss: 0.4535 - accuracy: 0.8594 - val_loss: 2.4780 - val_accuracy: 0.5349\n",
      "Epoch 25/40\n",
      "107/107 [==============================] - 22s 206ms/step - loss: 0.4062 - accuracy: 0.8736 - val_loss: 2.5003 - val_accuracy: 0.5412\n",
      "Epoch 26/40\n",
      "107/107 [==============================] - 22s 203ms/step - loss: 0.3922 - accuracy: 0.8743 - val_loss: 2.3961 - val_accuracy: 0.5496\n",
      "Epoch 27/40\n",
      "107/107 [==============================] - 22s 202ms/step - loss: 0.3668 - accuracy: 0.8862 - val_loss: 2.5685 - val_accuracy: 0.5384\n",
      "Epoch 28/40\n",
      "107/107 [==============================] - 21s 198ms/step - loss: 0.3709 - accuracy: 0.8841 - val_loss: 2.4955 - val_accuracy: 0.5437\n",
      "Epoch 29/40\n",
      "107/107 [==============================] - 18s 172ms/step - loss: 0.3605 - accuracy: 0.8834 - val_loss: 2.5001 - val_accuracy: 0.5466\n",
      "Epoch 30/40\n",
      "107/107 [==============================] - 22s 203ms/step - loss: 0.3303 - accuracy: 0.8979 - val_loss: 2.5527 - val_accuracy: 0.5432\n",
      "Epoch 31/40\n",
      "107/107 [==============================] - 22s 209ms/step - loss: 0.3194 - accuracy: 0.8990 - val_loss: 2.6526 - val_accuracy: 0.5453\n",
      "Epoch 32/40\n",
      "107/107 [==============================] - 23s 220ms/step - loss: 0.3209 - accuracy: 0.8993 - val_loss: 2.5957 - val_accuracy: 0.5462\n",
      "Epoch 33/40\n",
      "107/107 [==============================] - 22s 204ms/step - loss: 0.2688 - accuracy: 0.9138 - val_loss: 2.6393 - val_accuracy: 0.5563\n",
      "Epoch 34/40\n",
      "107/107 [==============================] - 22s 207ms/step - loss: 0.2836 - accuracy: 0.9108 - val_loss: 2.6078 - val_accuracy: 0.5574\n",
      "Epoch 35/40\n",
      "107/107 [==============================] - 22s 207ms/step - loss: 0.2945 - accuracy: 0.9069 - val_loss: 2.6321 - val_accuracy: 0.5572\n",
      "Epoch 36/40\n",
      "107/107 [==============================] - 22s 209ms/step - loss: 0.2716 - accuracy: 0.9147 - val_loss: 2.5583 - val_accuracy: 0.5585\n",
      "Epoch 37/40\n",
      "107/107 [==============================] - 22s 208ms/step - loss: 0.2710 - accuracy: 0.9170 - val_loss: 2.6659 - val_accuracy: 0.5556\n",
      "Epoch 38/40\n",
      "107/107 [==============================] - 22s 208ms/step - loss: 0.2691 - accuracy: 0.9169 - val_loss: 2.6323 - val_accuracy: 0.5609\n",
      "Epoch 39/40\n",
      "107/107 [==============================] - 22s 208ms/step - loss: 0.2584 - accuracy: 0.9207 - val_loss: 2.6464 - val_accuracy: 0.5588\n",
      "Epoch 40/40\n",
      "107/107 [==============================] - 22s 207ms/step - loss: 0.2541 - accuracy: 0.9217 - val_loss: 2.6807 - val_accuracy: 0.5571\n",
      "Epoch 1/40\n",
      "54/54 [==============================] - 54s 633ms/step - loss: 8.6099 - accuracy: 0.0672 - val_loss: 8.5755 - val_accuracy: 0.0799\n",
      "Epoch 2/40\n",
      "54/54 [==============================] - 30s 564ms/step - loss: 6.9844 - accuracy: 0.1378 - val_loss: 6.8394 - val_accuracy: 0.1000\n",
      "Epoch 3/40\n",
      "54/54 [==============================] - 31s 586ms/step - loss: 4.1859 - accuracy: 0.1849 - val_loss: 4.4733 - val_accuracy: 0.1852\n",
      "Epoch 4/40\n",
      "54/54 [==============================] - 32s 587ms/step - loss: 2.8578 - accuracy: 0.2634 - val_loss: 3.0402 - val_accuracy: 0.2446\n",
      "Epoch 5/40\n",
      "54/54 [==============================] - 31s 579ms/step - loss: 2.3511 - accuracy: 0.3298 - val_loss: 2.7035 - val_accuracy: 0.2758\n",
      "Epoch 6/40\n",
      "54/54 [==============================] - 31s 586ms/step - loss: 2.0767 - accuracy: 0.3792 - val_loss: 2.5960 - val_accuracy: 0.3054\n",
      "Epoch 7/40\n",
      "54/54 [==============================] - 29s 543ms/step - loss: 1.8747 - accuracy: 0.4338 - val_loss: 2.5048 - val_accuracy: 0.3255\n",
      "Epoch 8/40\n",
      "54/54 [==============================] - 29s 540ms/step - loss: 1.6719 - accuracy: 0.4925 - val_loss: 2.4216 - val_accuracy: 0.3498\n",
      "Epoch 9/40\n",
      "54/54 [==============================] - 31s 575ms/step - loss: 1.5362 - accuracy: 0.5261 - val_loss: 2.4009 - val_accuracy: 0.3747\n",
      "Epoch 10/40\n",
      "54/54 [==============================] - 30s 556ms/step - loss: 1.3958 - accuracy: 0.5681 - val_loss: 2.4716 - val_accuracy: 0.3839\n",
      "Epoch 11/40\n",
      "54/54 [==============================] - 29s 542ms/step - loss: 1.2759 - accuracy: 0.6006 - val_loss: 2.4889 - val_accuracy: 0.3941\n",
      "Epoch 12/40\n",
      "54/54 [==============================] - 29s 544ms/step - loss: 1.1798 - accuracy: 0.6225 - val_loss: 2.4244 - val_accuracy: 0.4163\n",
      "Epoch 13/40\n",
      "54/54 [==============================] - 29s 538ms/step - loss: 1.1003 - accuracy: 0.6578 - val_loss: 2.4985 - val_accuracy: 0.4187\n",
      "Epoch 14/40\n",
      "54/54 [==============================] - 29s 547ms/step - loss: 0.9831 - accuracy: 0.6909 - val_loss: 2.5226 - val_accuracy: 0.4241\n",
      "Epoch 15/40\n",
      "54/54 [==============================] - 29s 539ms/step - loss: 0.9311 - accuracy: 0.7102 - val_loss: 2.6199 - val_accuracy: 0.4298\n",
      "Epoch 16/40\n",
      "54/54 [==============================] - 29s 542ms/step - loss: 0.8553 - accuracy: 0.7270 - val_loss: 2.5805 - val_accuracy: 0.4467\n",
      "Epoch 17/40\n",
      "54/54 [==============================] - 29s 531ms/step - loss: 0.7817 - accuracy: 0.7526 - val_loss: 2.6472 - val_accuracy: 0.4470\n",
      "Epoch 18/40\n",
      "54/54 [==============================] - 27s 511ms/step - loss: 0.7459 - accuracy: 0.7640 - val_loss: 2.7239 - val_accuracy: 0.4432\n",
      "Epoch 19/40\n",
      "54/54 [==============================] - 28s 529ms/step - loss: 0.6934 - accuracy: 0.7810 - val_loss: 2.7375 - val_accuracy: 0.4467\n",
      "Epoch 20/40\n",
      "54/54 [==============================] - 28s 526ms/step - loss: 0.6584 - accuracy: 0.7860 - val_loss: 2.7017 - val_accuracy: 0.4540\n",
      "Epoch 21/40\n",
      "54/54 [==============================] - 28s 521ms/step - loss: 0.5802 - accuracy: 0.8165 - val_loss: 2.7249 - val_accuracy: 0.4609\n",
      "Epoch 22/40\n",
      "54/54 [==============================] - 28s 523ms/step - loss: 0.5644 - accuracy: 0.8260 - val_loss: 2.7149 - val_accuracy: 0.4656\n",
      "Epoch 23/40\n",
      "54/54 [==============================] - 28s 528ms/step - loss: 0.5345 - accuracy: 0.8294 - val_loss: 2.7771 - val_accuracy: 0.4676\n",
      "Epoch 24/40\n",
      "54/54 [==============================] - 28s 518ms/step - loss: 0.4867 - accuracy: 0.8484 - val_loss: 2.8553 - val_accuracy: 0.4634\n",
      "Epoch 25/40\n",
      "54/54 [==============================] - 28s 524ms/step - loss: 0.4853 - accuracy: 0.8465 - val_loss: 2.8528 - val_accuracy: 0.4613\n",
      "Epoch 26/40\n",
      "54/54 [==============================] - 29s 532ms/step - loss: 0.4487 - accuracy: 0.8604 - val_loss: 2.9354 - val_accuracy: 0.4644\n",
      "Epoch 27/40\n",
      "54/54 [==============================] - 28s 528ms/step - loss: 0.4381 - accuracy: 0.8607 - val_loss: 2.8385 - val_accuracy: 0.4853\n",
      "Epoch 28/40\n",
      "54/54 [==============================] - 29s 537ms/step - loss: 0.3963 - accuracy: 0.8758 - val_loss: 2.9180 - val_accuracy: 0.4719\n",
      "Epoch 29/40\n",
      "54/54 [==============================] - 29s 530ms/step - loss: 0.3589 - accuracy: 0.8854 - val_loss: 2.9197 - val_accuracy: 0.4743\n",
      "Epoch 30/40\n",
      "54/54 [==============================] - 28s 520ms/step - loss: 0.3198 - accuracy: 0.8969 - val_loss: 2.9714 - val_accuracy: 0.4907\n",
      "Epoch 31/40\n",
      "54/54 [==============================] - 24s 450ms/step - loss: 0.3018 - accuracy: 0.9026 - val_loss: 3.0530 - val_accuracy: 0.4719\n",
      "Epoch 32/40\n",
      "54/54 [==============================] - 27s 498ms/step - loss: 0.3181 - accuracy: 0.9008 - val_loss: 2.9962 - val_accuracy: 0.4860\n",
      "Epoch 33/40\n",
      "54/54 [==============================] - 26s 490ms/step - loss: 0.2791 - accuracy: 0.9058 - val_loss: 3.1521 - val_accuracy: 0.4788\n",
      "Epoch 34/40\n",
      "54/54 [==============================] - 26s 493ms/step - loss: 0.3098 - accuracy: 0.9036 - val_loss: 3.0910 - val_accuracy: 0.4765\n",
      "Epoch 35/40\n",
      "54/54 [==============================] - 27s 496ms/step - loss: 0.2725 - accuracy: 0.9129 - val_loss: 3.1698 - val_accuracy: 0.4779\n",
      "Epoch 36/40\n",
      "54/54 [==============================] - 26s 485ms/step - loss: 0.2602 - accuracy: 0.9157 - val_loss: 3.1503 - val_accuracy: 0.4835\n",
      "Epoch 37/40\n",
      "54/54 [==============================] - 26s 483ms/step - loss: 0.2488 - accuracy: 0.9210 - val_loss: 3.1816 - val_accuracy: 0.4854\n",
      "Epoch 38/40\n",
      "54/54 [==============================] - 27s 506ms/step - loss: 0.2451 - accuracy: 0.9230 - val_loss: 3.2076 - val_accuracy: 0.4773\n",
      "Epoch 39/40\n",
      "54/54 [==============================] - 27s 509ms/step - loss: 0.2430 - accuracy: 0.9229 - val_loss: 3.2791 - val_accuracy: 0.4748\n",
      "Epoch 40/40\n",
      "54/54 [==============================] - 27s 505ms/step - loss: 0.2465 - accuracy: 0.9225 - val_loss: 3.2241 - val_accuracy: 0.4779\n",
      "Epoch 1/10\n",
      "214/214 [==============================] - 44s 148ms/step - loss: 7.8680 - accuracy: 0.0534 - val_loss: 5.6668 - val_accuracy: 0.0834\n",
      "Epoch 2/10\n",
      "214/214 [==============================] - 29s 135ms/step - loss: 3.6989 - accuracy: 0.1083 - val_loss: 3.0112 - val_accuracy: 0.1353\n",
      "Epoch 3/10\n",
      "214/214 [==============================] - 28s 133ms/step - loss: 2.9258 - accuracy: 0.1680 - val_loss: 2.7772 - val_accuracy: 0.1887\n",
      "Epoch 4/10\n",
      "214/214 [==============================] - 27s 127ms/step - loss: 2.7022 - accuracy: 0.2089 - val_loss: 2.6443 - val_accuracy: 0.2348\n",
      "Epoch 5/10\n",
      "214/214 [==============================] - 29s 137ms/step - loss: 2.5217 - accuracy: 0.2562 - val_loss: 2.5110 - val_accuracy: 0.2741\n",
      "Epoch 6/10\n",
      "214/214 [==============================] - 29s 136ms/step - loss: 2.3621 - accuracy: 0.2970 - val_loss: 2.4631 - val_accuracy: 0.2946\n",
      "Epoch 7/10\n",
      "214/214 [==============================] - 29s 136ms/step - loss: 2.2015 - accuracy: 0.3482 - val_loss: 2.2829 - val_accuracy: 0.3304\n",
      "Epoch 8/10\n",
      "214/214 [==============================] - 29s 136ms/step - loss: 2.0899 - accuracy: 0.3723 - val_loss: 2.2851 - val_accuracy: 0.3450\n",
      "Epoch 9/10\n",
      "214/214 [==============================] - 29s 136ms/step - loss: 1.9558 - accuracy: 0.4072 - val_loss: 2.2088 - val_accuracy: 0.3795\n",
      "Epoch 10/10\n",
      "214/214 [==============================] - 29s 137ms/step - loss: 1.8711 - accuracy: 0.4345 - val_loss: 2.1354 - val_accuracy: 0.4003\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 40s 225ms/step - loss: 8.4644 - accuracy: 0.0553 - val_loss: 8.1622 - val_accuracy: 0.0659\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 21s 201ms/step - loss: 5.4241 - accuracy: 0.0892 - val_loss: 3.8925 - val_accuracy: 0.1015\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 22s 202ms/step - loss: 3.3830 - accuracy: 0.1263 - val_loss: 3.0327 - val_accuracy: 0.1370\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 22s 202ms/step - loss: 2.9376 - accuracy: 0.1583 - val_loss: 2.8164 - val_accuracy: 0.1673\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 22s 202ms/step - loss: 2.7270 - accuracy: 0.1895 - val_loss: 2.6892 - val_accuracy: 0.2001\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 21s 201ms/step - loss: 2.5589 - accuracy: 0.2257 - val_loss: 2.6244 - val_accuracy: 0.2362\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 22s 206ms/step - loss: 2.4193 - accuracy: 0.2634 - val_loss: 2.5723 - val_accuracy: 0.2676\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 21s 192ms/step - loss: 2.3156 - accuracy: 0.2942 - val_loss: 2.5042 - val_accuracy: 0.2733\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 22s 205ms/step - loss: 2.1696 - accuracy: 0.3366 - val_loss: 2.5227 - val_accuracy: 0.3030\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 22s 208ms/step - loss: 2.0472 - accuracy: 0.3656 - val_loss: 2.3094 - val_accuracy: 0.3417\n",
      "Epoch 1/10\n",
      "54/54 [==============================] - 42s 523ms/step - loss: 8.7128 - accuracy: 0.0382 - val_loss: 8.6305 - val_accuracy: 0.0850\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 26s 477ms/step - loss: 7.7942 - accuracy: 0.0936 - val_loss: 7.2538 - val_accuracy: 0.0783\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 25s 471ms/step - loss: 5.4341 - accuracy: 0.1194 - val_loss: 5.0783 - val_accuracy: 0.1180\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 25s 471ms/step - loss: 3.6206 - accuracy: 0.1624 - val_loss: 3.5645 - val_accuracy: 0.1553\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 25s 471ms/step - loss: 3.0161 - accuracy: 0.1862 - val_loss: 3.0775 - val_accuracy: 0.1898\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 25s 456ms/step - loss: 2.7377 - accuracy: 0.2240 - val_loss: 2.9823 - val_accuracy: 0.2018\n",
      "Epoch 7/10\n",
      "54/54 [==============================] - 26s 487ms/step - loss: 2.5383 - accuracy: 0.2496 - val_loss: 2.8214 - val_accuracy: 0.2237\n",
      "Epoch 8/10\n",
      "54/54 [==============================] - 26s 480ms/step - loss: 2.4215 - accuracy: 0.2847 - val_loss: 2.7517 - val_accuracy: 0.2493\n",
      "Epoch 9/10\n",
      "54/54 [==============================] - 26s 486ms/step - loss: 2.2798 - accuracy: 0.2988 - val_loss: 2.6616 - val_accuracy: 0.2804\n",
      "Epoch 10/10\n",
      "54/54 [==============================] - 24s 446ms/step - loss: 2.1696 - accuracy: 0.3277 - val_loss: 2.6991 - val_accuracy: 0.2902\n",
      "Epoch 1/20\n",
      "214/214 [==============================] - 46s 150ms/step - loss: 7.5343 - accuracy: 0.0546 - val_loss: 5.4851 - val_accuracy: 0.0668\n",
      "Epoch 2/20\n",
      "214/214 [==============================] - 29s 136ms/step - loss: 3.5819 - accuracy: 0.0935 - val_loss: 3.1286 - val_accuracy: 0.1097\n",
      "Epoch 3/20\n",
      "214/214 [==============================] - 29s 137ms/step - loss: 3.0102 - accuracy: 0.1320 - val_loss: 2.9395 - val_accuracy: 0.1487\n",
      "Epoch 4/20\n",
      "214/214 [==============================] - 29s 137ms/step - loss: 2.8186 - accuracy: 0.1706 - val_loss: 2.7589 - val_accuracy: 0.1884\n",
      "Epoch 5/20\n",
      "214/214 [==============================] - 29s 136ms/step - loss: 2.6312 - accuracy: 0.2219 - val_loss: 2.5660 - val_accuracy: 0.2523\n",
      "Epoch 6/20\n",
      "214/214 [==============================] - 30s 140ms/step - loss: 2.4869 - accuracy: 0.2628 - val_loss: 2.5289 - val_accuracy: 0.2751\n",
      "Epoch 7/20\n",
      "214/214 [==============================] - 30s 142ms/step - loss: 2.3254 - accuracy: 0.3103 - val_loss: 2.4271 - val_accuracy: 0.3016\n",
      "Epoch 8/20\n",
      "214/214 [==============================] - 28s 133ms/step - loss: 2.2165 - accuracy: 0.3448 - val_loss: 2.3039 - val_accuracy: 0.3450\n",
      "Epoch 9/20\n",
      "214/214 [==============================] - 27s 128ms/step - loss: 2.0562 - accuracy: 0.3841 - val_loss: 2.2181 - val_accuracy: 0.3580\n",
      "Epoch 10/20\n",
      "214/214 [==============================] - 29s 136ms/step - loss: 1.9481 - accuracy: 0.4107 - val_loss: 2.1878 - val_accuracy: 0.3923\n",
      "Epoch 11/20\n",
      "214/214 [==============================] - 29s 135ms/step - loss: 1.8160 - accuracy: 0.4518 - val_loss: 2.0985 - val_accuracy: 0.4129\n",
      "Epoch 12/20\n",
      "214/214 [==============================] - 29s 134ms/step - loss: 1.7415 - accuracy: 0.4696 - val_loss: 2.0462 - val_accuracy: 0.4264\n",
      "Epoch 13/20\n",
      "214/214 [==============================] - 29s 134ms/step - loss: 1.6596 - accuracy: 0.5027 - val_loss: 2.0292 - val_accuracy: 0.4540\n",
      "Epoch 14/20\n",
      "214/214 [==============================] - 29s 135ms/step - loss: 1.5837 - accuracy: 0.5156 - val_loss: 2.0587 - val_accuracy: 0.4413\n",
      "Epoch 15/20\n",
      "214/214 [==============================] - 29s 135ms/step - loss: 1.5161 - accuracy: 0.5472 - val_loss: 2.0679 - val_accuracy: 0.4598\n",
      "Epoch 16/20\n",
      "214/214 [==============================] - 29s 135ms/step - loss: 1.4410 - accuracy: 0.5639 - val_loss: 2.0307 - val_accuracy: 0.4643\n",
      "Epoch 17/20\n",
      "214/214 [==============================] - 29s 135ms/step - loss: 1.3887 - accuracy: 0.5754 - val_loss: 2.0595 - val_accuracy: 0.4706\n",
      "Epoch 18/20\n",
      "214/214 [==============================] - 29s 136ms/step - loss: 1.3136 - accuracy: 0.6007 - val_loss: 1.9821 - val_accuracy: 0.4919\n",
      "Epoch 19/20\n",
      "214/214 [==============================] - 29s 135ms/step - loss: 1.2792 - accuracy: 0.6157 - val_loss: 2.0430 - val_accuracy: 0.4850\n",
      "Epoch 20/20\n",
      "214/214 [==============================] - 29s 134ms/step - loss: 1.2322 - accuracy: 0.6313 - val_loss: 2.0370 - val_accuracy: 0.4937\n",
      "Epoch 1/20\n",
      "107/107 [==============================] - 46s 246ms/step - loss: 8.5235 - accuracy: 0.0505 - val_loss: 8.2823 - val_accuracy: 0.0516\n",
      "Epoch 2/20\n",
      "107/107 [==============================] - 23s 219ms/step - loss: 5.6496 - accuracy: 0.0974 - val_loss: 4.1160 - val_accuracy: 0.0943\n",
      "Epoch 3/20\n",
      "107/107 [==============================] - 23s 215ms/step - loss: 3.3787 - accuracy: 0.1343 - val_loss: 3.1237 - val_accuracy: 0.1280\n",
      "Epoch 4/20\n",
      "107/107 [==============================] - 23s 219ms/step - loss: 2.9388 - accuracy: 0.1554 - val_loss: 2.8750 - val_accuracy: 0.1739\n",
      "Epoch 5/20\n",
      "107/107 [==============================] - 23s 218ms/step - loss: 2.7532 - accuracy: 0.1915 - val_loss: 2.7982 - val_accuracy: 0.1946\n",
      "Epoch 6/20\n",
      "107/107 [==============================] - 22s 208ms/step - loss: 2.6000 - accuracy: 0.2255 - val_loss: 2.7254 - val_accuracy: 0.2212\n",
      "Epoch 7/20\n",
      "107/107 [==============================] - 22s 204ms/step - loss: 2.4463 - accuracy: 0.2651 - val_loss: 2.6395 - val_accuracy: 0.2707\n",
      "Epoch 8/20\n",
      "107/107 [==============================] - 23s 216ms/step - loss: 2.3007 - accuracy: 0.3039 - val_loss: 2.4768 - val_accuracy: 0.2888\n",
      "Epoch 9/20\n",
      "107/107 [==============================] - 23s 218ms/step - loss: 2.1505 - accuracy: 0.3378 - val_loss: 2.4081 - val_accuracy: 0.3067\n",
      "Epoch 10/20\n",
      "107/107 [==============================] - 23s 216ms/step - loss: 2.0692 - accuracy: 0.3584 - val_loss: 2.4674 - val_accuracy: 0.3213\n",
      "Epoch 11/20\n",
      "107/107 [==============================] - 23s 219ms/step - loss: 1.9562 - accuracy: 0.3931 - val_loss: 2.3433 - val_accuracy: 0.3482\n",
      "Epoch 12/20\n",
      "107/107 [==============================] - 23s 217ms/step - loss: 1.8526 - accuracy: 0.4301 - val_loss: 2.3236 - val_accuracy: 0.3817\n",
      "Epoch 13/20\n",
      "107/107 [==============================] - 23s 218ms/step - loss: 1.7658 - accuracy: 0.4546 - val_loss: 2.3379 - val_accuracy: 0.3810\n",
      "Epoch 14/20\n",
      "107/107 [==============================] - 21s 201ms/step - loss: 1.6650 - accuracy: 0.4799 - val_loss: 2.2099 - val_accuracy: 0.4134\n",
      "Epoch 15/20\n",
      "107/107 [==============================] - 24s 225ms/step - loss: 1.5723 - accuracy: 0.5151 - val_loss: 2.3328 - val_accuracy: 0.4192\n",
      "Epoch 16/20\n",
      "107/107 [==============================] - 24s 225ms/step - loss: 1.5282 - accuracy: 0.5287 - val_loss: 2.1941 - val_accuracy: 0.4373\n",
      "Epoch 17/20\n",
      "107/107 [==============================] - 24s 225ms/step - loss: 1.4584 - accuracy: 0.5460 - val_loss: 2.2009 - val_accuracy: 0.4470\n",
      "Epoch 18/20\n",
      "107/107 [==============================] - 24s 223ms/step - loss: 1.3711 - accuracy: 0.5725 - val_loss: 2.2802 - val_accuracy: 0.4588\n",
      "Epoch 19/20\n",
      "107/107 [==============================] - 22s 206ms/step - loss: 1.3067 - accuracy: 0.6026 - val_loss: 2.2809 - val_accuracy: 0.4540\n",
      "Epoch 20/20\n",
      "107/107 [==============================] - 23s 217ms/step - loss: 1.2610 - accuracy: 0.6075 - val_loss: 2.1367 - val_accuracy: 0.4804\n",
      "Epoch 1/20\n",
      "54/54 [==============================] - 49s 586ms/step - loss: 8.7258 - accuracy: 0.0375 - val_loss: 8.7009 - val_accuracy: 0.0374\n",
      "Epoch 2/20\n",
      "54/54 [==============================] - 28s 520ms/step - loss: 7.7706 - accuracy: 0.0800 - val_loss: 7.7425 - val_accuracy: 0.0721\n",
      "Epoch 3/20\n",
      "54/54 [==============================] - 28s 521ms/step - loss: 5.3490 - accuracy: 0.0794 - val_loss: 5.8999 - val_accuracy: 0.0944\n",
      "Epoch 4/20\n",
      "54/54 [==============================] - 27s 507ms/step - loss: 3.6925 - accuracy: 0.1052 - val_loss: 3.8235 - val_accuracy: 0.1037\n",
      "Epoch 5/20\n",
      "54/54 [==============================] - 25s 474ms/step - loss: 3.2192 - accuracy: 0.1222 - val_loss: 3.3330 - val_accuracy: 0.1252\n",
      "Epoch 6/20\n",
      "54/54 [==============================] - 27s 503ms/step - loss: 2.9687 - accuracy: 0.1405 - val_loss: 3.0047 - val_accuracy: 0.1381\n",
      "Epoch 7/20\n",
      "54/54 [==============================] - 27s 500ms/step - loss: 2.8352 - accuracy: 0.1614 - val_loss: 2.9912 - val_accuracy: 0.1534\n",
      "Epoch 8/20\n",
      "54/54 [==============================] - 27s 494ms/step - loss: 2.7220 - accuracy: 0.1857 - val_loss: 2.8966 - val_accuracy: 0.1712\n",
      "Epoch 9/20\n",
      "54/54 [==============================] - 27s 508ms/step - loss: 2.5965 - accuracy: 0.2186 - val_loss: 2.8087 - val_accuracy: 0.2070\n",
      "Epoch 10/20\n",
      "54/54 [==============================] - 28s 514ms/step - loss: 2.5069 - accuracy: 0.2372 - val_loss: 2.8141 - val_accuracy: 0.2182\n",
      "Epoch 11/20\n",
      "54/54 [==============================] - 28s 522ms/step - loss: 2.3853 - accuracy: 0.2635 - val_loss: 2.8138 - val_accuracy: 0.2508\n",
      "Epoch 12/20\n",
      "54/54 [==============================] - 27s 510ms/step - loss: 2.2827 - accuracy: 0.2989 - val_loss: 2.7219 - val_accuracy: 0.2704\n",
      "Epoch 13/20\n",
      "54/54 [==============================] - 27s 500ms/step - loss: 2.2076 - accuracy: 0.3274 - val_loss: 2.6739 - val_accuracy: 0.2870\n",
      "Epoch 14/20\n",
      "54/54 [==============================] - 27s 498ms/step - loss: 2.0718 - accuracy: 0.3609 - val_loss: 2.5598 - val_accuracy: 0.3266\n",
      "Epoch 15/20\n",
      "54/54 [==============================] - 24s 454ms/step - loss: 1.9719 - accuracy: 0.3980 - val_loss: 2.7449 - val_accuracy: 0.3085\n",
      "Epoch 16/20\n",
      "54/54 [==============================] - 29s 533ms/step - loss: 1.9048 - accuracy: 0.4101 - val_loss: 2.5210 - val_accuracy: 0.3388\n",
      "Epoch 17/20\n",
      "54/54 [==============================] - 29s 533ms/step - loss: 1.8049 - accuracy: 0.4396 - val_loss: 2.5491 - val_accuracy: 0.3594\n",
      "Epoch 18/20\n",
      "54/54 [==============================] - 29s 539ms/step - loss: 1.7321 - accuracy: 0.4647 - val_loss: 2.6003 - val_accuracy: 0.3648\n",
      "Epoch 19/20\n",
      "54/54 [==============================] - 27s 511ms/step - loss: 1.6363 - accuracy: 0.4903 - val_loss: 2.5223 - val_accuracy: 0.3806\n",
      "Epoch 20/20\n",
      "54/54 [==============================] - 27s 503ms/step - loss: 1.5934 - accuracy: 0.4992 - val_loss: 2.4540 - val_accuracy: 0.3913\n",
      "Epoch 1/30\n",
      "214/214 [==============================] - 52s 165ms/step - loss: 7.8291 - accuracy: 0.0489 - val_loss: 5.2803 - val_accuracy: 0.0862\n",
      "Epoch 2/30\n",
      "214/214 [==============================] - 31s 145ms/step - loss: 3.6401 - accuracy: 0.1131 - val_loss: 3.0452 - val_accuracy: 0.1236\n",
      "Epoch 3/30\n",
      "214/214 [==============================] - 32s 151ms/step - loss: 2.9440 - accuracy: 0.1505 - val_loss: 2.8824 - val_accuracy: 0.1701\n",
      "Epoch 4/30\n",
      "214/214 [==============================] - 32s 151ms/step - loss: 2.7243 - accuracy: 0.1960 - val_loss: 2.7007 - val_accuracy: 0.2039\n",
      "Epoch 5/30\n",
      "214/214 [==============================] - 33s 154ms/step - loss: 2.5694 - accuracy: 0.2386 - val_loss: 2.5862 - val_accuracy: 0.2389\n",
      "Epoch 6/30\n",
      "214/214 [==============================] - 33s 153ms/step - loss: 2.4383 - accuracy: 0.2629 - val_loss: 2.4756 - val_accuracy: 0.2743\n",
      "Epoch 7/30\n",
      "214/214 [==============================] - 32s 151ms/step - loss: 2.2868 - accuracy: 0.3078 - val_loss: 2.3828 - val_accuracy: 0.3089\n",
      "Epoch 8/30\n",
      "214/214 [==============================] - 31s 144ms/step - loss: 2.1611 - accuracy: 0.3466 - val_loss: 2.3706 - val_accuracy: 0.3289\n",
      "Epoch 9/30\n",
      "214/214 [==============================] - 32s 151ms/step - loss: 2.0118 - accuracy: 0.3862 - val_loss: 2.2308 - val_accuracy: 0.3658\n",
      "Epoch 10/30\n",
      "214/214 [==============================] - 32s 151ms/step - loss: 1.9120 - accuracy: 0.4192 - val_loss: 2.3113 - val_accuracy: 0.3706\n",
      "Epoch 11/30\n",
      "214/214 [==============================] - 32s 150ms/step - loss: 1.7991 - accuracy: 0.4481 - val_loss: 2.1580 - val_accuracy: 0.3925\n",
      "Epoch 12/30\n",
      "214/214 [==============================] - 31s 147ms/step - loss: 1.7272 - accuracy: 0.4756 - val_loss: 2.1321 - val_accuracy: 0.4213\n",
      "Epoch 13/30\n",
      "214/214 [==============================] - 32s 148ms/step - loss: 1.6254 - accuracy: 0.5116 - val_loss: 2.1321 - val_accuracy: 0.4281\n",
      "Epoch 14/30\n",
      "214/214 [==============================] - 31s 146ms/step - loss: 1.5575 - accuracy: 0.5264 - val_loss: 2.1894 - val_accuracy: 0.4334\n",
      "Epoch 15/30\n",
      "214/214 [==============================] - 31s 145ms/step - loss: 1.4777 - accuracy: 0.5489 - val_loss: 2.1339 - val_accuracy: 0.4535\n",
      "Epoch 16/30\n",
      "214/214 [==============================] - 33s 153ms/step - loss: 1.4411 - accuracy: 0.5624 - val_loss: 2.0311 - val_accuracy: 0.4813\n",
      "Epoch 17/30\n",
      "214/214 [==============================] - 33s 153ms/step - loss: 1.3838 - accuracy: 0.5789 - val_loss: 2.1333 - val_accuracy: 0.4728\n",
      "Epoch 18/30\n",
      "214/214 [==============================] - 32s 150ms/step - loss: 1.2988 - accuracy: 0.6016 - val_loss: 2.0955 - val_accuracy: 0.4825\n",
      "Epoch 19/30\n",
      "175/214 [=======================>......] - ETA: 4s - loss: 1.2401 - accuracy: 0.6288"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense, Bidirectional, TimeDistributed, BatchNormalization\n",
    "\n",
    "results = pd.DataFrame(columns=['lstm_units', 'dropout_rate', 'epoch', 'batch', 'loss', 'loss_max', 'accuracy', 'accuracy_max', 'val_loss', 'val_loss_max', 'val_accuracy', 'val_accuracy_max'])\n",
    "\n",
    "# Set your model's hyperparameters\n",
    "for lstm_units in [64, 128, 256]:\n",
    "    for dropout_rate in [0.2, 0.4, 0.6]:\n",
    "            for epoch in [10, 20, 30, 40]:\n",
    "                  for batch in [32, 64, 128]:\n",
    "\n",
    "                        num_classes = len(y_train_encoded)  # Number of unique classes in your dataset\n",
    "\n",
    "                        input_shape = (39, 44)\n",
    "\n",
    "                        model = Sequential([\n",
    "                            Bidirectional(LSTM(lstm_units, return_sequences=True), input_shape=input_shape),\n",
    "                            BatchNormalization(),\n",
    "                            Dropout(dropout_rate),\n",
    "                            Bidirectional(LSTM(lstm_units, return_sequences=True)),\n",
    "                            BatchNormalization(),\n",
    "                            Dropout(dropout_rate),\n",
    "                            LSTM(lstm_units, return_sequences=True),\n",
    "                            BatchNormalization(),\n",
    "                            Dropout(dropout_rate),\n",
    "                            TimeDistributed(Dense(64, activation='relu')),\n",
    "                            BatchNormalization(),\n",
    "                            Dropout(dropout_rate),\n",
    "                            TimeDistributed(Dense(32, activation='relu')),\n",
    "                            BatchNormalization(),\n",
    "                            Dropout(dropout_rate),\n",
    "                            LSTM(lstm_units),\n",
    "                            BatchNormalization(),\n",
    "                            Dropout(dropout_rate),\n",
    "                            Dense(num_classes, activation='softmax')\n",
    "                        ])\n",
    "\n",
    "\n",
    "                        # Compile the model\n",
    "                        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "                        # Train the model with your training set and validate it with your validation set\n",
    "                        epochs = epoch\n",
    "                        batch_size = batch\n",
    "                        history = model.fit(X_train, y_train_encoded, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val_encoded))\n",
    "\n",
    "                        results = np.concatenate((results, pd.DataFrame([[lstm_units, dropout_rate, epoch, batch, history.history['loss'][-1], history.history['loss'], history.history['accuracy'][-1], history.history['accuracy'], history.history['val_loss'][-1], history.history['val_loss'], history.history['val_accuracy'][-1], history.history['val_accuracy']]], \n",
    "                                                                        columns=['lstm_units', 'dropout_rate', 'epoch', 'batch', 'loss', 'loss_max', 'accuracy', 'accuracy_max', 'val_loss', 'val_loss_max', 'val_accuracy', 'val_accuracy_max'])), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[64, 0.2, 2, 32, 3.100442886352539,\n",
       "        list([6.995808124542236, 3.100442886352539]),\n",
       "        0.16634966433048248, 0.16634966433048248, 2.812389373779297,\n",
       "        3.762976884841919, 0.18740805983543396, 0.18740805983543396]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.to_pickle('results\\\\model_lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
