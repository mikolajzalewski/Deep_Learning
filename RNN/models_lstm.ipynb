{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lstm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dataset import LABELS\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import labels_only_detection_training, labels_only_detection_validation, labels_only_detection_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_pickle('results\\\\model_lstm_final_version.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "80/81 [============================>.] - ETA: 0s - loss: 2.5870 - accuracy: 0.1422\n",
      "Epoch 1: val_accuracy improved from -inf to 0.17967, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 13s 88ms/step - loss: 2.5884 - accuracy: 0.1418 - val_loss: 2.2453 - val_accuracy: 0.1797\n",
      "Epoch 2/20\n",
      "80/81 [============================>.] - ETA: 0s - loss: 2.1278 - accuracy: 0.2484\n",
      "Epoch 2: val_accuracy improved from 0.17967 to 0.28056, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 7s 82ms/step - loss: 2.1297 - accuracy: 0.2481 - val_loss: 2.0381 - val_accuracy: 0.2806\n",
      "Epoch 3/20\n",
      "80/81 [============================>.] - ETA: 0s - loss: 1.8290 - accuracy: 0.3617\n",
      "Epoch 3: val_accuracy improved from 0.28056 to 0.40396, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 7s 84ms/step - loss: 1.8282 - accuracy: 0.3619 - val_loss: 1.7489 - val_accuracy: 0.4040\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.5441 - accuracy: 0.4714\n",
      "Epoch 4: val_accuracy improved from 0.40396 to 0.44936, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 9s 110ms/step - loss: 1.5441 - accuracy: 0.4714 - val_loss: 1.6019 - val_accuracy: 0.4494\n",
      "Epoch 5/20\n",
      "80/81 [============================>.] - ETA: 0s - loss: 1.2872 - accuracy: 0.5633\n",
      "Epoch 5: val_accuracy improved from 0.44936 to 0.46255, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 9s 114ms/step - loss: 1.2877 - accuracy: 0.5633 - val_loss: 1.6499 - val_accuracy: 0.4626\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.0846 - accuracy: 0.6221\n",
      "Epoch 6: val_accuracy improved from 0.46255 to 0.47769, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 10s 127ms/step - loss: 1.0846 - accuracy: 0.6221 - val_loss: 1.7129 - val_accuracy: 0.4777\n",
      "Epoch 7/20\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.9259 - accuracy: 0.6805\n",
      "Epoch 7: val_accuracy improved from 0.47769 to 0.50718, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 10s 120ms/step - loss: 0.9254 - accuracy: 0.6806 - val_loss: 1.7721 - val_accuracy: 0.5072\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.8194 - accuracy: 0.7257\n",
      "Epoch 8: val_accuracy improved from 0.50718 to 0.52930, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 10s 123ms/step - loss: 0.8194 - accuracy: 0.7257 - val_loss: 1.6531 - val_accuracy: 0.5293\n",
      "Epoch 9/20\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.6679 - accuracy: 0.7738\n",
      "Epoch 9: val_accuracy did not improve from 0.52930\n",
      "81/81 [==============================] - 10s 124ms/step - loss: 0.6718 - accuracy: 0.7725 - val_loss: 1.7679 - val_accuracy: 0.5204\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.5919 - accuracy: 0.7955\n",
      "Epoch 10: val_accuracy improved from 0.52930 to 0.53163, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 10s 121ms/step - loss: 0.5919 - accuracy: 0.7955 - val_loss: 1.7952 - val_accuracy: 0.5316\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.5772 - accuracy: 0.8118\n",
      "Epoch 11: val_accuracy improved from 0.53163 to 0.54792, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 10s 125ms/step - loss: 0.5772 - accuracy: 0.8118 - val_loss: 1.7463 - val_accuracy: 0.5479\n",
      "Epoch 12/20\n",
      "80/81 [============================>.] - ETA: 0s - loss: 0.4627 - accuracy: 0.8391\n",
      "Epoch 12: val_accuracy improved from 0.54792 to 0.56888, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 9s 114ms/step - loss: 0.4648 - accuracy: 0.8387 - val_loss: 1.7095 - val_accuracy: 0.5689\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.4258 - accuracy: 0.8605\n",
      "Epoch 13: val_accuracy did not improve from 0.56888\n",
      "81/81 [==============================] - 9s 108ms/step - loss: 0.4258 - accuracy: 0.8605 - val_loss: 1.8131 - val_accuracy: 0.5541\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.3811 - accuracy: 0.8660\n",
      "Epoch 14: val_accuracy did not improve from 0.56888\n",
      "81/81 [==============================] - 10s 122ms/step - loss: 0.3811 - accuracy: 0.8660 - val_loss: 1.8546 - val_accuracy: 0.5518\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.4072 - accuracy: 0.8648\n",
      "Epoch 15: val_accuracy did not improve from 0.56888\n",
      "81/81 [==============================] - 10s 125ms/step - loss: 0.4072 - accuracy: 0.8648 - val_loss: 1.8680 - val_accuracy: 0.5429\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.3352 - accuracy: 0.8866\n",
      "Epoch 16: val_accuracy did not improve from 0.56888\n",
      "81/81 [==============================] - 10s 128ms/step - loss: 0.3352 - accuracy: 0.8866 - val_loss: 1.8810 - val_accuracy: 0.5565\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2955 - accuracy: 0.9042\n",
      "Epoch 17: val_accuracy did not improve from 0.56888\n",
      "81/81 [==============================] - 10s 125ms/step - loss: 0.2955 - accuracy: 0.9042 - val_loss: 1.8665 - val_accuracy: 0.5669\n",
      "Epoch 1/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.6252 - accuracy: 0.1508\n",
      "Epoch 1: val_accuracy improved from -inf to 0.16647, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 27s 281ms/step - loss: 2.6252 - accuracy: 0.1508 - val_loss: 2.2847 - val_accuracy: 0.1665\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.1798 - accuracy: 0.2462\n",
      "Epoch 2: val_accuracy improved from 0.16647 to 0.22002, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 8s 192ms/step - loss: 2.1798 - accuracy: 0.2462 - val_loss: 2.2271 - val_accuracy: 0.2200\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.8636 - accuracy: 0.3588\n",
      "Epoch 3: val_accuracy improved from 0.22002 to 0.29142, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 10s 240ms/step - loss: 1.8636 - accuracy: 0.3588 - val_loss: 2.0917 - val_accuracy: 0.2914\n",
      "Epoch 4/20\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.6197 - accuracy: 0.4383\n",
      "Epoch 4: val_accuracy improved from 0.29142 to 0.36981, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 10s 250ms/step - loss: 1.6209 - accuracy: 0.4375 - val_loss: 1.8841 - val_accuracy: 0.3698\n",
      "Epoch 5/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.4025 - accuracy: 0.5201\n",
      "Epoch 5: val_accuracy improved from 0.36981 to 0.40551, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 10s 247ms/step - loss: 1.4025 - accuracy: 0.5201 - val_loss: 1.7634 - val_accuracy: 0.4055\n",
      "Epoch 6/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1934 - accuracy: 0.5808\n",
      "Epoch 6: val_accuracy improved from 0.40551 to 0.44820, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 10s 251ms/step - loss: 1.1934 - accuracy: 0.5808 - val_loss: 1.6018 - val_accuracy: 0.4482\n",
      "Epoch 7/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0642 - accuracy: 0.6260\n",
      "Epoch 7: val_accuracy improved from 0.44820 to 0.46061, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 10s 246ms/step - loss: 1.0642 - accuracy: 0.6260 - val_loss: 1.7102 - val_accuracy: 0.4606\n",
      "Epoch 8/20\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.8447 - accuracy: 0.7258\n",
      "Epoch 8: val_accuracy improved from 0.46061 to 0.48545, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 8s 196ms/step - loss: 0.8472 - accuracy: 0.7254 - val_loss: 1.6952 - val_accuracy: 0.4854\n",
      "Epoch 9/20\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.7464 - accuracy: 0.7473\n",
      "Epoch 9: val_accuracy improved from 0.48545 to 0.50718, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 9s 230ms/step - loss: 0.7472 - accuracy: 0.7472 - val_loss: 1.6546 - val_accuracy: 0.5072\n",
      "Epoch 10/20\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.6510 - accuracy: 0.7918\n",
      "Epoch 10: val_accuracy did not improve from 0.50718\n",
      "41/41 [==============================] - 10s 256ms/step - loss: 0.6514 - accuracy: 0.7916 - val_loss: 1.8994 - val_accuracy: 0.4854\n",
      "Epoch 11/20\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.5465 - accuracy: 0.8141\n",
      "Epoch 11: val_accuracy improved from 0.50718 to 0.52619, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 9s 219ms/step - loss: 0.5478 - accuracy: 0.8134 - val_loss: 1.7884 - val_accuracy: 0.5262\n",
      "Epoch 12/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.4926 - accuracy: 0.8426\n",
      "Epoch 12: val_accuracy did not improve from 0.52619\n",
      "41/41 [==============================] - 9s 209ms/step - loss: 0.4926 - accuracy: 0.8426 - val_loss: 1.8865 - val_accuracy: 0.5219\n",
      "Epoch 13/20\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.4166 - accuracy: 0.8637\n",
      "Epoch 13: val_accuracy improved from 0.52619 to 0.54366, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 9s 214ms/step - loss: 0.4163 - accuracy: 0.8637 - val_loss: 1.8666 - val_accuracy: 0.5437\n",
      "Epoch 14/20\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.3903 - accuracy: 0.8652\n",
      "Epoch 14: val_accuracy improved from 0.54366 to 0.55840, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 8s 195ms/step - loss: 0.3935 - accuracy: 0.8644 - val_loss: 1.9147 - val_accuracy: 0.5584\n",
      "Epoch 15/20\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.3828 - accuracy: 0.8754\n",
      "Epoch 15: val_accuracy did not improve from 0.55840\n",
      "41/41 [==============================] - 8s 184ms/step - loss: 0.3857 - accuracy: 0.8746 - val_loss: 1.9245 - val_accuracy: 0.5378\n",
      "Epoch 16/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.3715 - accuracy: 0.8742\n",
      "Epoch 16: val_accuracy did not improve from 0.55840\n",
      "41/41 [==============================] - 6s 157ms/step - loss: 0.3715 - accuracy: 0.8742 - val_loss: 2.0183 - val_accuracy: 0.5518\n",
      "Epoch 17/20\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.3269 - accuracy: 0.8906\n",
      "Epoch 17: val_accuracy did not improve from 0.55840\n",
      "41/41 [==============================] - 8s 185ms/step - loss: 0.3265 - accuracy: 0.8909 - val_loss: 2.1102 - val_accuracy: 0.5425\n",
      "Epoch 18/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2481 - accuracy: 0.9194\n",
      "Epoch 18: val_accuracy improved from 0.55840 to 0.56655, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 8s 206ms/step - loss: 0.2481 - accuracy: 0.9194 - val_loss: 2.0326 - val_accuracy: 0.5666\n",
      "Epoch 19/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.3245 - accuracy: 0.8905\n",
      "Epoch 19: val_accuracy did not improve from 0.56655\n",
      "41/41 [==============================] - 8s 203ms/step - loss: 0.3245 - accuracy: 0.8905 - val_loss: 2.0832 - val_accuracy: 0.5440\n",
      "Epoch 20/20\n",
      "40/41 [============================>.] - ETA: 0s - loss: 0.2776 - accuracy: 0.9082\n",
      "Epoch 20: val_accuracy did not improve from 0.56655\n",
      "41/41 [==============================] - 7s 183ms/step - loss: 0.2782 - accuracy: 0.9081 - val_loss: 2.0439 - val_accuracy: 0.5654\n",
      "Epoch 1/20\n",
      "20/21 [===========================>..] - ETA: 0s - loss: 2.6769 - accuracy: 0.1430\n",
      "Epoch 1: val_accuracy improved from -inf to 0.17579, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 36s 645ms/step - loss: 2.6770 - accuracy: 0.1430 - val_loss: 2.2864 - val_accuracy: 0.1758\n",
      "Epoch 2/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.2232 - accuracy: 0.2458\n",
      "Epoch 2: val_accuracy improved from 0.17579 to 0.18122, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 7s 338ms/step - loss: 2.2232 - accuracy: 0.2458 - val_loss: 2.2611 - val_accuracy: 0.1812\n",
      "Epoch 3/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.9955 - accuracy: 0.3007\n",
      "Epoch 3: val_accuracy improved from 0.18122 to 0.19053, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 7s 342ms/step - loss: 1.9955 - accuracy: 0.3007 - val_loss: 2.2315 - val_accuracy: 0.1905\n",
      "Epoch 4/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7959 - accuracy: 0.3829\n",
      "Epoch 4: val_accuracy improved from 0.19053 to 0.24486, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 7s 338ms/step - loss: 1.7959 - accuracy: 0.3829 - val_loss: 2.1771 - val_accuracy: 0.2449\n",
      "Epoch 5/20\n",
      "20/21 [===========================>..] - ETA: 0s - loss: 1.6523 - accuracy: 0.4184\n",
      "Epoch 5: val_accuracy improved from 0.24486 to 0.26969, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 7s 343ms/step - loss: 1.6517 - accuracy: 0.4188 - val_loss: 2.1047 - val_accuracy: 0.2697\n",
      "Epoch 6/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.4760 - accuracy: 0.4807\n",
      "Epoch 6: val_accuracy improved from 0.26969 to 0.35157, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 7s 351ms/step - loss: 1.4760 - accuracy: 0.4807 - val_loss: 1.9618 - val_accuracy: 0.3516\n",
      "Epoch 7/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.3126 - accuracy: 0.5520\n",
      "Epoch 7: val_accuracy improved from 0.35157 to 0.36826, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 7s 341ms/step - loss: 1.3126 - accuracy: 0.5520 - val_loss: 1.8787 - val_accuracy: 0.3683\n",
      "Epoch 8/20\n",
      "20/21 [===========================>..] - ETA: 0s - loss: 1.1455 - accuracy: 0.6066\n",
      "Epoch 8: val_accuracy improved from 0.36826 to 0.40667, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 7s 343ms/step - loss: 1.1449 - accuracy: 0.6069 - val_loss: 1.7613 - val_accuracy: 0.4067\n",
      "Epoch 9/20\n",
      "20/21 [===========================>..] - ETA: 0s - loss: 0.9791 - accuracy: 0.6547\n",
      "Epoch 9: val_accuracy improved from 0.40667 to 0.41987, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 7s 340ms/step - loss: 0.9802 - accuracy: 0.6545 - val_loss: 1.6885 - val_accuracy: 0.4199\n",
      "Epoch 10/20\n",
      "20/21 [===========================>..] - ETA: 0s - loss: 0.8968 - accuracy: 0.6875\n",
      "Epoch 10: val_accuracy improved from 0.41987 to 0.42879, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 7s 343ms/step - loss: 0.8959 - accuracy: 0.6880 - val_loss: 1.6883 - val_accuracy: 0.4288\n",
      "Epoch 11/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.7587 - accuracy: 0.7343\n",
      "Epoch 11: val_accuracy improved from 0.42879 to 0.46605, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 7s 327ms/step - loss: 0.7587 - accuracy: 0.7343 - val_loss: 1.6543 - val_accuracy: 0.4660\n",
      "Epoch 12/20\n",
      "20/21 [===========================>..] - ETA: 0s - loss: 0.7222 - accuracy: 0.7566\n",
      "Epoch 12: val_accuracy improved from 0.46605 to 0.46682, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 7s 330ms/step - loss: 0.7247 - accuracy: 0.7561 - val_loss: 1.7440 - val_accuracy: 0.4668\n",
      "Epoch 13/20\n",
      "20/21 [===========================>..] - ETA: 0s - loss: 0.6956 - accuracy: 0.7605\n",
      "Epoch 13: val_accuracy improved from 0.46682 to 0.48661, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 7s 333ms/step - loss: 0.6955 - accuracy: 0.7604 - val_loss: 1.6906 - val_accuracy: 0.4866\n",
      "Epoch 14/20\n",
      "20/21 [===========================>..] - ETA: 0s - loss: 0.6426 - accuracy: 0.7848\n",
      "Epoch 14: val_accuracy improved from 0.48661 to 0.48972, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 6s 286ms/step - loss: 0.6437 - accuracy: 0.7846 - val_loss: 1.7533 - val_accuracy: 0.4897\n",
      "Epoch 15/20\n",
      "20/21 [===========================>..] - ETA: 0s - loss: 0.5315 - accuracy: 0.8141\n",
      "Epoch 15: val_accuracy did not improve from 0.48972\n",
      "21/21 [==============================] - 6s 282ms/step - loss: 0.5320 - accuracy: 0.8138 - val_loss: 1.9251 - val_accuracy: 0.4808\n",
      "Epoch 16/20\n",
      "20/21 [===========================>..] - ETA: 0s - loss: 0.5113 - accuracy: 0.8285\n",
      "Epoch 16: val_accuracy improved from 0.48972 to 0.49127, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 6s 312ms/step - loss: 0.5129 - accuracy: 0.8282 - val_loss: 1.9104 - val_accuracy: 0.4913\n",
      "Epoch 17/20\n",
      "20/21 [===========================>..] - ETA: 0s - loss: 0.6598 - accuracy: 0.7758\n",
      "Epoch 17: val_accuracy did not improve from 0.49127\n",
      "21/21 [==============================] - 7s 311ms/step - loss: 0.6600 - accuracy: 0.7756 - val_loss: 2.0892 - val_accuracy: 0.4680\n",
      "Epoch 18/20\n",
      "20/21 [===========================>..] - ETA: 0s - loss: 0.6511 - accuracy: 0.7816\n",
      "Epoch 18: val_accuracy did not improve from 0.49127\n",
      "21/21 [==============================] - 7s 321ms/step - loss: 0.6511 - accuracy: 0.7815 - val_loss: 2.0086 - val_accuracy: 0.4754\n",
      "Epoch 19/20\n",
      "20/21 [===========================>..] - ETA: 0s - loss: 0.5068 - accuracy: 0.8320\n",
      "Epoch 19: val_accuracy improved from 0.49127 to 0.52775, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 7s 328ms/step - loss: 0.5081 - accuracy: 0.8313 - val_loss: 1.9198 - val_accuracy: 0.5277\n",
      "Epoch 20/20\n",
      "20/21 [===========================>..] - ETA: 0s - loss: 0.3744 - accuracy: 0.8746\n",
      "Epoch 20: val_accuracy did not improve from 0.52775\n",
      "21/21 [==============================] - 7s 318ms/step - loss: 0.3752 - accuracy: 0.8742 - val_loss: 2.0060 - val_accuracy: 0.5177\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.4309 - accuracy: 0.1496\n",
      "Epoch 1: val_accuracy improved from -inf to 0.19092, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 45s 238ms/step - loss: 2.4309 - accuracy: 0.1496 - val_loss: 2.2187 - val_accuracy: 0.1909\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.0614 - accuracy: 0.2439\n",
      "Epoch 2: val_accuracy did not improve from 0.19092\n",
      "81/81 [==============================] - 10s 126ms/step - loss: 2.0614 - accuracy: 0.2439 - val_loss: 2.3277 - val_accuracy: 0.1187\n",
      "Epoch 3/20\n",
      "80/81 [============================>.] - ETA: 0s - loss: 1.8592 - accuracy: 0.3230\n",
      "Epoch 3: val_accuracy improved from 0.19092 to 0.26737, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 8s 105ms/step - loss: 1.8599 - accuracy: 0.3229 - val_loss: 2.0386 - val_accuracy: 0.2674\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.7636 - accuracy: 0.3592\n",
      "Epoch 4: val_accuracy improved from 0.26737 to 0.27008, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 10s 123ms/step - loss: 1.7636 - accuracy: 0.3592 - val_loss: 2.1815 - val_accuracy: 0.2701\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.6925 - accuracy: 0.4016\n",
      "Epoch 5: val_accuracy improved from 0.27008 to 0.34614, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 10s 129ms/step - loss: 1.6925 - accuracy: 0.4016 - val_loss: 1.8662 - val_accuracy: 0.3461\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.5787 - accuracy: 0.4375\n",
      "Epoch 6: val_accuracy did not improve from 0.34614\n",
      "81/81 [==============================] - 10s 124ms/step - loss: 1.5787 - accuracy: 0.4375 - val_loss: 2.1196 - val_accuracy: 0.2938\n",
      "Epoch 7/20\n",
      "80/81 [============================>.] - ETA: 0s - loss: 1.5417 - accuracy: 0.4547\n",
      "Epoch 7: val_accuracy improved from 0.34614 to 0.40861, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 9s 109ms/step - loss: 1.5420 - accuracy: 0.4546 - val_loss: 1.7480 - val_accuracy: 0.4086\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.5429 - accuracy: 0.4675\n",
      "Epoch 8: val_accuracy did not improve from 0.40861\n",
      "81/81 [==============================] - 10s 125ms/step - loss: 1.5429 - accuracy: 0.4675 - val_loss: 2.0439 - val_accuracy: 0.3706\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.4933 - accuracy: 0.4733\n",
      "Epoch 9: val_accuracy did not improve from 0.40861\n",
      "81/81 [==============================] - 11s 130ms/step - loss: 1.4933 - accuracy: 0.4733 - val_loss: 1.7989 - val_accuracy: 0.3927\n",
      "Epoch 10/20\n",
      "80/81 [============================>.] - ETA: 0s - loss: 1.4706 - accuracy: 0.4766\n",
      "Epoch 10: val_accuracy did not improve from 0.40861\n",
      "81/81 [==============================] - 10s 123ms/step - loss: 1.4711 - accuracy: 0.4764 - val_loss: 1.8164 - val_accuracy: 0.3977\n",
      "Epoch 11/20\n",
      "80/81 [============================>.] - ETA: 0s - loss: 1.4671 - accuracy: 0.4855\n",
      "Epoch 11: val_accuracy did not improve from 0.40861\n",
      "81/81 [==============================] - 8s 103ms/step - loss: 1.4690 - accuracy: 0.4846 - val_loss: 1.8632 - val_accuracy: 0.3624\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.4242 - accuracy: 0.4986\n",
      "Epoch 12: val_accuracy did not improve from 0.40861\n",
      "81/81 [==============================] - 9s 116ms/step - loss: 1.4242 - accuracy: 0.4986 - val_loss: 1.8027 - val_accuracy: 0.4067\n",
      "Epoch 1/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.4861 - accuracy: 0.1531\n",
      "Epoch 1: val_accuracy improved from -inf to 0.16182, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 40s 369ms/step - loss: 2.4861 - accuracy: 0.1531 - val_loss: 2.2290 - val_accuracy: 0.1618\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.1374 - accuracy: 0.2205\n",
      "Epoch 2: val_accuracy did not improve from 0.16182\n",
      "41/41 [==============================] - 9s 223ms/step - loss: 2.1374 - accuracy: 0.2205 - val_loss: 2.3792 - val_accuracy: 0.1098\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.8864 - accuracy: 0.3265\n",
      "Epoch 3: val_accuracy improved from 0.16182 to 0.19596, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 11s 270ms/step - loss: 1.8864 - accuracy: 0.3265 - val_loss: 2.1444 - val_accuracy: 0.1960\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.7093 - accuracy: 0.3841\n",
      "Epoch 4: val_accuracy improved from 0.19596 to 0.28677, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 11s 274ms/step - loss: 1.7093 - accuracy: 0.3841 - val_loss: 1.9449 - val_accuracy: 0.2868\n",
      "Epoch 5/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.5913 - accuracy: 0.4122\n",
      "Epoch 5: val_accuracy improved from 0.28677 to 0.33605, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 10s 253ms/step - loss: 1.5913 - accuracy: 0.4122 - val_loss: 1.8313 - val_accuracy: 0.3360\n",
      "Epoch 6/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.5376 - accuracy: 0.4554\n",
      "Epoch 6: val_accuracy improved from 0.33605 to 0.33760, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 8s 197ms/step - loss: 1.5376 - accuracy: 0.4554 - val_loss: 1.8400 - val_accuracy: 0.3376\n",
      "Epoch 7/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.4950 - accuracy: 0.4714\n",
      "Epoch 7: val_accuracy improved from 0.33760 to 0.39232, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 8s 195ms/step - loss: 1.4950 - accuracy: 0.4714 - val_loss: 1.7128 - val_accuracy: 0.3923\n",
      "Epoch 8/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.4613 - accuracy: 0.4725\n",
      "Epoch 8: val_accuracy did not improve from 0.39232\n",
      "41/41 [==============================] - 9s 221ms/step - loss: 1.4613 - accuracy: 0.4725 - val_loss: 1.6341 - val_accuracy: 0.3900\n",
      "Epoch 9/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.4080 - accuracy: 0.5208\n",
      "Epoch 9: val_accuracy did not improve from 0.39232\n",
      "41/41 [==============================] - 9s 221ms/step - loss: 1.4080 - accuracy: 0.5208 - val_loss: 1.9264 - val_accuracy: 0.3679\n",
      "Epoch 10/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.2883 - accuracy: 0.5419\n",
      "Epoch 10: val_accuracy improved from 0.39232 to 0.44509, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 9s 221ms/step - loss: 1.2883 - accuracy: 0.5419 - val_loss: 1.6668 - val_accuracy: 0.4451\n",
      "Epoch 11/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.3740 - accuracy: 0.5212\n",
      "Epoch 11: val_accuracy did not improve from 0.44509\n",
      "41/41 [==============================] - 8s 195ms/step - loss: 1.3740 - accuracy: 0.5212 - val_loss: 1.6817 - val_accuracy: 0.4055\n",
      "Epoch 12/20\n",
      "40/41 [============================>.] - ETA: 0s - loss: 1.3914 - accuracy: 0.5059\n",
      "Epoch 12: val_accuracy did not improve from 0.44509\n",
      "41/41 [==============================] - 8s 191ms/step - loss: 1.3938 - accuracy: 0.5053 - val_loss: 1.9175 - val_accuracy: 0.4133\n",
      "Epoch 13/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.3847 - accuracy: 0.5107\n",
      "Epoch 13: val_accuracy did not improve from 0.44509\n",
      "41/41 [==============================] - 8s 199ms/step - loss: 1.3847 - accuracy: 0.5107 - val_loss: 1.7805 - val_accuracy: 0.4253\n",
      "Epoch 14/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.3257 - accuracy: 0.5411\n",
      "Epoch 14: val_accuracy did not improve from 0.44509\n",
      "41/41 [==============================] - 8s 190ms/step - loss: 1.3257 - accuracy: 0.5411 - val_loss: 1.7474 - val_accuracy: 0.4334\n",
      "Epoch 15/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1761 - accuracy: 0.5980\n",
      "Epoch 15: val_accuracy improved from 0.44509 to 0.45518, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 8s 193ms/step - loss: 1.1761 - accuracy: 0.5980 - val_loss: 1.7635 - val_accuracy: 0.4552\n",
      "Epoch 16/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1862 - accuracy: 0.5894\n",
      "Epoch 16: val_accuracy did not improve from 0.45518\n",
      "41/41 [==============================] - 9s 217ms/step - loss: 1.1862 - accuracy: 0.5894 - val_loss: 1.7019 - val_accuracy: 0.4509\n",
      "Epoch 17/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1343 - accuracy: 0.6108\n",
      "Epoch 17: val_accuracy did not improve from 0.45518\n",
      "41/41 [==============================] - 8s 194ms/step - loss: 1.1343 - accuracy: 0.6108 - val_loss: 1.8153 - val_accuracy: 0.4366\n",
      "Epoch 18/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1626 - accuracy: 0.6116\n",
      "Epoch 18: val_accuracy improved from 0.45518 to 0.47303, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 9s 232ms/step - loss: 1.1626 - accuracy: 0.6116 - val_loss: 1.5351 - val_accuracy: 0.4730\n",
      "Epoch 19/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.2615 - accuracy: 0.5649\n",
      "Epoch 19: val_accuracy did not improve from 0.47303\n",
      "41/41 [==============================] - 9s 230ms/step - loss: 1.2615 - accuracy: 0.5649 - val_loss: 1.6847 - val_accuracy: 0.4672\n",
      "Epoch 20/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.2017 - accuracy: 0.5808\n",
      "Epoch 20: val_accuracy did not improve from 0.47303\n",
      "41/41 [==============================] - 10s 235ms/step - loss: 1.2017 - accuracy: 0.5808 - val_loss: 1.6592 - val_accuracy: 0.4695\n",
      "Epoch 1/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.5671 - accuracy: 0.1488\n",
      "Epoch 1: val_accuracy improved from -inf to 0.14009, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 52s 845ms/step - loss: 2.5671 - accuracy: 0.1488 - val_loss: 2.2306 - val_accuracy: 0.1401\n",
      "Epoch 2/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.1010 - accuracy: 0.2450\n",
      "Epoch 2: val_accuracy improved from 0.14009 to 0.19907, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 9s 424ms/step - loss: 2.1010 - accuracy: 0.2450 - val_loss: 2.1393 - val_accuracy: 0.1991\n",
      "Epoch 3/20\n",
      "20/21 [===========================>..] - ETA: 0s - loss: 1.8316 - accuracy: 0.3406\n",
      "Epoch 3: val_accuracy improved from 0.19907 to 0.20761, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 8s 403ms/step - loss: 1.8311 - accuracy: 0.3405 - val_loss: 2.1509 - val_accuracy: 0.2076\n",
      "Epoch 4/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.5950 - accuracy: 0.4242\n",
      "Epoch 4: val_accuracy improved from 0.20761 to 0.32945, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 9s 421ms/step - loss: 1.5950 - accuracy: 0.4242 - val_loss: 1.8797 - val_accuracy: 0.3295\n",
      "Epoch 5/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.5330 - accuracy: 0.4515\n",
      "Epoch 5: val_accuracy did not improve from 0.32945\n",
      "21/21 [==============================] - 9s 409ms/step - loss: 1.5330 - accuracy: 0.4515 - val_loss: 1.9664 - val_accuracy: 0.2953\n",
      "Epoch 6/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.4548 - accuracy: 0.4893\n",
      "Epoch 6: val_accuracy improved from 0.32945 to 0.38068, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 9s 430ms/step - loss: 1.4548 - accuracy: 0.4893 - val_loss: 1.7488 - val_accuracy: 0.3807\n",
      "Epoch 7/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.3758 - accuracy: 0.5197\n",
      "Epoch 7: val_accuracy improved from 0.38068 to 0.43694, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 8s 398ms/step - loss: 1.3758 - accuracy: 0.5197 - val_loss: 1.6834 - val_accuracy: 0.4369\n",
      "Epoch 8/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.3496 - accuracy: 0.5236\n",
      "Epoch 8: val_accuracy did not improve from 0.43694\n",
      "21/21 [==============================] - 7s 358ms/step - loss: 1.3496 - accuracy: 0.5236 - val_loss: 1.8110 - val_accuracy: 0.3516\n",
      "Epoch 9/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.2277 - accuracy: 0.5812\n",
      "Epoch 9: val_accuracy improved from 0.43694 to 0.44897, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 8s 366ms/step - loss: 1.2277 - accuracy: 0.5812 - val_loss: 1.6458 - val_accuracy: 0.4490\n",
      "Epoch 10/20\n",
      "20/21 [===========================>..] - ETA: 0s - loss: 1.2364 - accuracy: 0.5914\n",
      "Epoch 10: val_accuracy did not improve from 0.44897\n",
      "21/21 [==============================] - 7s 316ms/step - loss: 1.2394 - accuracy: 0.5914 - val_loss: 1.5695 - val_accuracy: 0.4474\n",
      "Epoch 11/20\n",
      "20/21 [===========================>..] - ETA: 0s - loss: 1.1675 - accuracy: 0.5988\n",
      "Epoch 11: val_accuracy improved from 0.44897 to 0.46178, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 7s 333ms/step - loss: 1.1689 - accuracy: 0.5984 - val_loss: 1.6020 - val_accuracy: 0.4618\n",
      "Epoch 12/20\n",
      "20/21 [===========================>..] - ETA: 0s - loss: 1.1841 - accuracy: 0.5906\n",
      "Epoch 12: val_accuracy did not improve from 0.46178\n",
      "21/21 [==============================] - 8s 378ms/step - loss: 1.1825 - accuracy: 0.5910 - val_loss: 1.7985 - val_accuracy: 0.4404\n",
      "Epoch 13/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.1548 - accuracy: 0.6124\n",
      "Epoch 13: val_accuracy did not improve from 0.46178\n",
      "21/21 [==============================] - 9s 423ms/step - loss: 1.1548 - accuracy: 0.6124 - val_loss: 1.7540 - val_accuracy: 0.4016\n",
      "Epoch 14/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.1715 - accuracy: 0.5988\n",
      "Epoch 14: val_accuracy did not improve from 0.46178\n",
      "21/21 [==============================] - 9s 428ms/step - loss: 1.1715 - accuracy: 0.5988 - val_loss: 1.6770 - val_accuracy: 0.4292\n",
      "Epoch 15/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.0952 - accuracy: 0.6323\n",
      "Epoch 15: val_accuracy did not improve from 0.46178\n",
      "21/21 [==============================] - 10s 462ms/step - loss: 1.0952 - accuracy: 0.6323 - val_loss: 1.6632 - val_accuracy: 0.4536\n",
      "Epoch 16/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.2033 - accuracy: 0.5949\n",
      "Epoch 16: val_accuracy did not improve from 0.46178\n",
      "21/21 [==============================] - 10s 477ms/step - loss: 1.2033 - accuracy: 0.5949 - val_loss: 1.7189 - val_accuracy: 0.4334\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.5731 - accuracy: 0.1013\n",
      "Epoch 1: val_accuracy improved from -inf to 0.10244, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 35s 181ms/step - loss: 2.5731 - accuracy: 0.1013 - val_loss: 2.5053 - val_accuracy: 0.1024\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.3737 - accuracy: 0.0962\n",
      "Epoch 2: val_accuracy did not improve from 0.10244\n",
      "81/81 [==============================] - 13s 166ms/step - loss: 2.3737 - accuracy: 0.0962 - val_loss: 2.3698 - val_accuracy: 0.1001\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.3725 - accuracy: 0.1025\n",
      "Epoch 3: val_accuracy did not improve from 0.10244\n",
      "81/81 [==============================] - 15s 183ms/step - loss: 2.3725 - accuracy: 0.1025 - val_loss: 2.4558 - val_accuracy: 0.0935\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.3902 - accuracy: 0.0966\n",
      "Epoch 4: val_accuracy improved from 0.10244 to 0.10322, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 16s 192ms/step - loss: 2.3902 - accuracy: 0.0966 - val_loss: 2.4214 - val_accuracy: 0.1032\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.3833 - accuracy: 0.1087\n",
      "Epoch 5: val_accuracy did not improve from 0.10322\n",
      "81/81 [==============================] - 14s 171ms/step - loss: 2.3833 - accuracy: 0.1087 - val_loss: 2.4916 - val_accuracy: 0.0904\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.3831 - accuracy: 0.0853\n",
      "Epoch 6: val_accuracy did not improve from 0.10322\n",
      "81/81 [==============================] - 13s 161ms/step - loss: 2.3831 - accuracy: 0.0853 - val_loss: 5.6856 - val_accuracy: 0.0986\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.3867 - accuracy: 0.1056\n",
      "Epoch 7: val_accuracy improved from 0.10322 to 0.10477, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 12s 147ms/step - loss: 2.3867 - accuracy: 0.1056 - val_loss: 3.7589 - val_accuracy: 0.1048\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.3866 - accuracy: 0.0951\n",
      "Epoch 8: val_accuracy did not improve from 0.10477\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 2.3866 - accuracy: 0.0951 - val_loss: 2.5252 - val_accuracy: 0.0990\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.3627 - accuracy: 0.0989\n",
      "Epoch 9: val_accuracy did not improve from 0.10477\n",
      "81/81 [==============================] - 14s 168ms/step - loss: 2.3627 - accuracy: 0.0989 - val_loss: 2.3958 - val_accuracy: 0.0955\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.4095 - accuracy: 0.0970\n",
      "Epoch 10: val_accuracy did not improve from 0.10477\n",
      "81/81 [==============================] - 14s 178ms/step - loss: 2.4095 - accuracy: 0.0970 - val_loss: 6.8336 - val_accuracy: 0.1001\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.5060 - accuracy: 0.0974\n",
      "Epoch 11: val_accuracy improved from 0.10477 to 0.10633, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 14s 177ms/step - loss: 2.5060 - accuracy: 0.0974 - val_loss: 22.4202 - val_accuracy: 0.1063\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.4250 - accuracy: 0.1025\n",
      "Epoch 12: val_accuracy did not improve from 0.10633\n",
      "81/81 [==============================] - 12s 152ms/step - loss: 2.4250 - accuracy: 0.1025 - val_loss: 4.4623 - val_accuracy: 0.1013\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.3970 - accuracy: 0.1005\n",
      "Epoch 13: val_accuracy did not improve from 0.10633\n",
      "81/81 [==============================] - 11s 139ms/step - loss: 2.3970 - accuracy: 0.1005 - val_loss: 4.0513 - val_accuracy: 0.1009\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.3930 - accuracy: 0.0915\n",
      "Epoch 14: val_accuracy did not improve from 0.10633\n",
      "81/81 [==============================] - 12s 147ms/step - loss: 2.3930 - accuracy: 0.0915 - val_loss: 2.6680 - val_accuracy: 0.0997\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.4914 - accuracy: 0.0857\n",
      "Epoch 15: val_accuracy did not improve from 0.10633\n",
      "81/81 [==============================] - 13s 166ms/step - loss: 2.4914 - accuracy: 0.0857 - val_loss: 24.6893 - val_accuracy: 0.0997\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.5239 - accuracy: 0.1040\n",
      "Epoch 16: val_accuracy did not improve from 0.10633\n",
      "81/81 [==============================] - 15s 181ms/step - loss: 2.5239 - accuracy: 0.1040 - val_loss: 5.4367 - val_accuracy: 0.1013\n",
      "Epoch 1/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.5834 - accuracy: 0.1102\n",
      "Epoch 1: val_accuracy improved from -inf to 0.09507, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 52s 487ms/step - loss: 2.5834 - accuracy: 0.1102 - val_loss: 2.3635 - val_accuracy: 0.0951\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.3803 - accuracy: 0.1028\n",
      "Epoch 2: val_accuracy improved from 0.09507 to 0.09546, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 10s 252ms/step - loss: 2.3803 - accuracy: 0.1028 - val_loss: 2.3463 - val_accuracy: 0.0955\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.3834 - accuracy: 0.0962\n",
      "Epoch 3: val_accuracy improved from 0.09546 to 0.10089, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 12s 292ms/step - loss: 2.3834 - accuracy: 0.0962 - val_loss: 2.3852 - val_accuracy: 0.1009\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.3728 - accuracy: 0.1056\n",
      "Epoch 4: val_accuracy improved from 0.10089 to 0.10283, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 12s 302ms/step - loss: 2.3728 - accuracy: 0.1056 - val_loss: 2.5600 - val_accuracy: 0.1028\n",
      "Epoch 5/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.3776 - accuracy: 0.0923\n",
      "Epoch 5: val_accuracy did not improve from 0.10283\n",
      "41/41 [==============================] - 12s 300ms/step - loss: 2.3776 - accuracy: 0.0923 - val_loss: 2.3367 - val_accuracy: 0.1005\n",
      "Epoch 6/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.3603 - accuracy: 0.0986\n",
      "Epoch 6: val_accuracy did not improve from 0.10283\n",
      "41/41 [==============================] - 12s 299ms/step - loss: 2.3603 - accuracy: 0.0986 - val_loss: 2.4936 - val_accuracy: 0.0997\n",
      "Epoch 7/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.3775 - accuracy: 0.0962\n",
      "Epoch 7: val_accuracy did not improve from 0.10283\n",
      "41/41 [==============================] - 12s 300ms/step - loss: 2.3775 - accuracy: 0.0962 - val_loss: 2.5824 - val_accuracy: 0.1013\n",
      "Epoch 8/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.3563 - accuracy: 0.1001\n",
      "Epoch 8: val_accuracy did not improve from 0.10283\n",
      "41/41 [==============================] - 12s 296ms/step - loss: 2.3563 - accuracy: 0.1001 - val_loss: 2.4090 - val_accuracy: 0.1009\n",
      "Epoch 9/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.3729 - accuracy: 0.0915\n",
      "Epoch 9: val_accuracy did not improve from 0.10283\n",
      "41/41 [==============================] - 12s 298ms/step - loss: 2.3729 - accuracy: 0.0915 - val_loss: 2.4179 - val_accuracy: 0.0958\n",
      "Epoch 1/20\n",
      "20/21 [===========================>..] - ETA: 0s - loss: 2.6114 - accuracy: 0.1059\n",
      "Epoch 1: val_accuracy improved from -inf to 0.09934, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 30s 602ms/step - loss: 2.6111 - accuracy: 0.1056 - val_loss: 2.3548 - val_accuracy: 0.0993\n",
      "Epoch 2/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.3831 - accuracy: 0.1063\n",
      "Epoch 2: val_accuracy did not improve from 0.09934\n",
      "21/21 [==============================] - 12s 598ms/step - loss: 2.3831 - accuracy: 0.1063 - val_loss: 2.4275 - val_accuracy: 0.0993\n",
      "Epoch 3/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.3578 - accuracy: 0.0978\n",
      "Epoch 3: val_accuracy did not improve from 0.09934\n",
      "21/21 [==============================] - 15s 705ms/step - loss: 2.3578 - accuracy: 0.0978 - val_loss: 2.3936 - val_accuracy: 0.0993\n",
      "Epoch 4/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.3415 - accuracy: 0.1001\n",
      "Epoch 4: val_accuracy improved from 0.09934 to 0.11059, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 15s 720ms/step - loss: 2.3415 - accuracy: 0.1001 - val_loss: 2.3818 - val_accuracy: 0.1106\n",
      "Epoch 5/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.3536 - accuracy: 0.0954\n",
      "Epoch 5: val_accuracy did not improve from 0.11059\n",
      "21/21 [==============================] - 14s 694ms/step - loss: 2.3536 - accuracy: 0.0954 - val_loss: 2.3550 - val_accuracy: 0.0993\n",
      "Epoch 6/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.3374 - accuracy: 0.0978\n",
      "Epoch 6: val_accuracy did not improve from 0.11059\n",
      "21/21 [==============================] - 15s 713ms/step - loss: 2.3374 - accuracy: 0.0978 - val_loss: 2.3727 - val_accuracy: 0.0993\n",
      "Epoch 7/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.3247 - accuracy: 0.1067\n",
      "Epoch 7: val_accuracy did not improve from 0.11059\n",
      "21/21 [==============================] - 15s 695ms/step - loss: 2.3247 - accuracy: 0.1067 - val_loss: 2.3616 - val_accuracy: 0.0993\n",
      "Epoch 8/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.3453 - accuracy: 0.0877\n",
      "Epoch 8: val_accuracy did not improve from 0.11059\n",
      "21/21 [==============================] - 15s 717ms/step - loss: 2.3453 - accuracy: 0.0877 - val_loss: 2.3687 - val_accuracy: 0.0993\n",
      "Epoch 9/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.3455 - accuracy: 0.0993\n",
      "Epoch 9: val_accuracy did not improve from 0.11059\n",
      "21/21 [==============================] - 14s 659ms/step - loss: 2.3455 - accuracy: 0.0993 - val_loss: 2.3236 - val_accuracy: 0.1013\n",
      "Epoch 1/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.5246 - accuracy: 0.1543\n",
      "Epoch 1: val_accuracy improved from -inf to 0.12922, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 43s 207ms/step - loss: 2.5246 - accuracy: 0.1543 - val_loss: 2.2589 - val_accuracy: 0.1292\n",
      "Epoch 2/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.0647 - accuracy: 0.2875\n",
      "Epoch 2: val_accuracy improved from 0.12922 to 0.27978, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 13s 159ms/step - loss: 2.0647 - accuracy: 0.2875 - val_loss: 2.0380 - val_accuracy: 0.2798\n",
      "Epoch 3/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.6757 - accuracy: 0.4176\n",
      "Epoch 3: val_accuracy improved from 0.27978 to 0.42569, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 13s 163ms/step - loss: 1.6757 - accuracy: 0.4176 - val_loss: 1.6900 - val_accuracy: 0.4257\n",
      "Epoch 4/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.3559 - accuracy: 0.5279\n",
      "Epoch 4: val_accuracy improved from 0.42569 to 0.46061, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 14s 176ms/step - loss: 1.3559 - accuracy: 0.5279 - val_loss: 1.6090 - val_accuracy: 0.4606\n",
      "Epoch 5/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.1214 - accuracy: 0.6042\n",
      "Epoch 5: val_accuracy improved from 0.46061 to 0.47031, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 15s 187ms/step - loss: 1.1214 - accuracy: 0.6042 - val_loss: 1.6982 - val_accuracy: 0.4703\n",
      "Epoch 6/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.9493 - accuracy: 0.6767\n",
      "Epoch 6: val_accuracy improved from 0.47031 to 0.51494, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 15s 188ms/step - loss: 0.9493 - accuracy: 0.6767 - val_loss: 1.6361 - val_accuracy: 0.5149\n",
      "Epoch 7/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.8148 - accuracy: 0.7215\n",
      "Epoch 7: val_accuracy improved from 0.51494 to 0.54016, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 15s 186ms/step - loss: 0.8148 - accuracy: 0.7215 - val_loss: 1.6014 - val_accuracy: 0.5402\n",
      "Epoch 8/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.6826 - accuracy: 0.7748\n",
      "Epoch 8: val_accuracy did not improve from 0.54016\n",
      "81/81 [==============================] - 15s 184ms/step - loss: 0.6826 - accuracy: 0.7748 - val_loss: 1.6080 - val_accuracy: 0.5305\n",
      "Epoch 9/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.5691 - accuracy: 0.8118\n",
      "Epoch 9: val_accuracy improved from 0.54016 to 0.54598, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 15s 188ms/step - loss: 0.5691 - accuracy: 0.8118 - val_loss: 1.6739 - val_accuracy: 0.5460\n",
      "Epoch 10/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.5164 - accuracy: 0.8352\n",
      "Epoch 10: val_accuracy improved from 0.54598 to 0.54831, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 15s 185ms/step - loss: 0.5164 - accuracy: 0.8352 - val_loss: 1.7309 - val_accuracy: 0.5483\n",
      "Epoch 11/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.4387 - accuracy: 0.8629\n",
      "Epoch 11: val_accuracy improved from 0.54831 to 0.56461, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 15s 185ms/step - loss: 0.4387 - accuracy: 0.8629 - val_loss: 1.7777 - val_accuracy: 0.5646\n",
      "Epoch 12/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.4265 - accuracy: 0.8625\n",
      "Epoch 12: val_accuracy did not improve from 0.56461\n",
      "81/81 [==============================] - 15s 184ms/step - loss: 0.4265 - accuracy: 0.8625 - val_loss: 1.8109 - val_accuracy: 0.5537\n",
      "Epoch 13/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.4008 - accuracy: 0.8660\n",
      "Epoch 13: val_accuracy did not improve from 0.56461\n",
      "81/81 [==============================] - 15s 184ms/step - loss: 0.4008 - accuracy: 0.8660 - val_loss: 1.8998 - val_accuracy: 0.5471\n",
      "Epoch 14/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.3686 - accuracy: 0.8847\n",
      "Epoch 14: val_accuracy did not improve from 0.56461\n",
      "81/81 [==============================] - 14s 175ms/step - loss: 0.3686 - accuracy: 0.8847 - val_loss: 1.9645 - val_accuracy: 0.5394\n",
      "Epoch 15/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.3331 - accuracy: 0.8890\n",
      "Epoch 15: val_accuracy did not improve from 0.56461\n",
      "81/81 [==============================] - 13s 164ms/step - loss: 0.3331 - accuracy: 0.8890 - val_loss: 2.0057 - val_accuracy: 0.5363\n",
      "Epoch 16/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2827 - accuracy: 0.9077\n",
      "Epoch 16: val_accuracy did not improve from 0.56461\n",
      "81/81 [==============================] - 13s 159ms/step - loss: 0.2827 - accuracy: 0.9077 - val_loss: 1.9548 - val_accuracy: 0.5572\n",
      "Epoch 1/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.6360 - accuracy: 0.1504\n",
      "Epoch 1: val_accuracy improved from -inf to 0.10477, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 37s 425ms/step - loss: 2.6360 - accuracy: 0.1504 - val_loss: 2.2909 - val_accuracy: 0.1048\n",
      "Epoch 2/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.1509 - accuracy: 0.2645\n",
      "Epoch 2: val_accuracy improved from 0.10477 to 0.14086, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 12s 292ms/step - loss: 2.1509 - accuracy: 0.2645 - val_loss: 2.2656 - val_accuracy: 0.1409\n",
      "Epoch 3/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.9209 - accuracy: 0.3370\n",
      "Epoch 3: val_accuracy improved from 0.14086 to 0.18937, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 12s 290ms/step - loss: 1.9209 - accuracy: 0.3370 - val_loss: 2.1880 - val_accuracy: 0.1894\n",
      "Epoch 4/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.6122 - accuracy: 0.4383\n",
      "Epoch 4: val_accuracy improved from 0.18937 to 0.26853, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 12s 291ms/step - loss: 1.6122 - accuracy: 0.4383 - val_loss: 2.0110 - val_accuracy: 0.2685\n",
      "Epoch 5/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.3423 - accuracy: 0.5399\n",
      "Epoch 5: val_accuracy improved from 0.26853 to 0.39426, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 12s 294ms/step - loss: 1.3423 - accuracy: 0.5399 - val_loss: 1.7736 - val_accuracy: 0.3943\n",
      "Epoch 6/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1583 - accuracy: 0.6030\n",
      "Epoch 6: val_accuracy improved from 0.39426 to 0.44975, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 12s 297ms/step - loss: 1.1583 - accuracy: 0.6030 - val_loss: 1.5900 - val_accuracy: 0.4497\n",
      "Epoch 7/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0017 - accuracy: 0.6541\n",
      "Epoch 7: val_accuracy improved from 0.44975 to 0.47963, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 12s 293ms/step - loss: 1.0017 - accuracy: 0.6541 - val_loss: 1.5808 - val_accuracy: 0.4796\n",
      "Epoch 8/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.8529 - accuracy: 0.7145\n",
      "Epoch 8: val_accuracy improved from 0.47963 to 0.50213, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 12s 293ms/step - loss: 0.8529 - accuracy: 0.7145 - val_loss: 1.6361 - val_accuracy: 0.5021\n",
      "Epoch 9/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.7451 - accuracy: 0.7499\n",
      "Epoch 9: val_accuracy improved from 0.50213 to 0.50757, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 11s 264ms/step - loss: 0.7451 - accuracy: 0.7499 - val_loss: 1.7299 - val_accuracy: 0.5076\n",
      "Epoch 10/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.6524 - accuracy: 0.7776\n",
      "Epoch 10: val_accuracy improved from 0.50757 to 0.52658, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 12s 289ms/step - loss: 0.6524 - accuracy: 0.7776 - val_loss: 1.7877 - val_accuracy: 0.5266\n",
      "Epoch 11/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.5289 - accuracy: 0.8231\n",
      "Epoch 11: val_accuracy did not improve from 0.52658\n",
      "41/41 [==============================] - 13s 309ms/step - loss: 0.5289 - accuracy: 0.8231 - val_loss: 1.8702 - val_accuracy: 0.5111\n",
      "Epoch 12/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.4994 - accuracy: 0.8344\n",
      "Epoch 12: val_accuracy improved from 0.52658 to 0.53240, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 13s 324ms/step - loss: 0.4994 - accuracy: 0.8344 - val_loss: 1.9207 - val_accuracy: 0.5324\n",
      "Epoch 13/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.4304 - accuracy: 0.8578\n",
      "Epoch 13: val_accuracy did not improve from 0.53240\n",
      "41/41 [==============================] - 13s 325ms/step - loss: 0.4304 - accuracy: 0.8578 - val_loss: 1.9905 - val_accuracy: 0.5099\n",
      "Epoch 14/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.4606 - accuracy: 0.8539\n",
      "Epoch 14: val_accuracy improved from 0.53240 to 0.54327, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 13s 326ms/step - loss: 0.4606 - accuracy: 0.8539 - val_loss: 1.9009 - val_accuracy: 0.5433\n",
      "Epoch 15/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.3480 - accuracy: 0.8862\n",
      "Epoch 15: val_accuracy did not improve from 0.54327\n",
      "41/41 [==============================] - 13s 326ms/step - loss: 0.3480 - accuracy: 0.8862 - val_loss: 1.9832 - val_accuracy: 0.5398\n",
      "Epoch 16/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.3060 - accuracy: 0.8952\n",
      "Epoch 16: val_accuracy did not improve from 0.54327\n",
      "41/41 [==============================] - 13s 318ms/step - loss: 0.3060 - accuracy: 0.8952 - val_loss: 2.0041 - val_accuracy: 0.5409\n",
      "Epoch 17/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.3186 - accuracy: 0.8944\n",
      "Epoch 17: val_accuracy did not improve from 0.54327\n",
      "41/41 [==============================] - 13s 307ms/step - loss: 0.3186 - accuracy: 0.8944 - val_loss: 2.1017 - val_accuracy: 0.5277\n",
      "Epoch 18/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2430 - accuracy: 0.9201\n",
      "Epoch 18: val_accuracy improved from 0.54327 to 0.55568, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 12s 286ms/step - loss: 0.2430 - accuracy: 0.9201 - val_loss: 2.0893 - val_accuracy: 0.5557\n",
      "Epoch 19/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2655 - accuracy: 0.9155\n",
      "Epoch 19: val_accuracy did not improve from 0.55568\n",
      "41/41 [==============================] - 12s 292ms/step - loss: 0.2655 - accuracy: 0.9155 - val_loss: 2.2462 - val_accuracy: 0.5281\n",
      "Epoch 20/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2757 - accuracy: 0.9034\n",
      "Epoch 20: val_accuracy did not improve from 0.55568\n",
      "41/41 [==============================] - 12s 285ms/step - loss: 0.2757 - accuracy: 0.9034 - val_loss: 2.2178 - val_accuracy: 0.5320\n",
      "Epoch 21/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2279 - accuracy: 0.9310\n",
      "Epoch 21: val_accuracy did not improve from 0.55568\n",
      "41/41 [==============================] - 13s 312ms/step - loss: 0.2279 - accuracy: 0.9310 - val_loss: 2.1610 - val_accuracy: 0.5499\n",
      "Epoch 22/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2038 - accuracy: 0.9318\n",
      "Epoch 22: val_accuracy did not improve from 0.55568\n",
      "41/41 [==============================] - 13s 318ms/step - loss: 0.2038 - accuracy: 0.9318 - val_loss: 2.1935 - val_accuracy: 0.5456\n",
      "Epoch 23/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2454 - accuracy: 0.9287\n",
      "Epoch 23: val_accuracy did not improve from 0.55568\n",
      "41/41 [==============================] - 14s 346ms/step - loss: 0.2454 - accuracy: 0.9287 - val_loss: 2.2897 - val_accuracy: 0.5460\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.7059 - accuracy: 0.1402\n",
      "Epoch 1: val_accuracy improved from -inf to 0.13077, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 51s 845ms/step - loss: 2.7059 - accuracy: 0.1402 - val_loss: 2.2947 - val_accuracy: 0.1308\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.2263 - accuracy: 0.2232\n",
      "Epoch 2: val_accuracy improved from 0.13077 to 0.15095, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 13s 634ms/step - loss: 2.2263 - accuracy: 0.2232 - val_loss: 2.2875 - val_accuracy: 0.1510\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.0587 - accuracy: 0.2883\n",
      "Epoch 3: val_accuracy improved from 0.15095 to 0.16880, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 12s 590ms/step - loss: 2.0587 - accuracy: 0.2883 - val_loss: 2.2646 - val_accuracy: 0.1688\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.8285 - accuracy: 0.3607\n",
      "Epoch 4: val_accuracy improved from 0.16880 to 0.18510, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 12s 584ms/step - loss: 1.8285 - accuracy: 0.3607 - val_loss: 2.2369 - val_accuracy: 0.1851\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.6527 - accuracy: 0.4316\n",
      "Epoch 5: val_accuracy improved from 0.18510 to 0.22390, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 12s 588ms/step - loss: 1.6527 - accuracy: 0.4316 - val_loss: 2.1652 - val_accuracy: 0.2239\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.4743 - accuracy: 0.4753\n",
      "Epoch 6: val_accuracy improved from 0.22390 to 0.24835, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 13s 626ms/step - loss: 1.4743 - accuracy: 0.4753 - val_loss: 2.0824 - val_accuracy: 0.2484\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.2961 - accuracy: 0.5372\n",
      "Epoch 7: val_accuracy improved from 0.24835 to 0.26426, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 11s 536ms/step - loss: 1.2961 - accuracy: 0.5372 - val_loss: 2.0694 - val_accuracy: 0.2643\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.1884 - accuracy: 0.5925\n",
      "Epoch 8: val_accuracy improved from 0.26426 to 0.32906, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 13s 628ms/step - loss: 1.1884 - accuracy: 0.5925 - val_loss: 1.9450 - val_accuracy: 0.3291\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.0855 - accuracy: 0.6299\n",
      "Epoch 9: val_accuracy improved from 0.32906 to 0.38417, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 14s 666ms/step - loss: 1.0855 - accuracy: 0.6299 - val_loss: 1.8302 - val_accuracy: 0.3842\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.9752 - accuracy: 0.6626\n",
      "Epoch 10: val_accuracy improved from 0.38417 to 0.39853, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 14s 675ms/step - loss: 0.9752 - accuracy: 0.6626 - val_loss: 1.8587 - val_accuracy: 0.3985\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.8343 - accuracy: 0.7125\n",
      "Epoch 11: val_accuracy improved from 0.39853 to 0.43345, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 14s 677ms/step - loss: 0.8343 - accuracy: 0.7125 - val_loss: 1.7842 - val_accuracy: 0.4334\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.8041 - accuracy: 0.7261\n",
      "Epoch 12: val_accuracy did not improve from 0.43345\n",
      "21/21 [==============================] - 14s 662ms/step - loss: 0.8041 - accuracy: 0.7261 - val_loss: 1.8201 - val_accuracy: 0.4245\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.7267 - accuracy: 0.7480\n",
      "Epoch 13: val_accuracy improved from 0.43345 to 0.47536, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 14s 677ms/step - loss: 0.7267 - accuracy: 0.7480 - val_loss: 1.7092 - val_accuracy: 0.4754\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.6424 - accuracy: 0.7850\n",
      "Epoch 14: val_accuracy did not improve from 0.47536\n",
      "21/21 [==============================] - 14s 664ms/step - loss: 0.6424 - accuracy: 0.7850 - val_loss: 1.8439 - val_accuracy: 0.4641\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.5258 - accuracy: 0.8259\n",
      "Epoch 15: val_accuracy improved from 0.47536 to 0.50446, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 12s 586ms/step - loss: 0.5258 - accuracy: 0.8259 - val_loss: 1.7193 - val_accuracy: 0.5045\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.5122 - accuracy: 0.8286\n",
      "Epoch 16: val_accuracy did not improve from 0.50446\n",
      "21/21 [==============================] - 12s 580ms/step - loss: 0.5122 - accuracy: 0.8286 - val_loss: 1.8367 - val_accuracy: 0.4975\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.5330 - accuracy: 0.8216\n",
      "Epoch 17: val_accuracy improved from 0.50446 to 0.51921, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 13s 638ms/step - loss: 0.5330 - accuracy: 0.8216 - val_loss: 1.7752 - val_accuracy: 0.5192\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.4866 - accuracy: 0.8360\n",
      "Epoch 18: val_accuracy did not improve from 0.51921\n",
      "21/21 [==============================] - 14s 660ms/step - loss: 0.4866 - accuracy: 0.8360 - val_loss: 1.8370 - val_accuracy: 0.5165\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.4260 - accuracy: 0.8652\n",
      "Epoch 19: val_accuracy improved from 0.51921 to 0.53434, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 14s 667ms/step - loss: 0.4260 - accuracy: 0.8652 - val_loss: 1.8580 - val_accuracy: 0.5343\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.4381 - accuracy: 0.8524\n",
      "Epoch 20: val_accuracy did not improve from 0.53434\n",
      "21/21 [==============================] - 14s 662ms/step - loss: 0.4381 - accuracy: 0.8524 - val_loss: 1.9133 - val_accuracy: 0.5270\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.3992 - accuracy: 0.8687\n",
      "Epoch 21: val_accuracy improved from 0.53434 to 0.53512, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 13s 607ms/step - loss: 0.3992 - accuracy: 0.8687 - val_loss: 1.9429 - val_accuracy: 0.5351\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.3311 - accuracy: 0.8968\n",
      "Epoch 22: val_accuracy did not improve from 0.53512\n",
      "21/21 [==============================] - 12s 562ms/step - loss: 0.3311 - accuracy: 0.8968 - val_loss: 2.0108 - val_accuracy: 0.5328\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2708 - accuracy: 0.9147\n",
      "Epoch 23: val_accuracy improved from 0.53512 to 0.54676, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 12s 569ms/step - loss: 0.2708 - accuracy: 0.9147 - val_loss: 1.9880 - val_accuracy: 0.5468\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2921 - accuracy: 0.9085\n",
      "Epoch 24: val_accuracy did not improve from 0.54676\n",
      "21/21 [==============================] - 13s 604ms/step - loss: 0.2921 - accuracy: 0.9085 - val_loss: 2.0516 - val_accuracy: 0.5398\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.3245 - accuracy: 0.8909\n",
      "Epoch 25: val_accuracy did not improve from 0.54676\n",
      "21/21 [==============================] - 12s 590ms/step - loss: 0.3245 - accuracy: 0.8909 - val_loss: 2.3453 - val_accuracy: 0.5087\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.4245 - accuracy: 0.8633\n",
      "Epoch 26: val_accuracy did not improve from 0.54676\n",
      "21/21 [==============================] - 13s 643ms/step - loss: 0.4245 - accuracy: 0.8633 - val_loss: 2.1507 - val_accuracy: 0.5285\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.3193 - accuracy: 0.8964\n",
      "Epoch 27: val_accuracy did not improve from 0.54676\n",
      "21/21 [==============================] - 13s 645ms/step - loss: 0.3193 - accuracy: 0.8964 - val_loss: 2.0949 - val_accuracy: 0.5340\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.3144 - accuracy: 0.8999\n",
      "Epoch 28: val_accuracy did not improve from 0.54676\n",
      "21/21 [==============================] - 12s 570ms/step - loss: 0.3144 - accuracy: 0.8999 - val_loss: 2.1149 - val_accuracy: 0.5289\n",
      "Epoch 1/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.4596 - accuracy: 0.1445\n",
      "Epoch 1: val_accuracy improved from -inf to 0.10050, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 34s 241ms/step - loss: 2.4596 - accuracy: 0.1445 - val_loss: 2.3260 - val_accuracy: 0.1005\n",
      "Epoch 2/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.1198 - accuracy: 0.2080\n",
      "Epoch 2: val_accuracy improved from 0.10050 to 0.22778, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 18s 225ms/step - loss: 2.1198 - accuracy: 0.2080 - val_loss: 2.0625 - val_accuracy: 0.2278\n",
      "Epoch 3/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.9463 - accuracy: 0.2832\n",
      "Epoch 3: val_accuracy improved from 0.22778 to 0.25340, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 17s 215ms/step - loss: 1.9463 - accuracy: 0.2832 - val_loss: 2.0224 - val_accuracy: 0.2534\n",
      "Epoch 4/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.7765 - accuracy: 0.3498\n",
      "Epoch 4: val_accuracy improved from 0.25340 to 0.28716, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 17s 211ms/step - loss: 1.7765 - accuracy: 0.3498 - val_loss: 2.0056 - val_accuracy: 0.2872\n",
      "Epoch 5/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.6870 - accuracy: 0.4098\n",
      "Epoch 5: val_accuracy improved from 0.28716 to 0.36477, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 16s 199ms/step - loss: 1.6870 - accuracy: 0.4098 - val_loss: 1.7739 - val_accuracy: 0.3648\n",
      "Epoch 6/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.6360 - accuracy: 0.4188\n",
      "Epoch 6: val_accuracy did not improve from 0.36477\n",
      "81/81 [==============================] - 16s 193ms/step - loss: 1.6360 - accuracy: 0.4188 - val_loss: 1.9137 - val_accuracy: 0.3535\n",
      "Epoch 7/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.6308 - accuracy: 0.4172\n",
      "Epoch 7: val_accuracy improved from 0.36477 to 0.37136, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 16s 201ms/step - loss: 1.6308 - accuracy: 0.4172 - val_loss: 1.8141 - val_accuracy: 0.3714\n",
      "Epoch 8/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.5281 - accuracy: 0.4589\n",
      "Epoch 8: val_accuracy improved from 0.37136 to 0.39503, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 17s 211ms/step - loss: 1.5281 - accuracy: 0.4589 - val_loss: 1.7918 - val_accuracy: 0.3950\n",
      "Epoch 9/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.5010 - accuracy: 0.4671\n",
      "Epoch 9: val_accuracy did not improve from 0.39503\n",
      "81/81 [==============================] - 18s 228ms/step - loss: 1.5010 - accuracy: 0.4671 - val_loss: 1.9750 - val_accuracy: 0.3741\n",
      "Epoch 10/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.4614 - accuracy: 0.4893\n",
      "Epoch 10: val_accuracy improved from 0.39503 to 0.39775, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 18s 227ms/step - loss: 1.4614 - accuracy: 0.4893 - val_loss: 1.7190 - val_accuracy: 0.3977\n",
      "Epoch 11/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.4468 - accuracy: 0.4877\n",
      "Epoch 11: val_accuracy did not improve from 0.39775\n",
      "81/81 [==============================] - 18s 228ms/step - loss: 1.4468 - accuracy: 0.4877 - val_loss: 2.2380 - val_accuracy: 0.2961\n",
      "Epoch 12/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.4363 - accuracy: 0.4776\n",
      "Epoch 12: val_accuracy did not improve from 0.39775\n",
      "81/81 [==============================] - 16s 204ms/step - loss: 1.4363 - accuracy: 0.4776 - val_loss: 1.8583 - val_accuracy: 0.3908\n",
      "Epoch 13/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.4018 - accuracy: 0.5010\n",
      "Epoch 13: val_accuracy improved from 0.39775 to 0.41870, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 15s 181ms/step - loss: 1.4018 - accuracy: 0.5010 - val_loss: 1.8062 - val_accuracy: 0.4187\n",
      "Epoch 14/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.4051 - accuracy: 0.4998\n",
      "Epoch 14: val_accuracy improved from 0.41870 to 0.43617, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 17s 210ms/step - loss: 1.4051 - accuracy: 0.4998 - val_loss: 1.6800 - val_accuracy: 0.4362\n",
      "Epoch 15/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.4053 - accuracy: 0.5014\n",
      "Epoch 15: val_accuracy did not improve from 0.43617\n",
      "81/81 [==============================] - 18s 219ms/step - loss: 1.4053 - accuracy: 0.5014 - val_loss: 1.6897 - val_accuracy: 0.4191\n",
      "Epoch 16/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.3913 - accuracy: 0.5111\n",
      "Epoch 16: val_accuracy did not improve from 0.43617\n",
      "81/81 [==============================] - 19s 234ms/step - loss: 1.3913 - accuracy: 0.5111 - val_loss: 2.0820 - val_accuracy: 0.3795\n",
      "Epoch 17/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.3791 - accuracy: 0.5154\n",
      "Epoch 17: val_accuracy did not improve from 0.43617\n",
      "81/81 [==============================] - 19s 233ms/step - loss: 1.3791 - accuracy: 0.5154 - val_loss: 2.0508 - val_accuracy: 0.3469\n",
      "Epoch 18/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.4148 - accuracy: 0.4959\n",
      "Epoch 18: val_accuracy did not improve from 0.43617\n",
      "81/81 [==============================] - 19s 234ms/step - loss: 1.4148 - accuracy: 0.4959 - val_loss: 1.8055 - val_accuracy: 0.4241\n",
      "Epoch 19/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.3704 - accuracy: 0.5228\n",
      "Epoch 19: val_accuracy improved from 0.43617 to 0.43733, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 19s 237ms/step - loss: 1.3704 - accuracy: 0.5228 - val_loss: 1.7510 - val_accuracy: 0.4373\n",
      "Epoch 20/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.3235 - accuracy: 0.5485\n",
      "Epoch 20: val_accuracy improved from 0.43733 to 0.47187, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 19s 234ms/step - loss: 1.3235 - accuracy: 0.5485 - val_loss: 1.6598 - val_accuracy: 0.4719\n",
      "Epoch 21/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.3473 - accuracy: 0.5364\n",
      "Epoch 21: val_accuracy did not improve from 0.47187\n",
      "81/81 [==============================] - 16s 203ms/step - loss: 1.3473 - accuracy: 0.5364 - val_loss: 1.7082 - val_accuracy: 0.4334\n",
      "Epoch 22/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.3591 - accuracy: 0.5271\n",
      "Epoch 22: val_accuracy did not improve from 0.47187\n",
      "81/81 [==============================] - 17s 216ms/step - loss: 1.3591 - accuracy: 0.5271 - val_loss: 1.7807 - val_accuracy: 0.4303\n",
      "Epoch 23/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.3137 - accuracy: 0.5411\n",
      "Epoch 23: val_accuracy did not improve from 0.47187\n",
      "81/81 [==============================] - 18s 219ms/step - loss: 1.3137 - accuracy: 0.5411 - val_loss: 1.6885 - val_accuracy: 0.4428\n",
      "Epoch 24/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.3263 - accuracy: 0.5450\n",
      "Epoch 24: val_accuracy did not improve from 0.47187\n",
      "81/81 [==============================] - 18s 220ms/step - loss: 1.3263 - accuracy: 0.5450 - val_loss: 1.8339 - val_accuracy: 0.4063\n",
      "Epoch 25/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.3844 - accuracy: 0.5236\n",
      "Epoch 25: val_accuracy did not improve from 0.47187\n",
      "81/81 [==============================] - 17s 214ms/step - loss: 1.3844 - accuracy: 0.5236 - val_loss: 1.6723 - val_accuracy: 0.4311\n",
      "Epoch 1/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.4093 - accuracy: 0.1854\n",
      "Epoch 1: val_accuracy improved from -inf to 0.19092, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 68s 693ms/step - loss: 2.4093 - accuracy: 0.1854 - val_loss: 2.1717 - val_accuracy: 0.1909\n",
      "Epoch 2/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.9636 - accuracy: 0.2750\n",
      "Epoch 2: val_accuracy improved from 0.19092 to 0.22119, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 15s 360ms/step - loss: 1.9636 - accuracy: 0.2750 - val_loss: 2.0975 - val_accuracy: 0.2212\n",
      "Epoch 3/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.7785 - accuracy: 0.3584\n",
      "Epoch 3: val_accuracy improved from 0.22119 to 0.36088, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 17s 418ms/step - loss: 1.7785 - accuracy: 0.3584 - val_loss: 1.8826 - val_accuracy: 0.3609\n",
      "Epoch 4/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.5794 - accuracy: 0.4531\n",
      "Epoch 4: val_accuracy did not improve from 0.36088\n",
      "41/41 [==============================] - 17s 417ms/step - loss: 1.5794 - accuracy: 0.4531 - val_loss: 1.8877 - val_accuracy: 0.3178\n",
      "Epoch 5/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.4739 - accuracy: 0.4702\n",
      "Epoch 5: val_accuracy improved from 0.36088 to 0.41405, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 14s 346ms/step - loss: 1.4739 - accuracy: 0.4702 - val_loss: 1.6775 - val_accuracy: 0.4140\n",
      "Epoch 6/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.4820 - accuracy: 0.4866\n",
      "Epoch 6: val_accuracy improved from 0.41405 to 0.44121, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 14s 349ms/step - loss: 1.4820 - accuracy: 0.4866 - val_loss: 1.5896 - val_accuracy: 0.4412\n",
      "Epoch 7/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.4282 - accuracy: 0.5072\n",
      "Epoch 7: val_accuracy did not improve from 0.44121\n",
      "41/41 [==============================] - 14s 338ms/step - loss: 1.4282 - accuracy: 0.5072 - val_loss: 1.7547 - val_accuracy: 0.4148\n",
      "Epoch 8/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.3734 - accuracy: 0.5325\n",
      "Epoch 8: val_accuracy did not improve from 0.44121\n",
      "41/41 [==============================] - 15s 369ms/step - loss: 1.3734 - accuracy: 0.5325 - val_loss: 1.7761 - val_accuracy: 0.4121\n",
      "Epoch 9/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.3572 - accuracy: 0.5314\n",
      "Epoch 9: val_accuracy did not improve from 0.44121\n",
      "41/41 [==============================] - 16s 399ms/step - loss: 1.3572 - accuracy: 0.5314 - val_loss: 1.7090 - val_accuracy: 0.4311\n",
      "Epoch 10/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.3781 - accuracy: 0.5294\n",
      "Epoch 10: val_accuracy did not improve from 0.44121\n",
      "41/41 [==============================] - 15s 360ms/step - loss: 1.3781 - accuracy: 0.5294 - val_loss: 1.7589 - val_accuracy: 0.4172\n",
      "Epoch 11/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.3713 - accuracy: 0.5263\n",
      "Epoch 11: val_accuracy improved from 0.44121 to 0.45440, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 15s 360ms/step - loss: 1.3713 - accuracy: 0.5263 - val_loss: 1.6743 - val_accuracy: 0.4544\n",
      "Epoch 12/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.2373 - accuracy: 0.5637\n",
      "Epoch 12: val_accuracy did not improve from 0.45440\n",
      "41/41 [==============================] - 16s 395ms/step - loss: 1.2373 - accuracy: 0.5637 - val_loss: 1.7871 - val_accuracy: 0.4203\n",
      "Epoch 13/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.2597 - accuracy: 0.5625\n",
      "Epoch 13: val_accuracy improved from 0.45440 to 0.47652, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 16s 397ms/step - loss: 1.2597 - accuracy: 0.5625 - val_loss: 1.6905 - val_accuracy: 0.4765\n",
      "Epoch 14/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1705 - accuracy: 0.5933\n",
      "Epoch 14: val_accuracy did not improve from 0.47652\n",
      "41/41 [==============================] - 16s 399ms/step - loss: 1.1705 - accuracy: 0.5933 - val_loss: 1.6920 - val_accuracy: 0.4556\n",
      "Epoch 15/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.2051 - accuracy: 0.5917\n",
      "Epoch 15: val_accuracy did not improve from 0.47652\n",
      "41/41 [==============================] - 16s 401ms/step - loss: 1.2051 - accuracy: 0.5917 - val_loss: 1.6624 - val_accuracy: 0.4525\n",
      "Epoch 16/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1351 - accuracy: 0.5995\n",
      "Epoch 16: val_accuracy improved from 0.47652 to 0.47808, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 16s 399ms/step - loss: 1.1351 - accuracy: 0.5995 - val_loss: 1.6859 - val_accuracy: 0.4781\n",
      "Epoch 17/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0648 - accuracy: 0.6354\n",
      "Epoch 17: val_accuracy did not improve from 0.47808\n",
      "41/41 [==============================] - 16s 396ms/step - loss: 1.0648 - accuracy: 0.6354 - val_loss: 1.7171 - val_accuracy: 0.4668\n",
      "Epoch 18/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0625 - accuracy: 0.6404\n",
      "Epoch 18: val_accuracy did not improve from 0.47808\n",
      "41/41 [==============================] - 16s 396ms/step - loss: 1.0625 - accuracy: 0.6404 - val_loss: 1.7773 - val_accuracy: 0.4556\n",
      "Epoch 19/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0878 - accuracy: 0.6198\n",
      "Epoch 19: val_accuracy did not improve from 0.47808\n",
      "41/41 [==============================] - 16s 401ms/step - loss: 1.0878 - accuracy: 0.6198 - val_loss: 1.8586 - val_accuracy: 0.4288\n",
      "Epoch 20/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0302 - accuracy: 0.6463\n",
      "Epoch 20: val_accuracy improved from 0.47808 to 0.48079, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 16s 397ms/step - loss: 1.0302 - accuracy: 0.6463 - val_loss: 1.7043 - val_accuracy: 0.4808\n",
      "Epoch 21/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1281 - accuracy: 0.6221\n",
      "Epoch 21: val_accuracy did not improve from 0.48079\n",
      "41/41 [==============================] - 16s 393ms/step - loss: 1.1281 - accuracy: 0.6221 - val_loss: 1.6159 - val_accuracy: 0.4645\n",
      "Epoch 22/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1290 - accuracy: 0.6139\n",
      "Epoch 22: val_accuracy improved from 0.48079 to 0.48700, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 16s 390ms/step - loss: 1.1290 - accuracy: 0.6139 - val_loss: 1.6810 - val_accuracy: 0.4870\n",
      "Epoch 23/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1179 - accuracy: 0.6256\n",
      "Epoch 23: val_accuracy did not improve from 0.48700\n",
      "41/41 [==============================] - 16s 391ms/step - loss: 1.1179 - accuracy: 0.6256 - val_loss: 1.7511 - val_accuracy: 0.4540\n",
      "Epoch 24/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0960 - accuracy: 0.6264\n",
      "Epoch 24: val_accuracy did not improve from 0.48700\n",
      "41/41 [==============================] - 16s 396ms/step - loss: 1.0960 - accuracy: 0.6264 - val_loss: 1.7523 - val_accuracy: 0.4660\n",
      "Epoch 25/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0938 - accuracy: 0.6182\n",
      "Epoch 25: val_accuracy did not improve from 0.48700\n",
      "41/41 [==============================] - 16s 396ms/step - loss: 1.0938 - accuracy: 0.6182 - val_loss: 1.7549 - val_accuracy: 0.4668\n",
      "Epoch 26/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0843 - accuracy: 0.6303\n",
      "Epoch 26: val_accuracy did not improve from 0.48700\n",
      "41/41 [==============================] - 16s 394ms/step - loss: 1.0843 - accuracy: 0.6303 - val_loss: 1.7538 - val_accuracy: 0.4598\n",
      "Epoch 27/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0666 - accuracy: 0.6311\n",
      "Epoch 27: val_accuracy did not improve from 0.48700\n",
      "41/41 [==============================] - 15s 373ms/step - loss: 1.0666 - accuracy: 0.6311 - val_loss: 1.8816 - val_accuracy: 0.4303\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.5677 - accuracy: 0.1344\n",
      "Epoch 1: val_accuracy improved from -inf to 0.16764, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 66s 1s/step - loss: 2.5677 - accuracy: 0.1344 - val_loss: 2.2552 - val_accuracy: 0.1676\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.1658 - accuracy: 0.2080\n",
      "Epoch 2: val_accuracy did not improve from 0.16764\n",
      "21/21 [==============================] - 18s 859ms/step - loss: 2.1658 - accuracy: 0.2080 - val_loss: 2.2013 - val_accuracy: 0.1626\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.8863 - accuracy: 0.3210\n",
      "Epoch 3: val_accuracy improved from 0.16764 to 0.21886, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 18s 888ms/step - loss: 1.8863 - accuracy: 0.3210 - val_loss: 2.1168 - val_accuracy: 0.2189\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7046 - accuracy: 0.3818\n",
      "Epoch 4: val_accuracy improved from 0.21886 to 0.28211, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 21s 1s/step - loss: 1.7046 - accuracy: 0.3818 - val_loss: 1.9708 - val_accuracy: 0.2821\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.5771 - accuracy: 0.4312\n",
      "Epoch 5: val_accuracy improved from 0.28211 to 0.30113, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 23s 1s/step - loss: 1.5771 - accuracy: 0.4312 - val_loss: 1.9510 - val_accuracy: 0.3011\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.4974 - accuracy: 0.4683\n",
      "Epoch 6: val_accuracy improved from 0.30113 to 0.31044, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 22s 1s/step - loss: 1.4974 - accuracy: 0.4683 - val_loss: 1.9067 - val_accuracy: 0.3104\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.4381 - accuracy: 0.4854\n",
      "Epoch 7: val_accuracy improved from 0.31044 to 0.41133, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 22s 1s/step - loss: 1.4381 - accuracy: 0.4854 - val_loss: 1.6976 - val_accuracy: 0.4113\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.3257 - accuracy: 0.5356\n",
      "Epoch 8: val_accuracy did not improve from 0.41133\n",
      "21/21 [==============================] - 19s 932ms/step - loss: 1.3257 - accuracy: 0.5356 - val_loss: 1.7811 - val_accuracy: 0.3690\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.2509 - accuracy: 0.5528\n",
      "Epoch 9: val_accuracy did not improve from 0.41133\n",
      "21/21 [==============================] - 21s 985ms/step - loss: 1.2509 - accuracy: 0.5528 - val_loss: 1.7336 - val_accuracy: 0.3985\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.2566 - accuracy: 0.5493\n",
      "Epoch 10: val_accuracy improved from 0.41133 to 0.45363, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 20s 953ms/step - loss: 1.2566 - accuracy: 0.5493 - val_loss: 1.6668 - val_accuracy: 0.4536\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.3265 - accuracy: 0.5477\n",
      "Epoch 11: val_accuracy did not improve from 0.45363\n",
      "21/21 [==============================] - 18s 868ms/step - loss: 1.3265 - accuracy: 0.5477 - val_loss: 1.8755 - val_accuracy: 0.3539\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.3067 - accuracy: 0.5454\n",
      "Epoch 12: val_accuracy did not improve from 0.45363\n",
      "21/21 [==============================] - 17s 841ms/step - loss: 1.3067 - accuracy: 0.5454 - val_loss: 1.9318 - val_accuracy: 0.3675\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.2271 - accuracy: 0.5672\n",
      "Epoch 13: val_accuracy did not improve from 0.45363\n",
      "21/21 [==============================] - 20s 971ms/step - loss: 1.2271 - accuracy: 0.5672 - val_loss: 1.9002 - val_accuracy: 0.4090\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.1565 - accuracy: 0.6101\n",
      "Epoch 14: val_accuracy did not improve from 0.45363\n",
      "21/21 [==============================] - 21s 1s/step - loss: 1.1565 - accuracy: 0.6101 - val_loss: 1.8274 - val_accuracy: 0.4292\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.1036 - accuracy: 0.6245\n",
      "Epoch 15: val_accuracy improved from 0.45363 to 0.48622, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 19s 889ms/step - loss: 1.1036 - accuracy: 0.6245 - val_loss: 1.6199 - val_accuracy: 0.4862\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.0197 - accuracy: 0.6626\n",
      "Epoch 16: val_accuracy did not improve from 0.48622\n",
      "21/21 [==============================] - 20s 979ms/step - loss: 1.0197 - accuracy: 0.6626 - val_loss: 1.7153 - val_accuracy: 0.4664\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.0451 - accuracy: 0.6404\n",
      "Epoch 17: val_accuracy did not improve from 0.48622\n",
      "21/21 [==============================] - 21s 1s/step - loss: 1.0451 - accuracy: 0.6404 - val_loss: 1.6798 - val_accuracy: 0.4618\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.1220 - accuracy: 0.6264\n",
      "Epoch 18: val_accuracy did not improve from 0.48622\n",
      "21/21 [==============================] - 21s 1s/step - loss: 1.1220 - accuracy: 0.6264 - val_loss: 1.7047 - val_accuracy: 0.4792\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.0382 - accuracy: 0.6506\n",
      "Epoch 19: val_accuracy did not improve from 0.48622\n",
      "21/21 [==============================] - 21s 1s/step - loss: 1.0382 - accuracy: 0.6506 - val_loss: 1.8912 - val_accuracy: 0.4377\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.9607 - accuracy: 0.6661\n",
      "Epoch 20: val_accuracy did not improve from 0.48622\n",
      "21/21 [==============================] - 19s 907ms/step - loss: 0.9607 - accuracy: 0.6661 - val_loss: 1.7650 - val_accuracy: 0.4789\n",
      "Epoch 1/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.5528 - accuracy: 0.0954\n",
      "Epoch 1: val_accuracy improved from -inf to 0.10089, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 67s 374ms/step - loss: 2.5528 - accuracy: 0.0954 - val_loss: 2.3753 - val_accuracy: 0.1009\n",
      "Epoch 2/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.3682 - accuracy: 0.0915\n",
      "Epoch 2: val_accuracy improved from 0.10089 to 0.10477, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 24s 302ms/step - loss: 2.3682 - accuracy: 0.0915 - val_loss: 2.3852 - val_accuracy: 0.1048\n",
      "Epoch 3/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.3510 - accuracy: 0.0947\n",
      "Epoch 3: val_accuracy did not improve from 0.10477\n",
      "81/81 [==============================] - 22s 271ms/step - loss: 2.3510 - accuracy: 0.0947 - val_loss: 2.3279 - val_accuracy: 0.0993\n",
      "Epoch 4/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.3522 - accuracy: 0.0974\n",
      "Epoch 4: val_accuracy did not improve from 0.10477\n",
      "81/81 [==============================] - 18s 229ms/step - loss: 2.3522 - accuracy: 0.0974 - val_loss: 2.3259 - val_accuracy: 0.0993\n",
      "Epoch 5/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.3516 - accuracy: 0.0978\n",
      "Epoch 5: val_accuracy did not improve from 0.10477\n",
      "81/81 [==============================] - 20s 242ms/step - loss: 2.3516 - accuracy: 0.0978 - val_loss: 2.4050 - val_accuracy: 0.1009\n",
      "Epoch 6/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.3740 - accuracy: 0.0943\n",
      "Epoch 6: val_accuracy did not improve from 0.10477\n",
      "81/81 [==============================] - 20s 252ms/step - loss: 2.3740 - accuracy: 0.0943 - val_loss: 2.3353 - val_accuracy: 0.1017\n",
      "Epoch 7/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.3748 - accuracy: 0.0888\n",
      "Epoch 7: val_accuracy did not improve from 0.10477\n",
      "81/81 [==============================] - 20s 252ms/step - loss: 2.3748 - accuracy: 0.0888 - val_loss: 2.3401 - val_accuracy: 0.1013\n",
      "Epoch 1/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.6403 - accuracy: 0.0986\n",
      "Epoch 1: val_accuracy improved from -inf to 0.09818, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 42s 480ms/step - loss: 2.6403 - accuracy: 0.0986 - val_loss: 2.3944 - val_accuracy: 0.0982\n",
      "Epoch 2/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.3685 - accuracy: 0.0974\n",
      "Epoch 2: val_accuracy improved from 0.09818 to 0.10089, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 14s 353ms/step - loss: 2.3685 - accuracy: 0.0974 - val_loss: 2.3581 - val_accuracy: 0.1009\n",
      "Epoch 3/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.3470 - accuracy: 0.1040\n",
      "Epoch 3: val_accuracy did not improve from 0.10089\n",
      "41/41 [==============================] - 13s 324ms/step - loss: 2.3470 - accuracy: 0.1040 - val_loss: 2.3545 - val_accuracy: 0.0958\n",
      "Epoch 4/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.3507 - accuracy: 0.1028\n",
      "Epoch 4: val_accuracy did not improve from 0.10089\n",
      "41/41 [==============================] - 13s 331ms/step - loss: 2.3507 - accuracy: 0.1028 - val_loss: 2.3706 - val_accuracy: 0.0997\n",
      "Epoch 5/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.3459 - accuracy: 0.0970\n",
      "Epoch 5: val_accuracy did not improve from 0.10089\n",
      "41/41 [==============================] - 13s 325ms/step - loss: 2.3459 - accuracy: 0.0970 - val_loss: 2.3378 - val_accuracy: 0.1009\n",
      "Epoch 6/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.3487 - accuracy: 0.1048\n",
      "Epoch 6: val_accuracy did not improve from 0.10089\n",
      "41/41 [==============================] - 13s 322ms/step - loss: 2.3487 - accuracy: 0.1048 - val_loss: 2.3507 - val_accuracy: 0.1009\n",
      "Epoch 7/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.3866 - accuracy: 0.0927\n",
      "Epoch 7: val_accuracy improved from 0.10089 to 0.10322, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 13s 327ms/step - loss: 2.3866 - accuracy: 0.0927 - val_loss: 2.5254 - val_accuracy: 0.1032\n",
      "Epoch 8/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.3924 - accuracy: 0.1025\n",
      "Epoch 8: val_accuracy did not improve from 0.10322\n",
      "41/41 [==============================] - 14s 334ms/step - loss: 2.3924 - accuracy: 0.1025 - val_loss: 3.1873 - val_accuracy: 0.1001\n",
      "Epoch 9/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.3844 - accuracy: 0.0896\n",
      "Epoch 9: val_accuracy did not improve from 0.10322\n",
      "41/41 [==============================] - 13s 323ms/step - loss: 2.3844 - accuracy: 0.0896 - val_loss: 2.4127 - val_accuracy: 0.0958\n",
      "Epoch 10/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.3779 - accuracy: 0.1036\n",
      "Epoch 10: val_accuracy did not improve from 0.10322\n",
      "41/41 [==============================] - 13s 320ms/step - loss: 2.3779 - accuracy: 0.1036 - val_loss: 3.1581 - val_accuracy: 0.1013\n",
      "Epoch 11/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.3968 - accuracy: 0.1001\n",
      "Epoch 11: val_accuracy did not improve from 0.10322\n",
      "41/41 [==============================] - 13s 324ms/step - loss: 2.3968 - accuracy: 0.1001 - val_loss: 3.1370 - val_accuracy: 0.0986\n",
      "Epoch 12/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.3572 - accuracy: 0.0966\n",
      "Epoch 12: val_accuracy did not improve from 0.10322\n",
      "41/41 [==============================] - 13s 328ms/step - loss: 2.3572 - accuracy: 0.0966 - val_loss: 9.3010 - val_accuracy: 0.1032\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.5943 - accuracy: 0.1001\n",
      "Epoch 1: val_accuracy improved from -inf to 0.10128, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 40s 936ms/step - loss: 2.5943 - accuracy: 0.1001 - val_loss: 2.4434 - val_accuracy: 0.1013\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.3737 - accuracy: 0.1056\n",
      "Epoch 2: val_accuracy did not improve from 0.10128\n",
      "21/21 [==============================] - 15s 745ms/step - loss: 2.3737 - accuracy: 0.1056 - val_loss: 2.4042 - val_accuracy: 0.0993\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.3637 - accuracy: 0.0943\n",
      "Epoch 3: val_accuracy did not improve from 0.10128\n",
      "21/21 [==============================] - 14s 696ms/step - loss: 2.3637 - accuracy: 0.0943 - val_loss: 2.3419 - val_accuracy: 0.0990\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.3393 - accuracy: 0.1114\n",
      "Epoch 4: val_accuracy did not improve from 0.10128\n",
      "21/21 [==============================] - 15s 699ms/step - loss: 2.3393 - accuracy: 0.1114 - val_loss: 2.3494 - val_accuracy: 0.0943\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.3560 - accuracy: 0.1032\n",
      "Epoch 5: val_accuracy did not improve from 0.10128\n",
      "21/21 [==============================] - 14s 681ms/step - loss: 2.3560 - accuracy: 0.1032 - val_loss: 2.3205 - val_accuracy: 0.0993\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.3289 - accuracy: 0.0923\n",
      "Epoch 6: val_accuracy did not improve from 0.10128\n",
      "21/21 [==============================] - 14s 686ms/step - loss: 2.3289 - accuracy: 0.0923 - val_loss: 2.3587 - val_accuracy: 0.0955\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.4196 - accuracy: 0.2030\n",
      "Epoch 1: val_accuracy improved from -inf to 0.25611, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 71s 581ms/step - loss: 2.4196 - accuracy: 0.2030 - val_loss: 2.1301 - val_accuracy: 0.2561\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.7716 - accuracy: 0.3966\n",
      "Epoch 2: val_accuracy improved from 0.25611 to 0.44043, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 42s 515ms/step - loss: 1.7716 - accuracy: 0.3966 - val_loss: 1.7086 - val_accuracy: 0.4404\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.3222 - accuracy: 0.5450\n",
      "Epoch 3: val_accuracy improved from 0.44043 to 0.49010, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 42s 518ms/step - loss: 1.3222 - accuracy: 0.5450 - val_loss: 1.4929 - val_accuracy: 0.4901\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.0153 - accuracy: 0.6697\n",
      "Epoch 4: val_accuracy improved from 0.49010 to 0.52891, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 37s 456ms/step - loss: 1.0153 - accuracy: 0.6697 - val_loss: 1.4422 - val_accuracy: 0.5289\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.7927 - accuracy: 0.7378\n",
      "Epoch 5: val_accuracy improved from 0.52891 to 0.54870, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 38s 473ms/step - loss: 0.7927 - accuracy: 0.7378 - val_loss: 1.5190 - val_accuracy: 0.5487\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.5970 - accuracy: 0.8052\n",
      "Epoch 6: val_accuracy improved from 0.54870 to 0.57780, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 39s 479ms/step - loss: 0.5970 - accuracy: 0.8052 - val_loss: 1.4719 - val_accuracy: 0.5778\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.5706 - accuracy: 0.8146\n",
      "Epoch 7: val_accuracy improved from 0.57780 to 0.57819, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 36s 449ms/step - loss: 0.5706 - accuracy: 0.8146 - val_loss: 1.6117 - val_accuracy: 0.5782\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.4648 - accuracy: 0.8492\n",
      "Epoch 8: val_accuracy did not improve from 0.57819\n",
      "81/81 [==============================] - 35s 439ms/step - loss: 0.4648 - accuracy: 0.8492 - val_loss: 1.6994 - val_accuracy: 0.5778\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.4408 - accuracy: 0.8582\n",
      "Epoch 9: val_accuracy improved from 0.57819 to 0.58789, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 39s 485ms/step - loss: 0.4408 - accuracy: 0.8582 - val_loss: 1.6249 - val_accuracy: 0.5879\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.3502 - accuracy: 0.8878\n",
      "Epoch 10: val_accuracy improved from 0.58789 to 0.59410, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 43s 528ms/step - loss: 0.3502 - accuracy: 0.8878 - val_loss: 1.6655 - val_accuracy: 0.5941\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2793 - accuracy: 0.9073\n",
      "Epoch 11: val_accuracy improved from 0.59410 to 0.61738, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 39s 477ms/step - loss: 0.2793 - accuracy: 0.9073 - val_loss: 1.6658 - val_accuracy: 0.6174\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2585 - accuracy: 0.9123\n",
      "Epoch 12: val_accuracy did not improve from 0.61738\n",
      "81/81 [==============================] - 42s 518ms/step - loss: 0.2585 - accuracy: 0.9123 - val_loss: 1.7548 - val_accuracy: 0.6054\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2187 - accuracy: 0.9291\n",
      "Epoch 13: val_accuracy did not improve from 0.61738\n",
      "81/81 [==============================] - 39s 482ms/step - loss: 0.2187 - accuracy: 0.9291 - val_loss: 1.8992 - val_accuracy: 0.6042\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2049 - accuracy: 0.9369\n",
      "Epoch 14: val_accuracy did not improve from 0.61738\n",
      "81/81 [==============================] - 36s 451ms/step - loss: 0.2049 - accuracy: 0.9369 - val_loss: 1.8984 - val_accuracy: 0.6054\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2150 - accuracy: 0.9303\n",
      "Epoch 15: val_accuracy did not improve from 0.61738\n",
      "81/81 [==============================] - 40s 494ms/step - loss: 0.2150 - accuracy: 0.9303 - val_loss: 2.0209 - val_accuracy: 0.5700\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2371 - accuracy: 0.9236\n",
      "Epoch 16: val_accuracy did not improve from 0.61738\n",
      "81/81 [==============================] - 40s 494ms/step - loss: 0.2371 - accuracy: 0.9236 - val_loss: 1.8343 - val_accuracy: 0.6112\n",
      "Epoch 1/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.4642 - accuracy: 0.1921\n",
      "Epoch 1: val_accuracy improved from -inf to 0.17811, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 93s 2s/step - loss: 2.4642 - accuracy: 0.1921 - val_loss: 2.2606 - val_accuracy: 0.1781\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.7856 - accuracy: 0.3677\n",
      "Epoch 2: val_accuracy improved from 0.17811 to 0.24563, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 66s 2s/step - loss: 1.7856 - accuracy: 0.3677 - val_loss: 2.1012 - val_accuracy: 0.2456\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.4076 - accuracy: 0.5018\n",
      "Epoch 3: val_accuracy improved from 0.24563 to 0.38572, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 62s 2s/step - loss: 1.4076 - accuracy: 0.5018 - val_loss: 1.8098 - val_accuracy: 0.3857\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0506 - accuracy: 0.6346\n",
      "Epoch 4: val_accuracy improved from 0.38572 to 0.47148, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 68s 2s/step - loss: 1.0506 - accuracy: 0.6346 - val_loss: 1.5268 - val_accuracy: 0.4715\n",
      "Epoch 5/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.7904 - accuracy: 0.7269\n",
      "Epoch 5: val_accuracy improved from 0.47148 to 0.55142, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 65s 2s/step - loss: 0.7904 - accuracy: 0.7269 - val_loss: 1.3490 - val_accuracy: 0.5514\n",
      "Epoch 6/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.6258 - accuracy: 0.7842\n",
      "Epoch 6: val_accuracy did not improve from 0.55142\n",
      "41/41 [==============================] - 63s 2s/step - loss: 0.6258 - accuracy: 0.7842 - val_loss: 1.3784 - val_accuracy: 0.5433\n",
      "Epoch 7/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.5044 - accuracy: 0.8309\n",
      "Epoch 7: val_accuracy improved from 0.55142 to 0.58285, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 67s 2s/step - loss: 0.5044 - accuracy: 0.8309 - val_loss: 1.3854 - val_accuracy: 0.5828\n",
      "Epoch 8/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.4297 - accuracy: 0.8555\n",
      "Epoch 8: val_accuracy did not improve from 0.58285\n",
      "41/41 [==============================] - 65s 2s/step - loss: 0.4297 - accuracy: 0.8555 - val_loss: 1.5938 - val_accuracy: 0.5681\n",
      "Epoch 9/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.3918 - accuracy: 0.8711\n",
      "Epoch 9: val_accuracy did not improve from 0.58285\n",
      "41/41 [==============================] - 64s 2s/step - loss: 0.3918 - accuracy: 0.8711 - val_loss: 1.6005 - val_accuracy: 0.5654\n",
      "Epoch 10/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.3275 - accuracy: 0.8901\n",
      "Epoch 10: val_accuracy improved from 0.58285 to 0.59100, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 60s 1s/step - loss: 0.3275 - accuracy: 0.8901 - val_loss: 1.6962 - val_accuracy: 0.5910\n",
      "Epoch 11/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2396 - accuracy: 0.9209\n",
      "Epoch 11: val_accuracy improved from 0.59100 to 0.59565, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 67s 2s/step - loss: 0.2396 - accuracy: 0.9209 - val_loss: 1.8034 - val_accuracy: 0.5957\n",
      "Epoch 12/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1969 - accuracy: 0.9365\n",
      "Epoch 12: val_accuracy did not improve from 0.59565\n",
      "41/41 [==============================] - 67s 2s/step - loss: 0.1969 - accuracy: 0.9365 - val_loss: 1.9220 - val_accuracy: 0.5898\n",
      "Epoch 13/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2305 - accuracy: 0.9260\n",
      "Epoch 13: val_accuracy did not improve from 0.59565\n",
      "41/41 [==============================] - 67s 2s/step - loss: 0.2305 - accuracy: 0.9260 - val_loss: 1.9071 - val_accuracy: 0.5825\n",
      "Epoch 14/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2620 - accuracy: 0.9112\n",
      "Epoch 14: val_accuracy did not improve from 0.59565\n",
      "41/41 [==============================] - 59s 1s/step - loss: 0.2620 - accuracy: 0.9112 - val_loss: 2.0797 - val_accuracy: 0.5902\n",
      "Epoch 15/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1596 - accuracy: 0.9521\n",
      "Epoch 15: val_accuracy did not improve from 0.59565\n",
      "41/41 [==============================] - 64s 2s/step - loss: 0.1596 - accuracy: 0.9521 - val_loss: 1.9178 - val_accuracy: 0.5937\n",
      "Epoch 16/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1480 - accuracy: 0.9529\n",
      "Epoch 16: val_accuracy improved from 0.59565 to 0.59953, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 67s 2s/step - loss: 0.1480 - accuracy: 0.9529 - val_loss: 1.9617 - val_accuracy: 0.5995\n",
      "Epoch 17/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2651 - accuracy: 0.9151\n",
      "Epoch 17: val_accuracy did not improve from 0.59953\n",
      "41/41 [==============================] - 65s 2s/step - loss: 0.2651 - accuracy: 0.9151 - val_loss: 1.9263 - val_accuracy: 0.5953\n",
      "Epoch 18/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1383 - accuracy: 0.9509\n",
      "Epoch 18: val_accuracy improved from 0.59953 to 0.62282, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 69s 2s/step - loss: 0.1383 - accuracy: 0.9509 - val_loss: 1.8201 - val_accuracy: 0.6228\n",
      "Epoch 19/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1443 - accuracy: 0.9571\n",
      "Epoch 19: val_accuracy did not improve from 0.62282\n",
      "41/41 [==============================] - 65s 2s/step - loss: 0.1443 - accuracy: 0.9571 - val_loss: 2.0034 - val_accuracy: 0.6003\n",
      "Epoch 20/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1592 - accuracy: 0.9474\n",
      "Epoch 20: val_accuracy did not improve from 0.62282\n",
      "41/41 [==============================] - 67s 2s/step - loss: 0.1592 - accuracy: 0.9474 - val_loss: 1.9960 - val_accuracy: 0.6003\n",
      "Epoch 1/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.5169 - accuracy: 0.1761\n",
      "Epoch 1: val_accuracy improved from -inf to 0.14862, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 67s 2s/step - loss: 2.5169 - accuracy: 0.1761 - val_loss: 2.2803 - val_accuracy: 0.1486\n",
      "Epoch 2/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.9644 - accuracy: 0.3218\n",
      "Epoch 2: val_accuracy improved from 0.14862 to 0.21653, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 41s 2s/step - loss: 1.9644 - accuracy: 0.3218 - val_loss: 2.2213 - val_accuracy: 0.2165\n",
      "Epoch 3/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.5460 - accuracy: 0.4581\n",
      "Epoch 3: val_accuracy improved from 0.21653 to 0.26814, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 40s 2s/step - loss: 1.5460 - accuracy: 0.4581 - val_loss: 2.1289 - val_accuracy: 0.2681\n",
      "Epoch 4/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.2279 - accuracy: 0.5808\n",
      "Epoch 4: val_accuracy improved from 0.26814 to 0.34420, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 36s 2s/step - loss: 1.2279 - accuracy: 0.5808 - val_loss: 1.9983 - val_accuracy: 0.3442\n",
      "Epoch 5/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.9688 - accuracy: 0.6665\n",
      "Epoch 5: val_accuracy improved from 0.34420 to 0.37951, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 38s 2s/step - loss: 0.9688 - accuracy: 0.6665 - val_loss: 1.8610 - val_accuracy: 0.3795\n",
      "Epoch 6/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.8184 - accuracy: 0.7238\n",
      "Epoch 6: val_accuracy improved from 0.37951 to 0.41715, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 38s 2s/step - loss: 0.8184 - accuracy: 0.7238 - val_loss: 1.7325 - val_accuracy: 0.4172\n",
      "Epoch 7/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.6240 - accuracy: 0.7900\n",
      "Epoch 7: val_accuracy did not improve from 0.41715\n",
      "21/21 [==============================] - 39s 2s/step - loss: 0.6240 - accuracy: 0.7900 - val_loss: 1.7392 - val_accuracy: 0.3985\n",
      "Epoch 8/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.5247 - accuracy: 0.8274\n",
      "Epoch 8: val_accuracy improved from 0.41715 to 0.49748, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 39s 2s/step - loss: 0.5247 - accuracy: 0.8274 - val_loss: 1.5010 - val_accuracy: 0.4975\n",
      "Epoch 9/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.4497 - accuracy: 0.8555\n",
      "Epoch 9: val_accuracy did not improve from 0.49748\n",
      "21/21 [==============================] - 39s 2s/step - loss: 0.4497 - accuracy: 0.8555 - val_loss: 1.5798 - val_accuracy: 0.4854\n",
      "Epoch 10/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.5089 - accuracy: 0.8278\n",
      "Epoch 10: val_accuracy improved from 0.49748 to 0.51688, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 39s 2s/step - loss: 0.5089 - accuracy: 0.8278 - val_loss: 1.4655 - val_accuracy: 0.5169\n",
      "Epoch 11/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.3890 - accuracy: 0.8730\n",
      "Epoch 11: val_accuracy did not improve from 0.51688\n",
      "21/21 [==============================] - 38s 2s/step - loss: 0.3890 - accuracy: 0.8730 - val_loss: 1.6951 - val_accuracy: 0.5080\n",
      "Epoch 12/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2883 - accuracy: 0.9034\n",
      "Epoch 12: val_accuracy improved from 0.51688 to 0.56073, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 39s 2s/step - loss: 0.2883 - accuracy: 0.9034 - val_loss: 1.5116 - val_accuracy: 0.5607\n",
      "Epoch 13/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.3154 - accuracy: 0.9022\n",
      "Epoch 13: val_accuracy improved from 0.56073 to 0.56461, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 39s 2s/step - loss: 0.3154 - accuracy: 0.9022 - val_loss: 1.5734 - val_accuracy: 0.5646\n",
      "Epoch 14/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.3421 - accuracy: 0.8898\n",
      "Epoch 14: val_accuracy did not improve from 0.56461\n",
      "21/21 [==============================] - 39s 2s/step - loss: 0.3421 - accuracy: 0.8898 - val_loss: 1.6511 - val_accuracy: 0.5642\n",
      "Epoch 15/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2214 - accuracy: 0.9268\n",
      "Epoch 15: val_accuracy improved from 0.56461 to 0.57082, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 39s 2s/step - loss: 0.2214 - accuracy: 0.9268 - val_loss: 1.6895 - val_accuracy: 0.5708\n",
      "Epoch 16/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1939 - accuracy: 0.9353\n",
      "Epoch 16: val_accuracy did not improve from 0.57082\n",
      "21/21 [==============================] - 39s 2s/step - loss: 0.1939 - accuracy: 0.9353 - val_loss: 1.7669 - val_accuracy: 0.5669\n",
      "Epoch 17/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1077 - accuracy: 0.9684\n",
      "Epoch 17: val_accuracy improved from 0.57082 to 0.57586, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 39s 2s/step - loss: 0.1077 - accuracy: 0.9684 - val_loss: 1.7833 - val_accuracy: 0.5759\n",
      "Epoch 18/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.0758 - accuracy: 0.9790\n",
      "Epoch 18: val_accuracy improved from 0.57586 to 0.59294, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 39s 2s/step - loss: 0.0758 - accuracy: 0.9790 - val_loss: 1.8812 - val_accuracy: 0.5929\n",
      "Epoch 19/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1083 - accuracy: 0.9681\n",
      "Epoch 19: val_accuracy did not improve from 0.59294\n",
      "21/21 [==============================] - 39s 2s/step - loss: 0.1083 - accuracy: 0.9681 - val_loss: 2.0589 - val_accuracy: 0.5731\n",
      "Epoch 20/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2790 - accuracy: 0.9159\n",
      "Epoch 20: val_accuracy did not improve from 0.59294\n",
      "21/21 [==============================] - 39s 2s/step - loss: 0.2790 - accuracy: 0.9159 - val_loss: 2.0233 - val_accuracy: 0.5720\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.5437 - accuracy: 0.1535\n",
      "Epoch 1: val_accuracy improved from -inf to 0.10128, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 48s 428ms/step - loss: 2.5437 - accuracy: 0.1535 - val_loss: 2.4474 - val_accuracy: 0.1013\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.2449 - accuracy: 0.1800\n",
      "Epoch 2: val_accuracy improved from 0.10128 to 0.19014, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 32s 398ms/step - loss: 2.2449 - accuracy: 0.1800 - val_loss: 2.2298 - val_accuracy: 0.1901\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.0493 - accuracy: 0.2591\n",
      "Epoch 3: val_accuracy improved from 0.19014 to 0.31044, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 32s 396ms/step - loss: 2.0493 - accuracy: 0.2591 - val_loss: 1.9344 - val_accuracy: 0.3104\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.8325 - accuracy: 0.3436\n",
      "Epoch 4: val_accuracy improved from 0.31044 to 0.32984, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 29s 365ms/step - loss: 1.8325 - accuracy: 0.3436 - val_loss: 1.8424 - val_accuracy: 0.3298\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.6462 - accuracy: 0.4036\n",
      "Epoch 5: val_accuracy did not improve from 0.32984\n",
      "81/81 [==============================] - 30s 378ms/step - loss: 1.6462 - accuracy: 0.4036 - val_loss: 2.0000 - val_accuracy: 0.3031\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.5298 - accuracy: 0.4601\n",
      "Epoch 6: val_accuracy improved from 0.32984 to 0.41560, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 31s 390ms/step - loss: 1.5298 - accuracy: 0.4601 - val_loss: 1.6527 - val_accuracy: 0.4156\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.4430 - accuracy: 0.4959\n",
      "Epoch 7: val_accuracy improved from 0.41560 to 0.42763, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 31s 388ms/step - loss: 1.4430 - accuracy: 0.4959 - val_loss: 1.6229 - val_accuracy: 0.4276\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.4028 - accuracy: 0.5146\n",
      "Epoch 8: val_accuracy improved from 0.42763 to 0.44276, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 32s 390ms/step - loss: 1.4028 - accuracy: 0.5146 - val_loss: 1.6187 - val_accuracy: 0.4428\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.3994 - accuracy: 0.5208\n",
      "Epoch 9: val_accuracy did not improve from 0.44276\n",
      "81/81 [==============================] - 31s 390ms/step - loss: 1.3994 - accuracy: 0.5208 - val_loss: 1.9218 - val_accuracy: 0.3811\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.3412 - accuracy: 0.5345\n",
      "Epoch 10: val_accuracy did not improve from 0.44276\n",
      "81/81 [==============================] - 31s 385ms/step - loss: 1.3412 - accuracy: 0.5345 - val_loss: 1.7340 - val_accuracy: 0.4222\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.3154 - accuracy: 0.5407\n",
      "Epoch 11: val_accuracy did not improve from 0.44276\n",
      "81/81 [==============================] - 31s 379ms/step - loss: 1.3154 - accuracy: 0.5407 - val_loss: 1.7384 - val_accuracy: 0.4369\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.3240 - accuracy: 0.5466\n",
      "Epoch 12: val_accuracy improved from 0.44276 to 0.45363, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 31s 380ms/step - loss: 1.3240 - accuracy: 0.5466 - val_loss: 1.6333 - val_accuracy: 0.4536\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.2906 - accuracy: 0.5594\n",
      "Epoch 13: val_accuracy did not improve from 0.45363\n",
      "81/81 [==============================] - 31s 379ms/step - loss: 1.2906 - accuracy: 0.5594 - val_loss: 1.7004 - val_accuracy: 0.4432\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.3020 - accuracy: 0.5489\n",
      "Epoch 14: val_accuracy improved from 0.45363 to 0.45557, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 31s 379ms/step - loss: 1.3020 - accuracy: 0.5489 - val_loss: 1.5582 - val_accuracy: 0.4556\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.3442 - accuracy: 0.5333\n",
      "Epoch 15: val_accuracy improved from 0.45557 to 0.47187, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 31s 379ms/step - loss: 1.3442 - accuracy: 0.5333 - val_loss: 1.6412 - val_accuracy: 0.4719\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.3692 - accuracy: 0.5294\n",
      "Epoch 16: val_accuracy did not improve from 0.47187\n",
      "81/81 [==============================] - 30s 377ms/step - loss: 1.3692 - accuracy: 0.5294 - val_loss: 1.7701 - val_accuracy: 0.3981\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.3476 - accuracy: 0.5504\n",
      "Epoch 17: val_accuracy did not improve from 0.47187\n",
      "81/81 [==============================] - 30s 377ms/step - loss: 1.3476 - accuracy: 0.5504 - val_loss: 1.6988 - val_accuracy: 0.4203\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.3235 - accuracy: 0.5512\n",
      "Epoch 18: val_accuracy did not improve from 0.47187\n",
      "81/81 [==============================] - 30s 376ms/step - loss: 1.3235 - accuracy: 0.5512 - val_loss: 1.8546 - val_accuracy: 0.4109\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.3588 - accuracy: 0.5356\n",
      "Epoch 19: val_accuracy did not improve from 0.47187\n",
      "81/81 [==============================] - 30s 376ms/step - loss: 1.3588 - accuracy: 0.5356 - val_loss: 1.6377 - val_accuracy: 0.4532\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.3204 - accuracy: 0.5493\n",
      "Epoch 20: val_accuracy did not improve from 0.47187\n",
      "81/81 [==============================] - 30s 376ms/step - loss: 1.3204 - accuracy: 0.5493 - val_loss: 1.5283 - val_accuracy: 0.4614\n",
      "Epoch 1/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.4841 - accuracy: 0.1695\n",
      "Epoch 1: val_accuracy improved from -inf to 0.18510, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 57s 1s/step - loss: 2.4841 - accuracy: 0.1695 - val_loss: 2.1897 - val_accuracy: 0.1851\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.1211 - accuracy: 0.2497\n",
      "Epoch 2: val_accuracy did not improve from 0.18510\n",
      "41/41 [==============================] - 44s 1s/step - loss: 2.1211 - accuracy: 0.2497 - val_loss: 2.3549 - val_accuracy: 0.1575\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.9693 - accuracy: 0.2820\n",
      "Epoch 3: val_accuracy improved from 0.18510 to 0.25262, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 44s 1s/step - loss: 1.9693 - accuracy: 0.2820 - val_loss: 2.0059 - val_accuracy: 0.2526\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.7171 - accuracy: 0.3751\n",
      "Epoch 4: val_accuracy improved from 0.25262 to 0.34032, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 45s 1s/step - loss: 1.7171 - accuracy: 0.3751 - val_loss: 1.8526 - val_accuracy: 0.3403\n",
      "Epoch 5/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.5048 - accuracy: 0.4741\n",
      "Epoch 5: val_accuracy improved from 0.34032 to 0.38184, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 45s 1s/step - loss: 1.5048 - accuracy: 0.4741 - val_loss: 1.7524 - val_accuracy: 0.3818\n",
      "Epoch 6/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.4646 - accuracy: 0.4858\n",
      "Epoch 6: val_accuracy did not improve from 0.38184\n",
      "41/41 [==============================] - 45s 1s/step - loss: 1.4646 - accuracy: 0.4858 - val_loss: 1.9144 - val_accuracy: 0.3166\n",
      "Epoch 7/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.4288 - accuracy: 0.5072\n",
      "Epoch 7: val_accuracy improved from 0.38184 to 0.40978, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 45s 1s/step - loss: 1.4288 - accuracy: 0.5072 - val_loss: 1.6951 - val_accuracy: 0.4098\n",
      "Epoch 8/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.3287 - accuracy: 0.5255\n",
      "Epoch 8: val_accuracy improved from 0.40978 to 0.46333, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 45s 1s/step - loss: 1.3287 - accuracy: 0.5255 - val_loss: 1.5739 - val_accuracy: 0.4633\n",
      "Epoch 9/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.3321 - accuracy: 0.5286\n",
      "Epoch 9: val_accuracy did not improve from 0.46333\n",
      "41/41 [==============================] - 45s 1s/step - loss: 1.3321 - accuracy: 0.5286 - val_loss: 1.9786 - val_accuracy: 0.3461\n",
      "Epoch 10/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.2528 - accuracy: 0.5684\n",
      "Epoch 10: val_accuracy did not improve from 0.46333\n",
      "41/41 [==============================] - 44s 1s/step - loss: 1.2528 - accuracy: 0.5684 - val_loss: 1.7196 - val_accuracy: 0.3935\n",
      "Epoch 11/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1157 - accuracy: 0.6186\n",
      "Epoch 11: val_accuracy improved from 0.46333 to 0.48118, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 45s 1s/step - loss: 1.1157 - accuracy: 0.6186 - val_loss: 1.6696 - val_accuracy: 0.4812\n",
      "Epoch 12/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1225 - accuracy: 0.6233\n",
      "Epoch 12: val_accuracy improved from 0.48118 to 0.48894, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 45s 1s/step - loss: 1.1225 - accuracy: 0.6233 - val_loss: 1.6950 - val_accuracy: 0.4889\n",
      "Epoch 13/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1595 - accuracy: 0.5937\n",
      "Epoch 13: val_accuracy did not improve from 0.48894\n",
      "41/41 [==============================] - 45s 1s/step - loss: 1.1595 - accuracy: 0.5937 - val_loss: 1.7070 - val_accuracy: 0.4544\n",
      "Epoch 14/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0939 - accuracy: 0.6338\n",
      "Epoch 14: val_accuracy did not improve from 0.48894\n",
      "41/41 [==============================] - 43s 1s/step - loss: 1.0939 - accuracy: 0.6338 - val_loss: 1.8751 - val_accuracy: 0.4412\n",
      "Epoch 15/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1647 - accuracy: 0.5914\n",
      "Epoch 15: val_accuracy did not improve from 0.48894\n",
      "41/41 [==============================] - 49s 1s/step - loss: 1.1647 - accuracy: 0.5914 - val_loss: 1.6632 - val_accuracy: 0.4641\n",
      "Epoch 16/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1694 - accuracy: 0.5902\n",
      "Epoch 16: val_accuracy improved from 0.48894 to 0.50058, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 49s 1s/step - loss: 1.1694 - accuracy: 0.5902 - val_loss: 1.6138 - val_accuracy: 0.5006\n",
      "Epoch 17/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1097 - accuracy: 0.6038\n",
      "Epoch 17: val_accuracy improved from 0.50058 to 0.50757, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 48s 1s/step - loss: 1.1097 - accuracy: 0.6038 - val_loss: 1.6522 - val_accuracy: 0.5076\n",
      "Epoch 18/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1036 - accuracy: 0.6132\n",
      "Epoch 18: val_accuracy did not improve from 0.50757\n",
      "41/41 [==============================] - 48s 1s/step - loss: 1.1036 - accuracy: 0.6132 - val_loss: 2.1295 - val_accuracy: 0.4109\n",
      "Epoch 19/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.2422 - accuracy: 0.5688\n",
      "Epoch 19: val_accuracy did not improve from 0.50757\n",
      "41/41 [==============================] - 49s 1s/step - loss: 1.2422 - accuracy: 0.5688 - val_loss: 1.7822 - val_accuracy: 0.4602\n",
      "Epoch 20/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1748 - accuracy: 0.5812\n",
      "Epoch 20: val_accuracy did not improve from 0.50757\n",
      "41/41 [==============================] - 49s 1s/step - loss: 1.1748 - accuracy: 0.5812 - val_loss: 1.7007 - val_accuracy: 0.4548\n",
      "Epoch 1/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.5887 - accuracy: 0.1667\n",
      "Epoch 1: val_accuracy improved from -inf to 0.18626, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 46s 2s/step - loss: 2.5887 - accuracy: 0.1667 - val_loss: 2.2040 - val_accuracy: 0.1863\n",
      "Epoch 2/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.1350 - accuracy: 0.2427\n",
      "Epoch 2: val_accuracy improved from 0.18626 to 0.21886, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 33s 2s/step - loss: 2.1350 - accuracy: 0.2427 - val_loss: 2.1497 - val_accuracy: 0.2189\n",
      "Epoch 3/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.9362 - accuracy: 0.2957\n",
      "Epoch 3: val_accuracy improved from 0.21886 to 0.26387, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 34s 2s/step - loss: 1.9362 - accuracy: 0.2957 - val_loss: 2.0081 - val_accuracy: 0.2639\n",
      "Epoch 4/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.8145 - accuracy: 0.3537\n",
      "Epoch 4: val_accuracy improved from 0.26387 to 0.29647, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 35s 2s/step - loss: 1.8145 - accuracy: 0.3537 - val_loss: 1.9426 - val_accuracy: 0.2965\n",
      "Epoch 5/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.6695 - accuracy: 0.4040\n",
      "Epoch 5: val_accuracy did not improve from 0.29647\n",
      "21/21 [==============================] - 35s 2s/step - loss: 1.6695 - accuracy: 0.4040 - val_loss: 2.0609 - val_accuracy: 0.2437\n",
      "Epoch 6/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.5962 - accuracy: 0.4192\n",
      "Epoch 6: val_accuracy improved from 0.29647 to 0.33993, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 35s 2s/step - loss: 1.5962 - accuracy: 0.4192 - val_loss: 1.8321 - val_accuracy: 0.3399\n",
      "Epoch 7/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.3698 - accuracy: 0.5084\n",
      "Epoch 7: val_accuracy improved from 0.33993 to 0.34808, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 34s 2s/step - loss: 1.3698 - accuracy: 0.5084 - val_loss: 1.8449 - val_accuracy: 0.3481\n",
      "Epoch 8/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.2304 - accuracy: 0.5578\n",
      "Epoch 8: val_accuracy improved from 0.34808 to 0.37912, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 35s 2s/step - loss: 1.2304 - accuracy: 0.5578 - val_loss: 1.8188 - val_accuracy: 0.3791\n",
      "Epoch 9/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.1202 - accuracy: 0.6128\n",
      "Epoch 9: val_accuracy improved from 0.37912 to 0.40706, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 35s 2s/step - loss: 1.1202 - accuracy: 0.6128 - val_loss: 1.6404 - val_accuracy: 0.4071\n",
      "Epoch 10/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.1353 - accuracy: 0.5984\n",
      "Epoch 10: val_accuracy improved from 0.40706 to 0.43500, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 35s 2s/step - loss: 1.1353 - accuracy: 0.5984 - val_loss: 1.6279 - val_accuracy: 0.4350\n",
      "Epoch 11/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.1200 - accuracy: 0.6229\n",
      "Epoch 11: val_accuracy improved from 0.43500 to 0.49437, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 35s 2s/step - loss: 1.1200 - accuracy: 0.6229 - val_loss: 1.5797 - val_accuracy: 0.4944\n",
      "Epoch 12/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.1438 - accuracy: 0.6171\n",
      "Epoch 12: val_accuracy did not improve from 0.49437\n",
      "21/21 [==============================] - 35s 2s/step - loss: 1.1438 - accuracy: 0.6171 - val_loss: 1.7034 - val_accuracy: 0.4284\n",
      "Epoch 13/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.1056 - accuracy: 0.6284\n",
      "Epoch 13: val_accuracy did not improve from 0.49437\n",
      "21/21 [==============================] - 35s 2s/step - loss: 1.1056 - accuracy: 0.6284 - val_loss: 1.6187 - val_accuracy: 0.4847\n",
      "Epoch 14/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.0747 - accuracy: 0.6354\n",
      "Epoch 14: val_accuracy did not improve from 0.49437\n",
      "21/21 [==============================] - 35s 2s/step - loss: 1.0747 - accuracy: 0.6354 - val_loss: 1.5979 - val_accuracy: 0.4886\n",
      "Epoch 15/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.0400 - accuracy: 0.6510\n",
      "Epoch 15: val_accuracy did not improve from 0.49437\n",
      "21/21 [==============================] - 35s 2s/step - loss: 1.0400 - accuracy: 0.6510 - val_loss: 1.6464 - val_accuracy: 0.4711\n",
      "Epoch 16/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.9944 - accuracy: 0.6626\n",
      "Epoch 16: val_accuracy did not improve from 0.49437\n",
      "21/21 [==============================] - 35s 2s/step - loss: 0.9944 - accuracy: 0.6626 - val_loss: 1.8867 - val_accuracy: 0.4478\n",
      "Epoch 1/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.9647 - accuracy: 0.1075\n",
      "Epoch 1: val_accuracy improved from -inf to 0.10477, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 47s 431ms/step - loss: 2.9647 - accuracy: 0.1075 - val_loss: 2.4384 - val_accuracy: 0.1048\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.4301 - accuracy: 0.0989\n",
      "Epoch 2: val_accuracy did not improve from 0.10477\n",
      "81/81 [==============================] - 32s 401ms/step - loss: 2.4301 - accuracy: 0.0989 - val_loss: 2.4991 - val_accuracy: 0.1024\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.4162 - accuracy: 0.1021\n",
      "Epoch 3: val_accuracy improved from 0.10477 to 0.10671, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 33s 406ms/step - loss: 2.4162 - accuracy: 0.1021 - val_loss: 2.7383 - val_accuracy: 0.1067\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.4114 - accuracy: 0.0884\n",
      "Epoch 4: val_accuracy did not improve from 0.10671\n",
      "81/81 [==============================] - 32s 400ms/step - loss: 2.4114 - accuracy: 0.0884 - val_loss: 3.5204 - val_accuracy: 0.0990\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.3932 - accuracy: 0.1079\n",
      "Epoch 5: val_accuracy did not improve from 0.10671\n",
      "81/81 [==============================] - 32s 401ms/step - loss: 2.3932 - accuracy: 0.1079 - val_loss: 2.8208 - val_accuracy: 0.1059\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.4160 - accuracy: 0.0954\n",
      "Epoch 6: val_accuracy did not improve from 0.10671\n",
      "81/81 [==============================] - 32s 399ms/step - loss: 2.4160 - accuracy: 0.0954 - val_loss: 2.6658 - val_accuracy: 0.0986\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.4021 - accuracy: 0.0951\n",
      "Epoch 7: val_accuracy did not improve from 0.10671\n",
      "81/81 [==============================] - 32s 402ms/step - loss: 2.4021 - accuracy: 0.0951 - val_loss: 2.4862 - val_accuracy: 0.0993\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.3945 - accuracy: 0.0970\n",
      "Epoch 8: val_accuracy did not improve from 0.10671\n",
      "81/81 [==============================] - 32s 400ms/step - loss: 2.3945 - accuracy: 0.0970 - val_loss: 2.4683 - val_accuracy: 0.0966\n",
      "Epoch 1/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.8388 - accuracy: 0.1036\n",
      "Epoch 1: val_accuracy improved from -inf to 0.09818, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 60s 1s/step - loss: 2.8388 - accuracy: 0.1036 - val_loss: 2.4581 - val_accuracy: 0.0982\n",
      "Epoch 2/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.4126 - accuracy: 0.1028\n",
      "Epoch 2: val_accuracy improved from 0.09818 to 0.10206, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 49s 1s/step - loss: 2.4126 - accuracy: 0.1028 - val_loss: 2.5153 - val_accuracy: 0.1021\n",
      "Epoch 3/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.4083 - accuracy: 0.0947\n",
      "Epoch 3: val_accuracy did not improve from 0.10206\n",
      "41/41 [==============================] - 50s 1s/step - loss: 2.4083 - accuracy: 0.0947 - val_loss: 2.4096 - val_accuracy: 0.0943\n",
      "Epoch 4/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.3839 - accuracy: 0.0978\n",
      "Epoch 4: val_accuracy did not improve from 0.10206\n",
      "41/41 [==============================] - 49s 1s/step - loss: 2.3839 - accuracy: 0.0978 - val_loss: 2.4017 - val_accuracy: 0.0958\n",
      "Epoch 5/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.3511 - accuracy: 0.1021\n",
      "Epoch 5: val_accuracy did not improve from 0.10206\n",
      "41/41 [==============================] - 50s 1s/step - loss: 2.3511 - accuracy: 0.1021 - val_loss: 2.4366 - val_accuracy: 0.0993\n",
      "Epoch 6/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.3874 - accuracy: 0.1106\n",
      "Epoch 6: val_accuracy did not improve from 0.10206\n",
      "41/41 [==============================] - 50s 1s/step - loss: 2.3874 - accuracy: 0.1106 - val_loss: 2.3532 - val_accuracy: 0.1013\n",
      "Epoch 7/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.3845 - accuracy: 0.1032\n",
      "Epoch 7: val_accuracy improved from 0.10206 to 0.10438, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 50s 1s/step - loss: 2.3845 - accuracy: 0.1032 - val_loss: 3.1982 - val_accuracy: 0.1044\n",
      "Epoch 8/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.3796 - accuracy: 0.0962\n",
      "Epoch 8: val_accuracy did not improve from 0.10438\n",
      "41/41 [==============================] - 50s 1s/step - loss: 2.3796 - accuracy: 0.0962 - val_loss: 4.0060 - val_accuracy: 0.0993\n",
      "Epoch 9/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.3907 - accuracy: 0.0923\n",
      "Epoch 9: val_accuracy did not improve from 0.10438\n",
      "41/41 [==============================] - 50s 1s/step - loss: 2.3907 - accuracy: 0.0923 - val_loss: 4.1494 - val_accuracy: 0.0908\n",
      "Epoch 10/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.4551 - accuracy: 0.0986\n",
      "Epoch 10: val_accuracy did not improve from 0.10438\n",
      "41/41 [==============================] - 50s 1s/step - loss: 2.4551 - accuracy: 0.0986 - val_loss: 28.1779 - val_accuracy: 0.0955\n",
      "Epoch 11/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.7126 - accuracy: 0.0970\n",
      "Epoch 11: val_accuracy did not improve from 0.10438\n",
      "41/41 [==============================] - 50s 1s/step - loss: 2.7126 - accuracy: 0.0970 - val_loss: 6.0138 - val_accuracy: 0.0927\n",
      "Epoch 12/20\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.5396 - accuracy: 0.0966\n",
      "Epoch 12: val_accuracy did not improve from 0.10438\n",
      "41/41 [==============================] - 49s 1s/step - loss: 2.5396 - accuracy: 0.0966 - val_loss: 24.9536 - val_accuracy: 0.0993\n",
      "Epoch 1/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.9691 - accuracy: 0.0931\n",
      "Epoch 1: val_accuracy improved from -inf to 0.10516, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 47s 2s/step - loss: 2.9691 - accuracy: 0.0931 - val_loss: 2.4617 - val_accuracy: 0.1052\n",
      "Epoch 2/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.4321 - accuracy: 0.0935\n",
      "Epoch 2: val_accuracy did not improve from 0.10516\n",
      "21/21 [==============================] - 35s 2s/step - loss: 2.4321 - accuracy: 0.0935 - val_loss: 2.4813 - val_accuracy: 0.1001\n",
      "Epoch 3/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.4028 - accuracy: 0.0958\n",
      "Epoch 3: val_accuracy did not improve from 0.10516\n",
      "21/21 [==============================] - 36s 2s/step - loss: 2.4028 - accuracy: 0.0958 - val_loss: 2.4088 - val_accuracy: 0.0982\n",
      "Epoch 4/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.4003 - accuracy: 0.0958\n",
      "Epoch 4: val_accuracy did not improve from 0.10516\n",
      "21/21 [==============================] - 36s 2s/step - loss: 2.4003 - accuracy: 0.0958 - val_loss: 2.3955 - val_accuracy: 0.1009\n",
      "Epoch 5/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.3541 - accuracy: 0.1099\n",
      "Epoch 5: val_accuracy did not improve from 0.10516\n",
      "21/21 [==============================] - 35s 2s/step - loss: 2.3541 - accuracy: 0.1099 - val_loss: 2.4983 - val_accuracy: 0.0993\n",
      "Epoch 6/20\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.3426 - accuracy: 0.1048\n",
      "Epoch 6: val_accuracy did not improve from 0.10516\n",
      "21/21 [==============================] - 31s 1s/step - loss: 2.3426 - accuracy: 0.1048 - val_loss: 2.3742 - val_accuracy: 0.1048\n",
      "Epoch 1/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.4131 - accuracy: 0.2205\n",
      "Epoch 1: val_accuracy improved from -inf to 0.26969, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 47s 436ms/step - loss: 2.4131 - accuracy: 0.2205 - val_loss: 2.1654 - val_accuracy: 0.2697\n",
      "Epoch 2/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.7247 - accuracy: 0.4129\n",
      "Epoch 2: val_accuracy improved from 0.26969 to 0.41094, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 32s 402ms/step - loss: 1.7247 - accuracy: 0.4129 - val_loss: 1.7601 - val_accuracy: 0.4109\n",
      "Epoch 3/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.2827 - accuracy: 0.5551\n",
      "Epoch 3: val_accuracy improved from 0.41094 to 0.49981, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 33s 405ms/step - loss: 1.2827 - accuracy: 0.5551 - val_loss: 1.4816 - val_accuracy: 0.4998\n",
      "Epoch 4/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.9469 - accuracy: 0.6732\n",
      "Epoch 4: val_accuracy improved from 0.49981 to 0.52775, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 33s 402ms/step - loss: 0.9469 - accuracy: 0.6732 - val_loss: 1.4925 - val_accuracy: 0.5277\n",
      "Epoch 5/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.7865 - accuracy: 0.7382\n",
      "Epoch 5: val_accuracy improved from 0.52775 to 0.56733, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 31s 386ms/step - loss: 0.7865 - accuracy: 0.7382 - val_loss: 1.4271 - val_accuracy: 0.5673\n",
      "Epoch 6/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.5981 - accuracy: 0.7998\n",
      "Epoch 6: val_accuracy improved from 0.56733 to 0.58246, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 31s 379ms/step - loss: 0.5981 - accuracy: 0.7998 - val_loss: 1.5572 - val_accuracy: 0.5825\n",
      "Epoch 7/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.5631 - accuracy: 0.8138\n",
      "Epoch 7: val_accuracy improved from 0.58246 to 0.58518, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 31s 390ms/step - loss: 0.5631 - accuracy: 0.8138 - val_loss: 1.5560 - val_accuracy: 0.5852\n",
      "Epoch 8/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.4087 - accuracy: 0.8695\n",
      "Epoch 8: val_accuracy improved from 0.58518 to 0.59410, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 32s 397ms/step - loss: 0.4087 - accuracy: 0.8695 - val_loss: 1.6025 - val_accuracy: 0.5941\n",
      "Epoch 9/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.3747 - accuracy: 0.8835\n",
      "Epoch 9: val_accuracy did not improve from 0.59410\n",
      "81/81 [==============================] - 32s 395ms/step - loss: 0.3747 - accuracy: 0.8835 - val_loss: 1.7507 - val_accuracy: 0.5728\n",
      "Epoch 10/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.3193 - accuracy: 0.9011\n",
      "Epoch 10: val_accuracy did not improve from 0.59410\n",
      "81/81 [==============================] - 32s 395ms/step - loss: 0.3193 - accuracy: 0.9011 - val_loss: 2.1033 - val_accuracy: 0.5382\n",
      "Epoch 11/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.3707 - accuracy: 0.8757\n",
      "Epoch 11: val_accuracy improved from 0.59410 to 0.62476, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 32s 397ms/step - loss: 0.3707 - accuracy: 0.8757 - val_loss: 1.6250 - val_accuracy: 0.6248\n",
      "Epoch 12/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2612 - accuracy: 0.9170\n",
      "Epoch 12: val_accuracy did not improve from 0.62476\n",
      "81/81 [==============================] - 32s 396ms/step - loss: 0.2612 - accuracy: 0.9170 - val_loss: 1.7307 - val_accuracy: 0.6042\n",
      "Epoch 13/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2276 - accuracy: 0.9307\n",
      "Epoch 13: val_accuracy did not improve from 0.62476\n",
      "81/81 [==============================] - 31s 379ms/step - loss: 0.2276 - accuracy: 0.9307 - val_loss: 1.7953 - val_accuracy: 0.6151\n",
      "Epoch 14/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.2094 - accuracy: 0.9287\n",
      "Epoch 14: val_accuracy did not improve from 0.62476\n",
      "81/81 [==============================] - 27s 339ms/step - loss: 0.2094 - accuracy: 0.9287 - val_loss: 1.8005 - val_accuracy: 0.5999\n",
      "Epoch 15/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.1927 - accuracy: 0.9349\n",
      "Epoch 15: val_accuracy did not improve from 0.62476\n",
      "81/81 [==============================] - 27s 339ms/step - loss: 0.1927 - accuracy: 0.9349 - val_loss: 1.8402 - val_accuracy: 0.6054\n",
      "Epoch 16/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.1826 - accuracy: 0.9443\n",
      "Epoch 16: val_accuracy did not improve from 0.62476\n",
      "81/81 [==============================] - 27s 339ms/step - loss: 0.1826 - accuracy: 0.9443 - val_loss: 1.8217 - val_accuracy: 0.6116\n",
      "Epoch 1/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.4410 - accuracy: 0.2002\n",
      "Epoch 1: val_accuracy improved from -inf to 0.22002, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 46s 987ms/step - loss: 2.4410 - accuracy: 0.2002 - val_loss: 2.2431 - val_accuracy: 0.2200\n",
      "Epoch 2/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.8247 - accuracy: 0.3864\n",
      "Epoch 2: val_accuracy improved from 0.22002 to 0.34071, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 41s 996ms/step - loss: 1.8247 - accuracy: 0.3864 - val_loss: 2.0719 - val_accuracy: 0.3407\n",
      "Epoch 3/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.3537 - accuracy: 0.5364\n",
      "Epoch 3: val_accuracy improved from 0.34071 to 0.44276, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 40s 991ms/step - loss: 1.3537 - accuracy: 0.5364 - val_loss: 1.7287 - val_accuracy: 0.4428\n",
      "Epoch 4/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.9917 - accuracy: 0.6513\n",
      "Epoch 4: val_accuracy improved from 0.44276 to 0.50175, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 40s 988ms/step - loss: 0.9917 - accuracy: 0.6513 - val_loss: 1.4905 - val_accuracy: 0.5017\n",
      "Epoch 5/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.7904 - accuracy: 0.7339\n",
      "Epoch 5: val_accuracy improved from 0.50175 to 0.54366, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 40s 991ms/step - loss: 0.7904 - accuracy: 0.7339 - val_loss: 1.3619 - val_accuracy: 0.5437\n",
      "Epoch 6/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.6172 - accuracy: 0.7935\n",
      "Epoch 6: val_accuracy improved from 0.54366 to 0.56228, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 40s 990ms/step - loss: 0.6172 - accuracy: 0.7935 - val_loss: 1.3475 - val_accuracy: 0.5623\n",
      "Epoch 7/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.4674 - accuracy: 0.8496\n",
      "Epoch 7: val_accuracy did not improve from 0.56228\n",
      "41/41 [==============================] - 41s 997ms/step - loss: 0.4674 - accuracy: 0.8496 - val_loss: 1.5687 - val_accuracy: 0.5305\n",
      "Epoch 8/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.4758 - accuracy: 0.8387\n",
      "Epoch 8: val_accuracy improved from 0.56228 to 0.56733, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 41s 995ms/step - loss: 0.4758 - accuracy: 0.8387 - val_loss: 1.5477 - val_accuracy: 0.5673\n",
      "Epoch 9/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.3927 - accuracy: 0.8629\n",
      "Epoch 9: val_accuracy improved from 0.56733 to 0.58789, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 40s 990ms/step - loss: 0.3927 - accuracy: 0.8629 - val_loss: 1.5421 - val_accuracy: 0.5879\n",
      "Epoch 10/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2659 - accuracy: 0.9116\n",
      "Epoch 10: val_accuracy improved from 0.58789 to 0.59177, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 41s 993ms/step - loss: 0.2659 - accuracy: 0.9116 - val_loss: 1.6455 - val_accuracy: 0.5918\n",
      "Epoch 11/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1964 - accuracy: 0.9342\n",
      "Epoch 11: val_accuracy did not improve from 0.59177\n",
      "41/41 [==============================] - 41s 997ms/step - loss: 0.1964 - accuracy: 0.9342 - val_loss: 1.9262 - val_accuracy: 0.5766\n",
      "Epoch 12/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1824 - accuracy: 0.9404\n",
      "Epoch 12: val_accuracy did not improve from 0.59177\n",
      "41/41 [==============================] - 41s 993ms/step - loss: 0.1824 - accuracy: 0.9404 - val_loss: 1.9231 - val_accuracy: 0.5797\n",
      "Epoch 13/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2546 - accuracy: 0.9092\n",
      "Epoch 13: val_accuracy did not improve from 0.59177\n",
      "41/41 [==============================] - 41s 995ms/step - loss: 0.2546 - accuracy: 0.9092 - val_loss: 1.9902 - val_accuracy: 0.5887\n",
      "Epoch 14/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2672 - accuracy: 0.9166\n",
      "Epoch 14: val_accuracy did not improve from 0.59177\n",
      "41/41 [==============================] - 40s 991ms/step - loss: 0.2672 - accuracy: 0.9166 - val_loss: 1.8218 - val_accuracy: 0.5825\n",
      "Epoch 15/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1743 - accuracy: 0.9423\n",
      "Epoch 15: val_accuracy improved from 0.59177 to 0.59682, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 41s 996ms/step - loss: 0.1743 - accuracy: 0.9423 - val_loss: 1.9241 - val_accuracy: 0.5968\n",
      "Epoch 16/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1977 - accuracy: 0.9330\n",
      "Epoch 16: val_accuracy improved from 0.59682 to 0.60846, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 40s 992ms/step - loss: 0.1977 - accuracy: 0.9330 - val_loss: 1.8151 - val_accuracy: 0.6085\n",
      "Epoch 17/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2962 - accuracy: 0.9049\n",
      "Epoch 17: val_accuracy did not improve from 0.60846\n",
      "41/41 [==============================] - 41s 994ms/step - loss: 0.2962 - accuracy: 0.9049 - val_loss: 1.8767 - val_accuracy: 0.5860\n",
      "Epoch 18/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1789 - accuracy: 0.9412\n",
      "Epoch 18: val_accuracy did not improve from 0.60846\n",
      "41/41 [==============================] - 41s 996ms/step - loss: 0.1789 - accuracy: 0.9412 - val_loss: 1.8525 - val_accuracy: 0.6034\n",
      "Epoch 19/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1771 - accuracy: 0.9525\n",
      "Epoch 19: val_accuracy improved from 0.60846 to 0.61583, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 40s 989ms/step - loss: 0.1771 - accuracy: 0.9525 - val_loss: 1.8486 - val_accuracy: 0.6158\n",
      "Epoch 20/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1147 - accuracy: 0.9700\n",
      "Epoch 20: val_accuracy improved from 0.61583 to 0.62709, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 41s 997ms/step - loss: 0.1147 - accuracy: 0.9700 - val_loss: 1.8256 - val_accuracy: 0.6271\n",
      "Epoch 21/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0570 - accuracy: 0.9829\n",
      "Epoch 21: val_accuracy improved from 0.62709 to 0.63174, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 41s 1s/step - loss: 0.0570 - accuracy: 0.9829 - val_loss: 1.9261 - val_accuracy: 0.6317\n",
      "Epoch 22/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0894 - accuracy: 0.9751\n",
      "Epoch 22: val_accuracy did not improve from 0.63174\n",
      "41/41 [==============================] - 40s 987ms/step - loss: 0.0894 - accuracy: 0.9751 - val_loss: 1.9526 - val_accuracy: 0.6314\n",
      "Epoch 23/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0645 - accuracy: 0.9821\n",
      "Epoch 23: val_accuracy did not improve from 0.63174\n",
      "41/41 [==============================] - 40s 990ms/step - loss: 0.0645 - accuracy: 0.9821 - val_loss: 1.9827 - val_accuracy: 0.6275\n",
      "Epoch 24/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0641 - accuracy: 0.9817\n",
      "Epoch 24: val_accuracy did not improve from 0.63174\n",
      "41/41 [==============================] - 41s 995ms/step - loss: 0.0641 - accuracy: 0.9817 - val_loss: 1.9979 - val_accuracy: 0.6251\n",
      "Epoch 25/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1616 - accuracy: 0.9497\n",
      "Epoch 25: val_accuracy did not improve from 0.63174\n",
      "41/41 [==============================] - 41s 1s/step - loss: 0.1616 - accuracy: 0.9497 - val_loss: 2.0787 - val_accuracy: 0.5988\n",
      "Epoch 26/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.2803 - accuracy: 0.9229\n",
      "Epoch 26: val_accuracy did not improve from 0.63174\n",
      "41/41 [==============================] - 41s 996ms/step - loss: 0.2803 - accuracy: 0.9229 - val_loss: 2.0034 - val_accuracy: 0.5902\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.5661 - accuracy: 0.1663\n",
      "Epoch 1: val_accuracy improved from -inf to 0.20217, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 42s 2s/step - loss: 2.5661 - accuracy: 0.1663 - val_loss: 2.2812 - val_accuracy: 0.2022\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.9869 - accuracy: 0.3163\n",
      "Epoch 2: val_accuracy improved from 0.20217 to 0.30229, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 35s 2s/step - loss: 1.9869 - accuracy: 0.3163 - val_loss: 2.2355 - val_accuracy: 0.3023\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.5948 - accuracy: 0.4258\n",
      "Epoch 3: val_accuracy did not improve from 0.30229\n",
      "21/21 [==============================] - 36s 2s/step - loss: 1.5948 - accuracy: 0.4258 - val_loss: 2.1283 - val_accuracy: 0.2782\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.3482 - accuracy: 0.5345\n",
      "Epoch 4: val_accuracy improved from 0.30229 to 0.39697, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 36s 2s/step - loss: 1.3482 - accuracy: 0.5345 - val_loss: 1.9973 - val_accuracy: 0.3970\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.0373 - accuracy: 0.6350\n",
      "Epoch 5: val_accuracy improved from 0.39697 to 0.40706, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 36s 2s/step - loss: 1.0373 - accuracy: 0.6350 - val_loss: 1.8542 - val_accuracy: 0.4071\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.9428 - accuracy: 0.6833\n",
      "Epoch 6: val_accuracy improved from 0.40706 to 0.48390, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 35s 2s/step - loss: 0.9428 - accuracy: 0.6833 - val_loss: 1.6351 - val_accuracy: 0.4839\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.8363 - accuracy: 0.7129\n",
      "Epoch 7: val_accuracy did not improve from 0.48390\n",
      "21/21 [==============================] - 35s 2s/step - loss: 0.8363 - accuracy: 0.7129 - val_loss: 1.5677 - val_accuracy: 0.4734\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.5770 - accuracy: 0.8025\n",
      "Epoch 8: val_accuracy improved from 0.48390 to 0.50640, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 40s 2s/step - loss: 0.5770 - accuracy: 0.8025 - val_loss: 1.4448 - val_accuracy: 0.5064\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.5149 - accuracy: 0.8251\n",
      "Epoch 9: val_accuracy did not improve from 0.50640\n",
      "21/21 [==============================] - 43s 2s/step - loss: 0.5149 - accuracy: 0.8251 - val_loss: 1.5211 - val_accuracy: 0.4792\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.4191 - accuracy: 0.8527\n",
      "Epoch 10: val_accuracy improved from 0.50640 to 0.54055, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 43s 2s/step - loss: 0.4191 - accuracy: 0.8527 - val_loss: 1.4127 - val_accuracy: 0.5406\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.3300 - accuracy: 0.8933\n",
      "Epoch 11: val_accuracy improved from 0.54055 to 0.55297, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 43s 2s/step - loss: 0.3300 - accuracy: 0.8933 - val_loss: 1.4214 - val_accuracy: 0.5530\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2988 - accuracy: 0.8925\n",
      "Epoch 12: val_accuracy improved from 0.55297 to 0.56577, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 43s 2s/step - loss: 0.2988 - accuracy: 0.8925 - val_loss: 1.4464 - val_accuracy: 0.5658\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2784 - accuracy: 0.9143\n",
      "Epoch 13: val_accuracy did not improve from 0.56577\n",
      "21/21 [==============================] - 43s 2s/step - loss: 0.2784 - accuracy: 0.9143 - val_loss: 1.6088 - val_accuracy: 0.5607\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.3542 - accuracy: 0.8796\n",
      "Epoch 14: val_accuracy did not improve from 0.56577\n",
      "21/21 [==============================] - 44s 2s/step - loss: 0.3542 - accuracy: 0.8796 - val_loss: 1.7787 - val_accuracy: 0.5305\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2985 - accuracy: 0.8975\n",
      "Epoch 15: val_accuracy did not improve from 0.56577\n",
      "21/21 [==============================] - 43s 2s/step - loss: 0.2985 - accuracy: 0.8975 - val_loss: 1.8719 - val_accuracy: 0.5409\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.4377 - accuracy: 0.8539\n",
      "Epoch 16: val_accuracy did not improve from 0.56577\n",
      "21/21 [==============================] - 44s 2s/step - loss: 0.4377 - accuracy: 0.8539 - val_loss: 1.9680 - val_accuracy: 0.5281\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.4349 - accuracy: 0.8601\n",
      "Epoch 17: val_accuracy did not improve from 0.56577\n",
      "21/21 [==============================] - 45s 2s/step - loss: 0.4349 - accuracy: 0.8601 - val_loss: 2.0150 - val_accuracy: 0.5017\n",
      "Epoch 1/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.5264 - accuracy: 0.1527\n",
      "Epoch 1: val_accuracy improved from -inf to 0.11021, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 40s 412ms/step - loss: 2.5264 - accuracy: 0.1527 - val_loss: 2.6224 - val_accuracy: 0.1102\n",
      "Epoch 2/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.1605 - accuracy: 0.2111\n",
      "Epoch 2: val_accuracy improved from 0.11021 to 0.17656, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 32s 394ms/step - loss: 2.1605 - accuracy: 0.2111 - val_loss: 2.2202 - val_accuracy: 0.1766\n",
      "Epoch 3/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.9265 - accuracy: 0.2910\n",
      "Epoch 3: val_accuracy improved from 0.17656 to 0.19519, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 32s 394ms/step - loss: 1.9265 - accuracy: 0.2910 - val_loss: 2.0632 - val_accuracy: 0.1952\n",
      "Epoch 4/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.7617 - accuracy: 0.3490\n",
      "Epoch 4: val_accuracy improved from 0.19519 to 0.30889, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 32s 392ms/step - loss: 1.7617 - accuracy: 0.3490 - val_loss: 1.8367 - val_accuracy: 0.3089\n",
      "Epoch 5/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.6660 - accuracy: 0.3646\n",
      "Epoch 5: val_accuracy improved from 0.30889 to 0.31704, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 32s 393ms/step - loss: 1.6660 - accuracy: 0.3646 - val_loss: 1.8644 - val_accuracy: 0.3170\n",
      "Epoch 6/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.6205 - accuracy: 0.4153\n",
      "Epoch 6: val_accuracy improved from 0.31704 to 0.35235, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 32s 392ms/step - loss: 1.6205 - accuracy: 0.4153 - val_loss: 1.8375 - val_accuracy: 0.3523\n",
      "Epoch 7/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.5661 - accuracy: 0.4468\n",
      "Epoch 7: val_accuracy did not improve from 0.35235\n",
      "81/81 [==============================] - 32s 391ms/step - loss: 1.5661 - accuracy: 0.4468 - val_loss: 2.3276 - val_accuracy: 0.3085\n",
      "Epoch 8/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.5244 - accuracy: 0.4741\n",
      "Epoch 8: val_accuracy improved from 0.35235 to 0.39930, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 31s 390ms/step - loss: 1.5244 - accuracy: 0.4741 - val_loss: 1.7745 - val_accuracy: 0.3993\n",
      "Epoch 9/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.4953 - accuracy: 0.4667\n",
      "Epoch 9: val_accuracy did not improve from 0.39930\n",
      "81/81 [==============================] - 32s 392ms/step - loss: 1.4953 - accuracy: 0.4667 - val_loss: 1.8481 - val_accuracy: 0.3733\n",
      "Epoch 10/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.4797 - accuracy: 0.4799\n",
      "Epoch 10: val_accuracy did not improve from 0.39930\n",
      "81/81 [==============================] - 32s 391ms/step - loss: 1.4797 - accuracy: 0.4799 - val_loss: 2.3716 - val_accuracy: 0.3089\n",
      "Epoch 11/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.4707 - accuracy: 0.4772\n",
      "Epoch 11: val_accuracy improved from 0.39930 to 0.42026, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 32s 393ms/step - loss: 1.4707 - accuracy: 0.4772 - val_loss: 1.7597 - val_accuracy: 0.4203\n",
      "Epoch 12/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.4945 - accuracy: 0.4784\n",
      "Epoch 12: val_accuracy improved from 0.42026 to 0.44043, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 31s 390ms/step - loss: 1.4945 - accuracy: 0.4784 - val_loss: 1.6039 - val_accuracy: 0.4404\n",
      "Epoch 13/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.5078 - accuracy: 0.4823\n",
      "Epoch 13: val_accuracy did not improve from 0.44043\n",
      "81/81 [==============================] - 31s 390ms/step - loss: 1.5078 - accuracy: 0.4823 - val_loss: 1.8458 - val_accuracy: 0.3900\n",
      "Epoch 14/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.4798 - accuracy: 0.4990\n",
      "Epoch 14: val_accuracy did not improve from 0.44043\n",
      "81/81 [==============================] - 32s 397ms/step - loss: 1.4798 - accuracy: 0.4990 - val_loss: 1.7401 - val_accuracy: 0.4245\n",
      "Epoch 15/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.4566 - accuracy: 0.4971\n",
      "Epoch 15: val_accuracy did not improve from 0.44043\n",
      "81/81 [==============================] - 32s 392ms/step - loss: 1.4566 - accuracy: 0.4971 - val_loss: 1.9014 - val_accuracy: 0.3508\n",
      "Epoch 16/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.4748 - accuracy: 0.4772\n",
      "Epoch 16: val_accuracy did not improve from 0.44043\n",
      "81/81 [==============================] - 32s 394ms/step - loss: 1.4748 - accuracy: 0.4772 - val_loss: 1.8524 - val_accuracy: 0.4009\n",
      "Epoch 17/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.4910 - accuracy: 0.4928\n",
      "Epoch 17: val_accuracy did not improve from 0.44043\n",
      "81/81 [==============================] - 31s 389ms/step - loss: 1.4910 - accuracy: 0.4928 - val_loss: 1.9331 - val_accuracy: 0.3329\n",
      "Epoch 1/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.6043 - accuracy: 0.1465\n",
      "Epoch 1: val_accuracy improved from -inf to 0.15483, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 55s 1s/step - loss: 2.6043 - accuracy: 0.1465 - val_loss: 2.2941 - val_accuracy: 0.1548\n",
      "Epoch 2/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.2453 - accuracy: 0.2049\n",
      "Epoch 2: val_accuracy improved from 0.15483 to 0.16686, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 47s 1s/step - loss: 2.2453 - accuracy: 0.2049 - val_loss: 2.2364 - val_accuracy: 0.1669\n",
      "Epoch 3/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.0495 - accuracy: 0.2587\n",
      "Epoch 3: val_accuracy improved from 0.16686 to 0.22352, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 47s 1s/step - loss: 2.0495 - accuracy: 0.2587 - val_loss: 2.0843 - val_accuracy: 0.2235\n",
      "Epoch 4/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.8701 - accuracy: 0.3190\n",
      "Epoch 4: val_accuracy improved from 0.22352 to 0.28172, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 47s 1s/step - loss: 1.8701 - accuracy: 0.3190 - val_loss: 1.9335 - val_accuracy: 0.2817\n",
      "Epoch 5/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.6645 - accuracy: 0.3946\n",
      "Epoch 5: val_accuracy improved from 0.28172 to 0.38766, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 47s 1s/step - loss: 1.6645 - accuracy: 0.3946 - val_loss: 1.7263 - val_accuracy: 0.3877\n",
      "Epoch 6/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.4494 - accuracy: 0.4815\n",
      "Epoch 6: val_accuracy did not improve from 0.38766\n",
      "41/41 [==============================] - 47s 1s/step - loss: 1.4494 - accuracy: 0.4815 - val_loss: 1.9053 - val_accuracy: 0.3636\n",
      "Epoch 7/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.3647 - accuracy: 0.5310\n",
      "Epoch 7: val_accuracy improved from 0.38766 to 0.45402, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 47s 1s/step - loss: 1.3647 - accuracy: 0.5310 - val_loss: 1.5442 - val_accuracy: 0.4540\n",
      "Epoch 8/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.2538 - accuracy: 0.5578\n",
      "Epoch 8: val_accuracy did not improve from 0.45402\n",
      "41/41 [==============================] - 47s 1s/step - loss: 1.2538 - accuracy: 0.5578 - val_loss: 1.8177 - val_accuracy: 0.3710\n",
      "Epoch 9/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.2266 - accuracy: 0.5758\n",
      "Epoch 9: val_accuracy improved from 0.45402 to 0.46333, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 47s 1s/step - loss: 1.2266 - accuracy: 0.5758 - val_loss: 1.6679 - val_accuracy: 0.4633\n",
      "Epoch 10/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1397 - accuracy: 0.6046\n",
      "Epoch 10: val_accuracy improved from 0.46333 to 0.46449, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 47s 1s/step - loss: 1.1397 - accuracy: 0.6046 - val_loss: 1.7603 - val_accuracy: 0.4645\n",
      "Epoch 11/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1273 - accuracy: 0.6128\n",
      "Epoch 11: val_accuracy did not improve from 0.46449\n",
      "41/41 [==============================] - 47s 1s/step - loss: 1.1273 - accuracy: 0.6128 - val_loss: 1.8524 - val_accuracy: 0.4482\n",
      "Epoch 12/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1264 - accuracy: 0.6132\n",
      "Epoch 12: val_accuracy improved from 0.46449 to 0.47846, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 47s 1s/step - loss: 1.1264 - accuracy: 0.6132 - val_loss: 1.6805 - val_accuracy: 0.4785\n",
      "Epoch 13/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.1080 - accuracy: 0.6233\n",
      "Epoch 13: val_accuracy did not improve from 0.47846\n",
      "41/41 [==============================] - 47s 1s/step - loss: 1.1080 - accuracy: 0.6233 - val_loss: 1.7730 - val_accuracy: 0.4241\n",
      "Epoch 14/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0538 - accuracy: 0.6358\n",
      "Epoch 14: val_accuracy did not improve from 0.47846\n",
      "41/41 [==============================] - 47s 1s/step - loss: 1.0538 - accuracy: 0.6358 - val_loss: 1.7814 - val_accuracy: 0.4769\n",
      "Epoch 15/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0109 - accuracy: 0.6525\n",
      "Epoch 15: val_accuracy did not improve from 0.47846\n",
      "41/41 [==============================] - 48s 1s/step - loss: 1.0109 - accuracy: 0.6525 - val_loss: 1.7028 - val_accuracy: 0.4711\n",
      "Epoch 16/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0853 - accuracy: 0.6284\n",
      "Epoch 16: val_accuracy did not improve from 0.47846\n",
      "41/41 [==============================] - 47s 1s/step - loss: 1.0853 - accuracy: 0.6284 - val_loss: 1.7902 - val_accuracy: 0.4633\n",
      "Epoch 17/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 1.0557 - accuracy: 0.6326\n",
      "Epoch 17: val_accuracy did not improve from 0.47846\n",
      "41/41 [==============================] - 47s 1s/step - loss: 1.0557 - accuracy: 0.6326 - val_loss: 1.8003 - val_accuracy: 0.4513\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.5785 - accuracy: 0.1722\n",
      "Epoch 1: val_accuracy improved from -inf to 0.15794, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 49s 2s/step - loss: 2.5785 - accuracy: 0.1722 - val_loss: 2.2802 - val_accuracy: 0.1579\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.0384 - accuracy: 0.2945\n",
      "Epoch 2: val_accuracy improved from 0.15794 to 0.26426, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 45s 2s/step - loss: 2.0384 - accuracy: 0.2945 - val_loss: 2.0530 - val_accuracy: 0.2643\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.8572 - accuracy: 0.3514\n",
      "Epoch 3: val_accuracy improved from 0.26426 to 0.28211, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 45s 2s/step - loss: 1.8572 - accuracy: 0.3514 - val_loss: 2.0447 - val_accuracy: 0.2821\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7241 - accuracy: 0.3989\n",
      "Epoch 4: val_accuracy improved from 0.28211 to 0.36166, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 45s 2s/step - loss: 1.7241 - accuracy: 0.3989 - val_loss: 1.8877 - val_accuracy: 0.3617\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.5431 - accuracy: 0.4655\n",
      "Epoch 5: val_accuracy improved from 0.36166 to 0.40512, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 45s 2s/step - loss: 1.5431 - accuracy: 0.4655 - val_loss: 1.6849 - val_accuracy: 0.4051\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.2892 - accuracy: 0.5551\n",
      "Epoch 6: val_accuracy improved from 0.40512 to 0.41638, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 45s 2s/step - loss: 1.2892 - accuracy: 0.5551 - val_loss: 1.6481 - val_accuracy: 0.4164\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.2217 - accuracy: 0.5898\n",
      "Epoch 7: val_accuracy did not improve from 0.41638\n",
      "21/21 [==============================] - 45s 2s/step - loss: 1.2217 - accuracy: 0.5898 - val_loss: 1.7177 - val_accuracy: 0.4020\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.1515 - accuracy: 0.6101\n",
      "Epoch 8: val_accuracy improved from 0.41638 to 0.42841, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 45s 2s/step - loss: 1.1515 - accuracy: 0.6101 - val_loss: 1.6394 - val_accuracy: 0.4284\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.9946 - accuracy: 0.6813\n",
      "Epoch 9: val_accuracy did not improve from 0.42841\n",
      "21/21 [==============================] - 45s 2s/step - loss: 0.9946 - accuracy: 0.6813 - val_loss: 1.7951 - val_accuracy: 0.3939\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.0296 - accuracy: 0.6591\n",
      "Epoch 10: val_accuracy improved from 0.42841 to 0.50058, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 45s 2s/step - loss: 1.0296 - accuracy: 0.6591 - val_loss: 1.5552 - val_accuracy: 0.5006\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.9984 - accuracy: 0.6661\n",
      "Epoch 11: val_accuracy did not improve from 0.50058\n",
      "21/21 [==============================] - 45s 2s/step - loss: 0.9984 - accuracy: 0.6661 - val_loss: 1.5671 - val_accuracy: 0.4769\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.9887 - accuracy: 0.6782\n",
      "Epoch 12: val_accuracy did not improve from 0.50058\n",
      "21/21 [==============================] - 45s 2s/step - loss: 0.9887 - accuracy: 0.6782 - val_loss: 1.6739 - val_accuracy: 0.4889\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.0356 - accuracy: 0.6595\n",
      "Epoch 13: val_accuracy did not improve from 0.50058\n",
      "21/21 [==============================] - 44s 2s/step - loss: 1.0356 - accuracy: 0.6595 - val_loss: 1.6839 - val_accuracy: 0.4742\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.1024 - accuracy: 0.6225\n",
      "Epoch 14: val_accuracy did not improve from 0.50058\n",
      "21/21 [==============================] - 45s 2s/step - loss: 1.1024 - accuracy: 0.6225 - val_loss: 1.7100 - val_accuracy: 0.4668\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.0638 - accuracy: 0.6506\n",
      "Epoch 15: val_accuracy did not improve from 0.50058\n",
      "21/21 [==============================] - 45s 2s/step - loss: 1.0638 - accuracy: 0.6506 - val_loss: 1.8005 - val_accuracy: 0.4785\n",
      "Epoch 1/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.6932 - accuracy: 0.0873\n",
      "Epoch 1: val_accuracy improved from -inf to 0.10128, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 41s 424ms/step - loss: 2.6932 - accuracy: 0.0873 - val_loss: 2.4399 - val_accuracy: 0.1013\n",
      "Epoch 2/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.4029 - accuracy: 0.0962\n",
      "Epoch 2: val_accuracy improved from 0.10128 to 0.10244, saving model to models\\lstm.h5\n",
      "81/81 [==============================] - 33s 411ms/step - loss: 2.4029 - accuracy: 0.0962 - val_loss: 2.3987 - val_accuracy: 0.1024\n",
      "Epoch 3/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.3708 - accuracy: 0.0962\n",
      "Epoch 3: val_accuracy did not improve from 0.10244\n",
      "81/81 [==============================] - 33s 410ms/step - loss: 2.3708 - accuracy: 0.0962 - val_loss: 2.3923 - val_accuracy: 0.1013\n",
      "Epoch 4/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.3582 - accuracy: 0.0966\n",
      "Epoch 4: val_accuracy did not improve from 0.10244\n",
      "81/81 [==============================] - 34s 427ms/step - loss: 2.3582 - accuracy: 0.0966 - val_loss: 2.3851 - val_accuracy: 0.0993\n",
      "Epoch 5/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.3665 - accuracy: 0.0935\n",
      "Epoch 5: val_accuracy did not improve from 0.10244\n",
      "81/81 [==============================] - 34s 421ms/step - loss: 2.3665 - accuracy: 0.0935 - val_loss: 2.3433 - val_accuracy: 0.0958\n",
      "Epoch 6/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.3560 - accuracy: 0.0989\n",
      "Epoch 6: val_accuracy did not improve from 0.10244\n",
      "81/81 [==============================] - 31s 387ms/step - loss: 2.3560 - accuracy: 0.0989 - val_loss: 2.3335 - val_accuracy: 0.1009\n",
      "Epoch 7/30\n",
      "81/81 [==============================] - ETA: 0s - loss: 2.4618 - accuracy: 0.0947\n",
      "Epoch 7: val_accuracy did not improve from 0.10244\n",
      "81/81 [==============================] - 31s 383ms/step - loss: 2.4618 - accuracy: 0.0947 - val_loss: 87.1474 - val_accuracy: 0.1009\n",
      "Epoch 1/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.8319 - accuracy: 0.0993\n",
      "Epoch 1: val_accuracy improved from -inf to 0.10206, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 52s 1s/step - loss: 2.8319 - accuracy: 0.0993 - val_loss: 2.4086 - val_accuracy: 0.1021\n",
      "Epoch 2/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.4258 - accuracy: 0.0877\n",
      "Epoch 2: val_accuracy did not improve from 0.10206\n",
      "41/41 [==============================] - 44s 1s/step - loss: 2.4258 - accuracy: 0.0877 - val_loss: 2.3767 - val_accuracy: 0.1013\n",
      "Epoch 3/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.3783 - accuracy: 0.0896\n",
      "Epoch 3: val_accuracy did not improve from 0.10206\n",
      "41/41 [==============================] - 44s 1s/step - loss: 2.3783 - accuracy: 0.0896 - val_loss: 2.4741 - val_accuracy: 0.1013\n",
      "Epoch 4/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.3568 - accuracy: 0.1095\n",
      "Epoch 4: val_accuracy improved from 0.10206 to 0.10244, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 44s 1s/step - loss: 2.3568 - accuracy: 0.1095 - val_loss: 2.3408 - val_accuracy: 0.1024\n",
      "Epoch 5/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.3530 - accuracy: 0.0993\n",
      "Epoch 5: val_accuracy did not improve from 0.10244\n",
      "41/41 [==============================] - 44s 1s/step - loss: 2.3530 - accuracy: 0.0993 - val_loss: 2.3488 - val_accuracy: 0.0955\n",
      "Epoch 6/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.3382 - accuracy: 0.1013\n",
      "Epoch 6: val_accuracy did not improve from 0.10244\n",
      "41/41 [==============================] - 44s 1s/step - loss: 2.3382 - accuracy: 0.1013 - val_loss: 2.3185 - val_accuracy: 0.1013\n",
      "Epoch 7/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.3385 - accuracy: 0.0982\n",
      "Epoch 7: val_accuracy improved from 0.10244 to 0.10477, saving model to models\\lstm.h5\n",
      "41/41 [==============================] - 44s 1s/step - loss: 2.3385 - accuracy: 0.0982 - val_loss: 2.3361 - val_accuracy: 0.1048\n",
      "Epoch 8/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.3362 - accuracy: 0.1044\n",
      "Epoch 8: val_accuracy did not improve from 0.10477\n",
      "41/41 [==============================] - 44s 1s/step - loss: 2.3362 - accuracy: 0.1044 - val_loss: 2.4578 - val_accuracy: 0.1009\n",
      "Epoch 9/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.3417 - accuracy: 0.1067\n",
      "Epoch 9: val_accuracy did not improve from 0.10477\n",
      "41/41 [==============================] - 44s 1s/step - loss: 2.3417 - accuracy: 0.1067 - val_loss: 2.3538 - val_accuracy: 0.0993\n",
      "Epoch 10/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.3421 - accuracy: 0.0986\n",
      "Epoch 10: val_accuracy did not improve from 0.10477\n",
      "41/41 [==============================] - 44s 1s/step - loss: 2.3421 - accuracy: 0.0986 - val_loss: 2.3569 - val_accuracy: 0.0958\n",
      "Epoch 11/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.3502 - accuracy: 0.0970\n",
      "Epoch 11: val_accuracy did not improve from 0.10477\n",
      "41/41 [==============================] - 44s 1s/step - loss: 2.3502 - accuracy: 0.0970 - val_loss: 2.3417 - val_accuracy: 0.0993\n",
      "Epoch 12/30\n",
      "41/41 [==============================] - ETA: 0s - loss: 2.3594 - accuracy: 0.1071\n",
      "Epoch 12: val_accuracy did not improve from 0.10477\n",
      "41/41 [==============================] - 44s 1s/step - loss: 2.3594 - accuracy: 0.1071 - val_loss: 2.4856 - val_accuracy: 0.0951\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.9928 - accuracy: 0.1040\n",
      "Epoch 1: val_accuracy improved from -inf to 0.10904, saving model to models\\lstm.h5\n",
      "21/21 [==============================] - 47s 2s/step - loss: 2.9928 - accuracy: 0.1040 - val_loss: 2.5273 - val_accuracy: 0.1090\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.4879 - accuracy: 0.0993\n",
      "Epoch 2: val_accuracy did not improve from 0.10904\n",
      "21/21 [==============================] - 43s 2s/step - loss: 2.4879 - accuracy: 0.0993 - val_loss: 2.3946 - val_accuracy: 0.0966\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.4068 - accuracy: 0.1040\n",
      "Epoch 3: val_accuracy did not improve from 0.10904\n",
      "21/21 [==============================] - 43s 2s/step - loss: 2.4068 - accuracy: 0.1040 - val_loss: 2.4520 - val_accuracy: 0.1005\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.4056 - accuracy: 0.1067\n",
      "Epoch 4: val_accuracy did not improve from 0.10904\n",
      "21/21 [==============================] - 43s 2s/step - loss: 2.4056 - accuracy: 0.1067 - val_loss: 2.4198 - val_accuracy: 0.0993\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.3797 - accuracy: 0.1017\n",
      "Epoch 5: val_accuracy did not improve from 0.10904\n",
      "21/21 [==============================] - 43s 2s/step - loss: 2.3797 - accuracy: 0.1017 - val_loss: 2.3461 - val_accuracy: 0.0978\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.3643 - accuracy: 0.0919\n",
      "Epoch 6: val_accuracy did not improve from 0.10904\n",
      "21/21 [==============================] - 44s 2s/step - loss: 2.3643 - accuracy: 0.0919 - val_loss: 2.3368 - val_accuracy: 0.0958\n"
     ]
    }
   ],
   "source": [
    "res = pd.DataFrame(columns=['lstm_units', 'dropout_rate', 'learning_rate', 'epoch', 'batch', 'loss_max','accuracy_max','val_loss_max', 'val_accuracy_max'])\n",
    "\n",
    "for lstm_unit in [64,128]:\n",
    "    for epoch in [20, 30]:\n",
    "        for lr in [0.001, 0.01, 0.1]:\n",
    "            for batch in [32,64,128]:\n",
    "                model = Lstm(lstm_units=lstm_unit, dropout_rate=0.2, learning_rate=lr, num_classes=10, batch_size=batch, epoch=epoch)\n",
    "                model.train(labels_only_detection_training, labels_only_detection_validation)\n",
    "                res = np.concatenate((res, pd.DataFrame([[lstm_unit,0.2, lr, epoch, batch, model.history.history['loss'][-1], model.history.history['accuracy'][-1], model.history.history['val_loss'][-1], model.history.history['val_accuracy'][-1]]], \n",
    "                                                                        columns=['lstm_units', 'dropout_rate', 'learning_rate', 'epoch', 'batch', 'loss_max','accuracy_max','val_loss_max', 'val_accuracy_max'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lstm_units</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>batch</th>\n",
       "      <th>loss_max</th>\n",
       "      <th>accuracy_max</th>\n",
       "      <th>val_loss_max</th>\n",
       "      <th>val_accuracy_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.295499</td>\n",
       "      <td>0.904168</td>\n",
       "      <td>1.866493</td>\n",
       "      <td>0.566938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.278164</td>\n",
       "      <td>0.908064</td>\n",
       "      <td>2.043893</td>\n",
       "      <td>0.565386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.375169</td>\n",
       "      <td>0.874172</td>\n",
       "      <td>2.005992</td>\n",
       "      <td>0.517656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.424195</td>\n",
       "      <td>0.498637</td>\n",
       "      <td>1.802717</td>\n",
       "      <td>0.406674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.201664</td>\n",
       "      <td>0.580834</td>\n",
       "      <td>1.65922</td>\n",
       "      <td>0.469538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1.203318</td>\n",
       "      <td>0.594858</td>\n",
       "      <td>1.718948</td>\n",
       "      <td>0.43345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.523939</td>\n",
       "      <td>0.104012</td>\n",
       "      <td>5.436676</td>\n",
       "      <td>0.101281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.372931</td>\n",
       "      <td>0.091547</td>\n",
       "      <td>2.417869</td>\n",
       "      <td>0.095848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>2.345453</td>\n",
       "      <td>0.099338</td>\n",
       "      <td>2.323612</td>\n",
       "      <td>0.101281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>30.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.282726</td>\n",
       "      <td>0.907674</td>\n",
       "      <td>1.954796</td>\n",
       "      <td>0.557237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>30.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.245392</td>\n",
       "      <td>0.928711</td>\n",
       "      <td>2.289701</td>\n",
       "      <td>0.545984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>30.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.314371</td>\n",
       "      <td>0.899883</td>\n",
       "      <td>2.114897</td>\n",
       "      <td>0.52891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.384447</td>\n",
       "      <td>0.523568</td>\n",
       "      <td>1.672328</td>\n",
       "      <td>0.431121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.06663</td>\n",
       "      <td>0.631087</td>\n",
       "      <td>1.881591</td>\n",
       "      <td>0.430345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.960746</td>\n",
       "      <td>0.666147</td>\n",
       "      <td>1.765011</td>\n",
       "      <td>0.478851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.374812</td>\n",
       "      <td>0.08882</td>\n",
       "      <td>2.340101</td>\n",
       "      <td>0.101281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.357168</td>\n",
       "      <td>0.096611</td>\n",
       "      <td>9.300986</td>\n",
       "      <td>0.103221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>2.328949</td>\n",
       "      <td>0.092326</td>\n",
       "      <td>2.358682</td>\n",
       "      <td>0.09546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>128.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.237104</td>\n",
       "      <td>0.923646</td>\n",
       "      <td>1.834324</td>\n",
       "      <td>0.611176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>128.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.159239</td>\n",
       "      <td>0.947409</td>\n",
       "      <td>1.995996</td>\n",
       "      <td>0.60031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>128.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.278971</td>\n",
       "      <td>0.915855</td>\n",
       "      <td>2.023277</td>\n",
       "      <td>0.571983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>128.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.320374</td>\n",
       "      <td>0.549279</td>\n",
       "      <td>1.528326</td>\n",
       "      <td>0.461389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>128.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.174817</td>\n",
       "      <td>0.581223</td>\n",
       "      <td>1.700699</td>\n",
       "      <td>0.454792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>128.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.994394</td>\n",
       "      <td>0.662641</td>\n",
       "      <td>1.886701</td>\n",
       "      <td>0.447808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>128.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.394496</td>\n",
       "      <td>0.097</td>\n",
       "      <td>2.468324</td>\n",
       "      <td>0.096624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>128.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.539634</td>\n",
       "      <td>0.096611</td>\n",
       "      <td>24.953644</td>\n",
       "      <td>0.09934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>128.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>2.342578</td>\n",
       "      <td>0.104792</td>\n",
       "      <td>2.374172</td>\n",
       "      <td>0.104773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>128.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>30.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.182577</td>\n",
       "      <td>0.944293</td>\n",
       "      <td>1.821681</td>\n",
       "      <td>0.611564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>128.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>30.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.280318</td>\n",
       "      <td>0.922867</td>\n",
       "      <td>2.003369</td>\n",
       "      <td>0.590221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>128.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>30.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.434871</td>\n",
       "      <td>0.860148</td>\n",
       "      <td>2.014958</td>\n",
       "      <td>0.501746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>128.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.490978</td>\n",
       "      <td>0.492793</td>\n",
       "      <td>1.933099</td>\n",
       "      <td>0.332945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>128.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.055669</td>\n",
       "      <td>0.632645</td>\n",
       "      <td>1.800285</td>\n",
       "      <td>0.4513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>128.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>1.063782</td>\n",
       "      <td>0.650565</td>\n",
       "      <td>1.800472</td>\n",
       "      <td>0.478463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>128.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.46178</td>\n",
       "      <td>0.094663</td>\n",
       "      <td>87.147385</td>\n",
       "      <td>0.100893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>128.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.359424</td>\n",
       "      <td>0.107129</td>\n",
       "      <td>2.485585</td>\n",
       "      <td>0.095072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>128.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>2.364307</td>\n",
       "      <td>0.091936</td>\n",
       "      <td>2.336782</td>\n",
       "      <td>0.095848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lstm_units dropout_rate learning_rate epoch  batch  loss_max accuracy_max  \\\n",
       "0        64.0          0.2         0.001  20.0   32.0  0.295499     0.904168   \n",
       "1        64.0          0.2         0.001  20.0   64.0  0.278164     0.908064   \n",
       "2        64.0          0.2         0.001  20.0  128.0  0.375169     0.874172   \n",
       "3        64.0          0.2          0.01  20.0   32.0  1.424195     0.498637   \n",
       "4        64.0          0.2          0.01  20.0   64.0  1.201664     0.580834   \n",
       "5        64.0          0.2          0.01  20.0  128.0  1.203318     0.594858   \n",
       "6        64.0          0.2           0.1  20.0   32.0  2.523939     0.104012   \n",
       "7        64.0          0.2           0.1  20.0   64.0  2.372931     0.091547   \n",
       "8        64.0          0.2           0.1  20.0  128.0  2.345453     0.099338   \n",
       "9        64.0          0.2         0.001  30.0   32.0  0.282726     0.907674   \n",
       "10       64.0          0.2         0.001  30.0   64.0  0.245392     0.928711   \n",
       "11       64.0          0.2         0.001  30.0  128.0  0.314371     0.899883   \n",
       "12       64.0          0.2          0.01  30.0   32.0  1.384447     0.523568   \n",
       "13       64.0          0.2          0.01  30.0   64.0   1.06663     0.631087   \n",
       "14       64.0          0.2          0.01  30.0  128.0  0.960746     0.666147   \n",
       "15       64.0          0.2           0.1  30.0   32.0  2.374812      0.08882   \n",
       "16       64.0          0.2           0.1  30.0   64.0  2.357168     0.096611   \n",
       "17       64.0          0.2           0.1  30.0  128.0  2.328949     0.092326   \n",
       "18      128.0          0.2         0.001  20.0   32.0  0.237104     0.923646   \n",
       "19      128.0          0.2         0.001  20.0   64.0  0.159239     0.947409   \n",
       "20      128.0          0.2         0.001  20.0  128.0  0.278971     0.915855   \n",
       "21      128.0          0.2          0.01  20.0   32.0  1.320374     0.549279   \n",
       "22      128.0          0.2          0.01  20.0   64.0  1.174817     0.581223   \n",
       "23      128.0          0.2          0.01  20.0  128.0  0.994394     0.662641   \n",
       "24      128.0          0.2           0.1  20.0   32.0  2.394496        0.097   \n",
       "25      128.0          0.2           0.1  20.0   64.0  2.539634     0.096611   \n",
       "26      128.0          0.2           0.1  20.0  128.0  2.342578     0.104792   \n",
       "27      128.0          0.2         0.001  30.0   32.0  0.182577     0.944293   \n",
       "28      128.0          0.2         0.001  30.0   64.0  0.280318     0.922867   \n",
       "29      128.0          0.2         0.001  30.0  128.0  0.434871     0.860148   \n",
       "30      128.0          0.2          0.01  30.0   32.0  1.490978     0.492793   \n",
       "31      128.0          0.2          0.01  30.0   64.0  1.055669     0.632645   \n",
       "32      128.0          0.2          0.01  30.0  128.0  1.063782     0.650565   \n",
       "33      128.0          0.2           0.1  30.0   32.0   2.46178     0.094663   \n",
       "34      128.0          0.2           0.1  30.0   64.0  2.359424     0.107129   \n",
       "35      128.0          0.2           0.1  30.0  128.0  2.364307     0.091936   \n",
       "\n",
       "   val_loss_max val_accuracy_max  \n",
       "0      1.866493         0.566938  \n",
       "1      2.043893         0.565386  \n",
       "2      2.005992         0.517656  \n",
       "3      1.802717         0.406674  \n",
       "4       1.65922         0.469538  \n",
       "5      1.718948          0.43345  \n",
       "6      5.436676         0.101281  \n",
       "7      2.417869         0.095848  \n",
       "8      2.323612         0.101281  \n",
       "9      1.954796         0.557237  \n",
       "10     2.289701         0.545984  \n",
       "11     2.114897          0.52891  \n",
       "12     1.672328         0.431121  \n",
       "13     1.881591         0.430345  \n",
       "14     1.765011         0.478851  \n",
       "15     2.340101         0.101281  \n",
       "16     9.300986         0.103221  \n",
       "17     2.358682          0.09546  \n",
       "18     1.834324         0.611176  \n",
       "19     1.995996          0.60031  \n",
       "20     2.023277         0.571983  \n",
       "21     1.528326         0.461389  \n",
       "22     1.700699         0.454792  \n",
       "23     1.886701         0.447808  \n",
       "24     2.468324         0.096624  \n",
       "25    24.953644          0.09934  \n",
       "26     2.374172         0.104773  \n",
       "27     1.821681         0.611564  \n",
       "28     2.003369         0.590221  \n",
       "29     2.014958         0.501746  \n",
       "30     1.933099         0.332945  \n",
       "31     1.800285           0.4513  \n",
       "32     1.800472         0.478463  \n",
       "33    87.147385         0.100893  \n",
       "34     2.485585         0.095072  \n",
       "35     2.336782         0.095848  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd.DataFrame(res,columns=['num_heads', 'dropout_rate', 'learning_rate', 'epoch', 'batch', 'num_layer', 'loss_max','accuracy_max','val_loss_max', 'val_accuracy_max']).to_pickle('transformer_wyniki_.pkl')\n",
    "pd.DataFrame(res,columns=['lstm_units', 'dropout_rate', 'learning_rate', 'epoch', 'batch', 'loss_max','accuracy_max','val_loss_max', 'val_accuracy_max'])#.to_pickle('results/lstm_wyniki_only_labels.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[64.0, 0.2, 0.001, 20.0, 32.0, 0.2954994738101959,\n",
       "        0.9041683077812195, 1.8664928674697876, 0.5669382810592651],\n",
       "       [64.0, 0.2, 0.001, 20.0, 64.0, 0.2781638503074646,\n",
       "        0.9080638885498047, 2.0438930988311768, 0.5653861165046692],\n",
       "       [64.0, 0.2, 0.001, 20.0, 128.0, 0.37516868114471436,\n",
       "        0.8741722106933594, 2.0059919357299805, 0.5176562070846558],\n",
       "       [64.0, 0.2, 0.01, 20.0, 32.0, 1.4241948127746582,\n",
       "        0.49863654375076294, 1.8027169704437256, 0.40667441487312317],\n",
       "       [64.0, 0.2, 0.01, 20.0, 64.0, 1.2016643285751343,\n",
       "        0.5808336734771729, 1.6592204570770264, 0.46953821182250977],\n",
       "       [64.0, 0.2, 0.01, 20.0, 128.0, 1.2033181190490723,\n",
       "        0.5948578119277954, 1.7189483642578125, 0.43344974517822266],\n",
       "       [64.0, 0.2, 0.1, 20.0, 32.0, 2.523939371109009,\n",
       "        0.10401246696710587, 5.436676025390625, 0.10128055512905121],\n",
       "       [64.0, 0.2, 0.1, 20.0, 64.0, 2.3729312419891357,\n",
       "        0.09154655039310455, 2.4178693294525146, 0.09584788233041763],\n",
       "       [64.0, 0.2, 0.1, 20.0, 128.0, 2.3454527854919434,\n",
       "        0.09933774918317795, 2.3236117362976074, 0.10128055512905121],\n",
       "       [64.0, 0.2, 0.001, 30.0, 32.0, 0.2827260494232178,\n",
       "        0.9076743125915527, 1.9547959566116333, 0.5572370886802673],\n",
       "       [64.0, 0.2, 0.001, 30.0, 64.0, 0.24539169669151306,\n",
       "        0.9287105798721313, 2.289701461791992, 0.5459837317466736],\n",
       "       [64.0, 0.2, 0.001, 30.0, 128.0, 0.3143714368343353,\n",
       "        0.8998831510543823, 2.1148972511291504, 0.5289095640182495],\n",
       "       [64.0, 0.2, 0.01, 30.0, 32.0, 1.3844469785690308,\n",
       "        0.5235683917999268, 1.672327995300293, 0.43112146854400635],\n",
       "       [64.0, 0.2, 0.01, 30.0, 64.0, 1.0666297674179077,\n",
       "        0.6310868859291077, 1.8815909624099731, 0.430345356464386],\n",
       "       [64.0, 0.2, 0.01, 30.0, 128.0, 0.9607456922531128,\n",
       "        0.6661472320556641, 1.7650110721588135, 0.4788513779640198],\n",
       "       [64.0, 0.2, 0.1, 30.0, 32.0, 2.374812364578247,\n",
       "        0.08881963044404984, 2.340101480484009, 0.10128055512905121],\n",
       "       [64.0, 0.2, 0.1, 30.0, 64.0, 2.357167959213257,\n",
       "        0.09661082923412323, 9.300986289978027, 0.10322079807519913],\n",
       "       [64.0, 0.2, 0.1, 30.0, 128.0, 2.328949451446533,\n",
       "        0.09232567250728607, 2.3586816787719727, 0.09545983374118805],\n",
       "       [128.0, 0.2, 0.001, 20.0, 32.0, 0.2371038943529129,\n",
       "        0.9236462712287903, 1.8343238830566406, 0.6111757755279541],\n",
       "       [128.0, 0.2, 0.001, 20.0, 64.0, 0.1592385470867157,\n",
       "        0.947409451007843, 1.995996356010437, 0.6003104448318481],\n",
       "       [128.0, 0.2, 0.001, 20.0, 128.0, 0.2789708971977234,\n",
       "        0.9158551096916199, 2.0232772827148438, 0.5719829201698303],\n",
       "       [128.0, 0.2, 0.01, 20.0, 32.0, 1.3203738927841187,\n",
       "        0.5492793321609497, 1.5283260345458984, 0.4613892138004303],\n",
       "       [128.0, 0.2, 0.01, 20.0, 64.0, 1.1748167276382446,\n",
       "        0.58122318983078, 1.7006993293762207, 0.4547923803329468],\n",
       "       [128.0, 0.2, 0.01, 20.0, 128.0, 0.9943941831588745,\n",
       "        0.6626412272453308, 1.8867005109786987, 0.44780752062797546],\n",
       "       [128.0, 0.2, 0.1, 20.0, 32.0, 2.394496440887451,\n",
       "        0.09700039029121399, 2.4683244228363037, 0.0966239795088768],\n",
       "       [128.0, 0.2, 0.1, 20.0, 64.0, 2.5396335124969482,\n",
       "        0.09661082923412323, 24.953643798828125, 0.09934031963348389],\n",
       "       [128.0, 0.2, 0.1, 20.0, 128.0, 2.3425776958465576,\n",
       "        0.10479158908128738, 2.3741719722747803, 0.10477299243211746],\n",
       "       [128.0, 0.2, 0.001, 30.0, 32.0, 0.18257713317871094,\n",
       "        0.9442929625511169, 1.821681261062622, 0.6115638613700867],\n",
       "       [128.0, 0.2, 0.001, 30.0, 64.0, 0.28031793236732483,\n",
       "        0.9228671789169312, 2.003369092941284, 0.5902211666107178],\n",
       "       [128.0, 0.2, 0.001, 30.0, 128.0, 0.43487119674682617,\n",
       "        0.860148012638092, 2.014957904815674, 0.5017462372779846],\n",
       "       [128.0, 0.2, 0.01, 30.0, 32.0, 1.4909783601760864,\n",
       "        0.49279314279556274, 1.9330990314483643, 0.3329452872276306],\n",
       "       [128.0, 0.2, 0.01, 30.0, 64.0, 1.0556690692901611,\n",
       "        0.6326451301574707, 1.8002849817276, 0.4512999653816223],\n",
       "       [128.0, 0.2, 0.01, 30.0, 128.0, 1.0637816190719604,\n",
       "        0.6505648493766785, 1.8004720211029053, 0.4784633219242096],\n",
       "       [128.0, 0.2, 0.1, 30.0, 32.0, 2.4617795944213867,\n",
       "        0.09466303139925003, 87.14738464355469, 0.10089251399040222],\n",
       "       [128.0, 0.2, 0.1, 30.0, 64.0, 2.359424352645874,\n",
       "        0.10712894797325134, 2.4855854511260986, 0.09507179260253906],\n",
       "       [128.0, 0.2, 0.1, 30.0, 128.0, 2.364307165145874,\n",
       "        0.09193611145019531, 2.336782455444336, 0.09584788233041763]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.columns=['lstm_units', 'dropout_rate', 'epoch', 'batch', 'loss', 'loss_max', 'accuracy', 'accuracy_max', 'val_loss', 'val_loss_max', 'val_accuracy', 'val_accuracy_max']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lstm_units</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>batch</th>\n",
       "      <th>loss</th>\n",
       "      <th>loss_max</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_max</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_loss_max</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_accuracy_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>20</td>\n",
       "      <td>64</td>\n",
       "      <td>0.434148</td>\n",
       "      <td>[2.4646902084350586, 1.4764158725738525, 1.160...</td>\n",
       "      <td>0.870311</td>\n",
       "      <td>[0.3031783699989319, 0.5757989287376404, 0.666...</td>\n",
       "      <td>0.736218</td>\n",
       "      <td>[1.6360548734664917, 1.2466334104537964, 1.031...</td>\n",
       "      <td>0.816564</td>\n",
       "      <td>[0.5272138714790344, 0.6362165212631226, 0.707...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lstm_units  ...                                   val_accuracy_max\n",
       "4         64  ...  [0.5272138714790344, 0.6362165212631226, 0.707...\n",
       "\n",
       "[1 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[results['val_accuracy'] == results['val_accuracy'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Lstm(64, 0.2, 20, 32, 0.001, (39,44), 30, 'models\\\\lstm_mod.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "213/213 [==============================] - ETA: 0s - loss: 2.7642 - accuracy: 0.3926\n",
      "Epoch 1: accuracy improved from -inf to 0.39262, saving model to models\\lstm_mod.h5\n",
      "213/213 [==============================] - 17s 46ms/step - loss: 2.7642 - accuracy: 0.3926\n",
      "Epoch 2/20\n",
      "213/213 [==============================] - ETA: 0s - loss: 1.5931 - accuracy: 0.6222\n",
      "Epoch 2: accuracy improved from 0.39262 to 0.62224, saving model to models\\lstm_mod.h5\n",
      "213/213 [==============================] - 10s 44ms/step - loss: 1.5931 - accuracy: 0.6222\n",
      "Epoch 3/20\n",
      "212/213 [============================>.] - ETA: 0s - loss: 1.2429 - accuracy: 0.6555\n",
      "Epoch 3: accuracy improved from 0.62224 to 0.65593, saving model to models\\lstm_mod.h5\n",
      "213/213 [==============================] - 9s 44ms/step - loss: 1.2420 - accuracy: 0.6559\n",
      "Epoch 4/20\n",
      "213/213 [==============================] - ETA: 0s - loss: 1.0566 - accuracy: 0.6890\n",
      "Epoch 4: accuracy improved from 0.65593 to 0.68903, saving model to models\\lstm_mod.h5\n",
      "213/213 [==============================] - 9s 44ms/step - loss: 1.0566 - accuracy: 0.6890\n",
      "Epoch 5/20\n",
      "213/213 [==============================] - ETA: 0s - loss: 0.9269 - accuracy: 0.7214\n",
      "Epoch 5: accuracy improved from 0.68903 to 0.72139, saving model to models\\lstm_mod.h5\n",
      "213/213 [==============================] - 10s 45ms/step - loss: 0.9269 - accuracy: 0.7214\n",
      "Epoch 6/20\n",
      "213/213 [==============================] - ETA: 0s - loss: 0.8182 - accuracy: 0.7501\n",
      "Epoch 6: accuracy improved from 0.72139 to 0.75007, saving model to models\\lstm_mod.h5\n",
      "213/213 [==============================] - 10s 45ms/step - loss: 0.8182 - accuracy: 0.7501\n",
      "Epoch 7/20\n",
      "213/213 [==============================] - ETA: 0s - loss: 0.7227 - accuracy: 0.7761\n",
      "Epoch 7: accuracy improved from 0.75007 to 0.77611, saving model to models\\lstm_mod.h5\n",
      "213/213 [==============================] - 10s 45ms/step - loss: 0.7227 - accuracy: 0.7761\n",
      "Epoch 8/20\n",
      "212/213 [============================>.] - ETA: 0s - loss: 0.6456 - accuracy: 0.7927\n",
      "Epoch 8: accuracy improved from 0.77611 to 0.79288, saving model to models\\lstm_mod.h5\n",
      "213/213 [==============================] - 10s 46ms/step - loss: 0.6455 - accuracy: 0.7929\n",
      "Epoch 9/20\n",
      "212/213 [============================>.] - ETA: 0s - loss: 0.5614 - accuracy: 0.8194\n",
      "Epoch 9: accuracy improved from 0.79288 to 0.81921, saving model to models\\lstm_mod.h5\n",
      "213/213 [==============================] - 11s 50ms/step - loss: 0.5612 - accuracy: 0.8192\n",
      "Epoch 10/20\n",
      "212/213 [============================>.] - ETA: 0s - loss: 0.5452 - accuracy: 0.8280\n",
      "Epoch 10: accuracy improved from 0.81921 to 0.82804, saving model to models\\lstm_mod.h5\n",
      "213/213 [==============================] - 11s 51ms/step - loss: 0.5453 - accuracy: 0.8280\n",
      "Epoch 11/20\n",
      "213/213 [==============================] - ETA: 0s - loss: 0.4609 - accuracy: 0.8503\n",
      "Epoch 11: accuracy improved from 0.82804 to 0.85025, saving model to models\\lstm_mod.h5\n",
      "213/213 [==============================] - 11s 50ms/step - loss: 0.4609 - accuracy: 0.8503\n",
      "Epoch 12/20\n",
      "213/213 [==============================] - ETA: 0s - loss: 0.4287 - accuracy: 0.8629\n",
      "Epoch 12: accuracy improved from 0.85025 to 0.86290, saving model to models\\lstm_mod.h5\n",
      "213/213 [==============================] - 11s 50ms/step - loss: 0.4287 - accuracy: 0.8629\n",
      "Epoch 13/20\n",
      "212/213 [============================>.] - ETA: 0s - loss: 0.3898 - accuracy: 0.8797\n",
      "Epoch 13: accuracy improved from 0.86290 to 0.87982, saving model to models\\lstm_mod.h5\n",
      "213/213 [==============================] - 11s 53ms/step - loss: 0.3902 - accuracy: 0.8798\n",
      "Epoch 14/20\n",
      "212/213 [============================>.] - ETA: 0s - loss: 0.3392 - accuracy: 0.8921\n",
      "Epoch 14: accuracy improved from 0.87982 to 0.89188, saving model to models\\lstm_mod.h5\n",
      "213/213 [==============================] - 11s 52ms/step - loss: 0.3407 - accuracy: 0.8919\n",
      "Epoch 15/20\n",
      "212/213 [============================>.] - ETA: 0s - loss: 0.3259 - accuracy: 0.8946\n",
      "Epoch 15: accuracy improved from 0.89188 to 0.89453, saving model to models\\lstm_mod.h5\n",
      "213/213 [==============================] - 11s 52ms/step - loss: 0.3264 - accuracy: 0.8945\n",
      "Epoch 16/20\n",
      "212/213 [============================>.] - ETA: 0s - loss: 0.2897 - accuracy: 0.9105\n",
      "Epoch 16: accuracy improved from 0.89453 to 0.91041, saving model to models\\lstm_mod.h5\n",
      "213/213 [==============================] - 11s 53ms/step - loss: 0.2904 - accuracy: 0.9104\n",
      "Epoch 17/20\n",
      "212/213 [============================>.] - ETA: 0s - loss: 0.2833 - accuracy: 0.9099\n",
      "Epoch 17: accuracy did not improve from 0.91041\n",
      "213/213 [==============================] - 11s 53ms/step - loss: 0.2829 - accuracy: 0.9101\n",
      "Epoch 18/20\n",
      "212/213 [============================>.] - ETA: 0s - loss: 0.2645 - accuracy: 0.9161\n",
      "Epoch 18: accuracy improved from 0.91041 to 0.91600, saving model to models\\lstm_mod.h5\n",
      "213/213 [==============================] - 11s 53ms/step - loss: 0.2652 - accuracy: 0.9160\n",
      "Epoch 19/20\n",
      "212/213 [============================>.] - ETA: 0s - loss: 0.2306 - accuracy: 0.9259\n",
      "Epoch 19: accuracy improved from 0.91600 to 0.92571, saving model to models\\lstm_mod.h5\n",
      "213/213 [==============================] - 11s 53ms/step - loss: 0.2310 - accuracy: 0.9257\n",
      "Epoch 20/20\n",
      "212/213 [============================>.] - ETA: 0s - loss: 0.2138 - accuracy: 0.9331\n",
      "Epoch 20: accuracy improved from 0.92571 to 0.93322, saving model to models\\lstm_mod.h5\n",
      "213/213 [==============================] - 12s 57ms/step - loss: 0.2135 - accuracy: 0.9332\n"
     ]
    }
   ],
   "source": [
    "model.train(label_detection_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense, Bidirectional, TimeDistributed, BatchNormalization\n",
    "from dataset import LABELS\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from dataset import label_detection_training, label_detection_validation, silence_detection_training, silence_detection_validation\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import TensorflowDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle('extracted_features\\\\features_training.pkl')\n",
    "y_train = np.array([x[1] for x in train])\n",
    "labels = list(np.unique(y_train))\n",
    "train = TensorflowDataset('extracted_features\\\\features_training.pkl', labels=labels).dataset\n",
    "train = train.shuffle(len(train), reshuffle_each_iteration=True)\n",
    "val = TensorflowDataset('extracted_features\\\\features_validation.pkl', labels=labels).dataset\n",
    "val = val.shuffle(len(val), reshuffle_each_iteration=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['lstm_units', 'dropout_rate', 'epoch', 'batch', 'loss', 'loss_max', 'accuracy', 'accuracy_max', 'val_loss', 'val_loss_max', 'val_accuracy', 'val_accuracy_max'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57923"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.read_pickle('extracted_features\\\\features_training.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model with 64 units, 0.2 dropout rate, 10 epochs and 32 batch size\n",
      "Epoch 1/10\n",
      "1811/1811 [==============================] - 218s 109ms/step - loss: 2.4271 - accuracy: 0.3132 - val_loss: 1.5653 - val_accuracy: 0.5462\n",
      "Epoch 2/10\n",
      "1811/1811 [==============================] - 159s 87ms/step - loss: 1.4517 - accuracy: 0.5814 - val_loss: 1.1923 - val_accuracy: 0.6553\n",
      "Epoch 3/10\n",
      "1811/1811 [==============================] - 167s 92ms/step - loss: 1.1520 - accuracy: 0.6685 - val_loss: 1.0082 - val_accuracy: 0.7170\n",
      "Epoch 4/10\n",
      "1811/1811 [==============================] - 183s 101ms/step - loss: 1.0003 - accuracy: 0.7115 - val_loss: 0.9068 - val_accuracy: 0.7343\n",
      "Epoch 5/10\n",
      "1811/1811 [==============================] - 180s 99ms/step - loss: 0.8990 - accuracy: 0.7417 - val_loss: 0.9288 - val_accuracy: 0.7396\n",
      "Epoch 6/10\n",
      "1811/1811 [==============================] - 182s 100ms/step - loss: 0.8240 - accuracy: 0.7619 - val_loss: 0.8555 - val_accuracy: 0.7611\n",
      "Epoch 7/10\n",
      "1811/1811 [==============================] - 181s 100ms/step - loss: 0.7710 - accuracy: 0.7767 - val_loss: 0.8312 - val_accuracy: 0.7702\n",
      "Epoch 8/10\n",
      "1811/1811 [==============================] - 182s 100ms/step - loss: 0.7267 - accuracy: 0.7895 - val_loss: 0.7934 - val_accuracy: 0.7777\n",
      "Epoch 9/10\n",
      "1811/1811 [==============================] - 193s 107ms/step - loss: 0.6943 - accuracy: 0.7999 - val_loss: 0.7510 - val_accuracy: 0.7951\n",
      "Epoch 10/10\n",
      "1811/1811 [==============================] - 206s 113ms/step - loss: 0.6609 - accuracy: 0.8072 - val_loss: 0.7606 - val_accuracy: 0.7955\n",
      "Running model with 64 units, 0.2 dropout rate, 10 epochs and 64 batch size\n",
      "Epoch 1/10\n",
      "906/906 [==============================] - 195s 181ms/step - loss: 2.4885 - accuracy: 0.3005 - val_loss: 1.6191 - val_accuracy: 0.5310\n",
      "Epoch 2/10\n",
      "906/906 [==============================] - 157s 173ms/step - loss: 1.4613 - accuracy: 0.5799 - val_loss: 1.1752 - val_accuracy: 0.6642\n",
      "Epoch 3/10\n",
      "906/906 [==============================] - 144s 158ms/step - loss: 1.1222 - accuracy: 0.6759 - val_loss: 1.0141 - val_accuracy: 0.7127\n",
      "Epoch 4/10\n",
      "906/906 [==============================] - 144s 159ms/step - loss: 0.9522 - accuracy: 0.7248 - val_loss: 0.9100 - val_accuracy: 0.7373\n",
      "Epoch 5/10\n",
      "906/906 [==============================] - 130s 143ms/step - loss: 0.8579 - accuracy: 0.7507 - val_loss: 0.8765 - val_accuracy: 0.7542\n",
      "Epoch 6/10\n",
      "906/906 [==============================] - 131s 145ms/step - loss: 0.7907 - accuracy: 0.7715 - val_loss: 0.8293 - val_accuracy: 0.7658\n",
      "Epoch 7/10\n",
      "906/906 [==============================] - 130s 143ms/step - loss: 0.7166 - accuracy: 0.7908 - val_loss: 0.7941 - val_accuracy: 0.7751\n",
      "Epoch 8/10\n",
      "906/906 [==============================] - 131s 144ms/step - loss: 0.6710 - accuracy: 0.8030 - val_loss: 0.8095 - val_accuracy: 0.7732\n",
      "Epoch 9/10\n",
      "906/906 [==============================] - 130s 144ms/step - loss: 0.6382 - accuracy: 0.8106 - val_loss: 0.7781 - val_accuracy: 0.7880\n",
      "Epoch 10/10\n",
      "906/906 [==============================] - 130s 143ms/step - loss: 0.6002 - accuracy: 0.8236 - val_loss: 0.7659 - val_accuracy: 0.7905\n",
      "Running model with 64 units, 0.2 dropout rate, 20 epochs and 32 batch size\n",
      "Epoch 1/20\n",
      "1811/1811 [==============================] - 202s 102ms/step - loss: 2.3512 - accuracy: 0.3354 - val_loss: 1.5099 - val_accuracy: 0.5597\n",
      "Epoch 2/20\n",
      "1811/1811 [==============================] - 171s 94ms/step - loss: 1.3959 - accuracy: 0.5999 - val_loss: 1.1395 - val_accuracy: 0.6802\n",
      "Epoch 3/20\n",
      "1811/1811 [==============================] - 172s 95ms/step - loss: 1.1104 - accuracy: 0.6819 - val_loss: 1.0019 - val_accuracy: 0.7132\n",
      "Epoch 4/20\n",
      "1811/1811 [==============================] - 174s 96ms/step - loss: 0.9653 - accuracy: 0.7231 - val_loss: 0.9118 - val_accuracy: 0.7448\n",
      "Epoch 5/20\n",
      "1811/1811 [==============================] - 173s 96ms/step - loss: 0.8767 - accuracy: 0.7490 - val_loss: 0.8685 - val_accuracy: 0.7599\n",
      "Epoch 6/20\n",
      "1811/1811 [==============================] - 175s 96ms/step - loss: 0.8132 - accuracy: 0.7653 - val_loss: 0.8413 - val_accuracy: 0.7693\n",
      "Epoch 7/20\n",
      "1811/1811 [==============================] - 176s 97ms/step - loss: 0.7643 - accuracy: 0.7804 - val_loss: 0.7937 - val_accuracy: 0.7811\n",
      "Epoch 8/20\n",
      "1811/1811 [==============================] - 180s 99ms/step - loss: 0.7142 - accuracy: 0.7942 - val_loss: 0.7716 - val_accuracy: 0.7882\n",
      "Epoch 9/20\n",
      "1811/1811 [==============================] - 184s 101ms/step - loss: 0.6812 - accuracy: 0.8041 - val_loss: 0.7966 - val_accuracy: 0.7801\n",
      "Epoch 10/20\n",
      "1811/1811 [==============================] - 190s 105ms/step - loss: 0.6510 - accuracy: 0.8111 - val_loss: 0.7837 - val_accuracy: 0.7916\n",
      "Epoch 11/20\n",
      "1811/1811 [==============================] - 190s 105ms/step - loss: 0.6208 - accuracy: 0.8206 - val_loss: 0.7309 - val_accuracy: 0.7988\n",
      "Epoch 12/20\n",
      "1811/1811 [==============================] - 194s 107ms/step - loss: 0.5985 - accuracy: 0.8266 - val_loss: 0.7361 - val_accuracy: 0.7999\n",
      "Epoch 13/20\n",
      "1811/1811 [==============================] - 198s 109ms/step - loss: 0.5756 - accuracy: 0.8332 - val_loss: 0.7206 - val_accuracy: 0.8061\n",
      "Epoch 14/20\n",
      "1811/1811 [==============================] - 196s 108ms/step - loss: 0.5598 - accuracy: 0.8393 - val_loss: 0.7367 - val_accuracy: 0.8029\n",
      "Epoch 15/20\n",
      "1811/1811 [==============================] - 200s 110ms/step - loss: 0.5344 - accuracy: 0.8445 - val_loss: 0.7284 - val_accuracy: 0.8010\n",
      "Epoch 16/20\n",
      "1811/1811 [==============================] - 219s 121ms/step - loss: 0.5257 - accuracy: 0.8474 - val_loss: 0.7300 - val_accuracy: 0.8111\n",
      "Epoch 17/20\n",
      "1811/1811 [==============================] - 222s 122ms/step - loss: 0.5041 - accuracy: 0.8523 - val_loss: 0.6965 - val_accuracy: 0.8127\n",
      "Epoch 18/20\n",
      "1811/1811 [==============================] - 228s 126ms/step - loss: 0.4937 - accuracy: 0.8562 - val_loss: 0.7070 - val_accuracy: 0.8130\n",
      "Epoch 19/20\n",
      "1811/1811 [==============================] - 235s 130ms/step - loss: 0.4784 - accuracy: 0.8593 - val_loss: 0.7119 - val_accuracy: 0.8169\n",
      "Epoch 20/20\n",
      "1811/1811 [==============================] - 241s 133ms/step - loss: 0.4597 - accuracy: 0.8654 - val_loss: 0.7083 - val_accuracy: 0.8163\n",
      "Running model with 64 units, 0.2 dropout rate, 20 epochs and 64 batch size\n",
      "Epoch 1/20\n",
      "906/906 [==============================] - 196s 190ms/step - loss: 2.4647 - accuracy: 0.3032 - val_loss: 1.6361 - val_accuracy: 0.5272\n",
      "Epoch 2/20\n",
      "906/906 [==============================] - 155s 171ms/step - loss: 1.4764 - accuracy: 0.5758 - val_loss: 1.2466 - val_accuracy: 0.6362\n",
      "Epoch 3/20\n",
      "906/906 [==============================] - 142s 156ms/step - loss: 1.1610 - accuracy: 0.6660 - val_loss: 1.0312 - val_accuracy: 0.7077\n",
      "Epoch 4/20\n",
      "906/906 [==============================] - 142s 157ms/step - loss: 0.9783 - accuracy: 0.7166 - val_loss: 0.9678 - val_accuracy: 0.7336\n",
      "Epoch 5/20\n",
      "906/906 [==============================] - 141s 155ms/step - loss: 0.8681 - accuracy: 0.7484 - val_loss: 0.8724 - val_accuracy: 0.7513\n",
      "Epoch 6/20\n",
      "906/906 [==============================] - 146s 161ms/step - loss: 0.7951 - accuracy: 0.7668 - val_loss: 0.8759 - val_accuracy: 0.7577\n",
      "Epoch 7/20\n",
      "906/906 [==============================] - 145s 160ms/step - loss: 0.7404 - accuracy: 0.7847 - val_loss: 0.7931 - val_accuracy: 0.7749\n",
      "Epoch 8/20\n",
      "906/906 [==============================] - 146s 161ms/step - loss: 0.6924 - accuracy: 0.7978 - val_loss: 0.8210 - val_accuracy: 0.7792\n",
      "Epoch 9/20\n",
      "906/906 [==============================] - 146s 161ms/step - loss: 0.6798 - accuracy: 0.8019 - val_loss: 0.7811 - val_accuracy: 0.7796\n",
      "Epoch 10/20\n",
      "906/906 [==============================] - 145s 160ms/step - loss: 0.6237 - accuracy: 0.8174 - val_loss: 0.7763 - val_accuracy: 0.7860\n",
      "Epoch 11/20\n",
      "906/906 [==============================] - 145s 160ms/step - loss: 0.5917 - accuracy: 0.8265 - val_loss: 0.7537 - val_accuracy: 0.7930\n",
      "Epoch 12/20\n",
      "906/906 [==============================] - 146s 161ms/step - loss: 0.5610 - accuracy: 0.8346 - val_loss: 0.7447 - val_accuracy: 0.7974\n",
      "Epoch 13/20\n",
      "906/906 [==============================] - 146s 161ms/step - loss: 0.5437 - accuracy: 0.8395 - val_loss: 0.7550 - val_accuracy: 0.8008\n",
      "Epoch 14/20\n",
      "906/906 [==============================] - 146s 162ms/step - loss: 0.5174 - accuracy: 0.8467 - val_loss: 0.7332 - val_accuracy: 0.8085\n",
      "Epoch 15/20\n",
      "906/906 [==============================] - 149s 165ms/step - loss: 0.5028 - accuracy: 0.8501 - val_loss: 0.7581 - val_accuracy: 0.8021\n",
      "Epoch 16/20\n",
      "906/906 [==============================] - 149s 164ms/step - loss: 0.5045 - accuracy: 0.8499 - val_loss: 0.7818 - val_accuracy: 0.8019\n",
      "Epoch 17/20\n",
      "906/906 [==============================] - 149s 165ms/step - loss: 0.4798 - accuracy: 0.8580 - val_loss: 0.7687 - val_accuracy: 0.8099\n",
      "Epoch 18/20\n",
      "906/906 [==============================] - 150s 165ms/step - loss: 0.4641 - accuracy: 0.8604 - val_loss: 0.7724 - val_accuracy: 0.8071\n",
      "Epoch 19/20\n",
      "906/906 [==============================] - 149s 165ms/step - loss: 0.4395 - accuracy: 0.8701 - val_loss: 0.7665 - val_accuracy: 0.8095\n",
      "Epoch 20/20\n",
      "906/906 [==============================] - 149s 164ms/step - loss: 0.4341 - accuracy: 0.8703 - val_loss: 0.7362 - val_accuracy: 0.8166\n",
      "Running model with 64 units, 0.4 dropout rate, 10 epochs and 32 batch size\n",
      "Epoch 1/10\n",
      "1811/1811 [==============================] - 295s 153ms/step - loss: 2.8703 - accuracy: 0.1959 - val_loss: 2.0042 - val_accuracy: 0.4179\n",
      "Epoch 2/10\n",
      "1811/1811 [==============================] - 288s 159ms/step - loss: 1.9049 - accuracy: 0.4504 - val_loss: 1.4960 - val_accuracy: 0.5721\n",
      "Epoch 3/10\n",
      "1811/1811 [==============================] - 289s 159ms/step - loss: 1.5276 - accuracy: 0.5626 - val_loss: 1.2571 - val_accuracy: 0.6412\n",
      "Epoch 4/10\n",
      "1811/1811 [==============================] - 297s 164ms/step - loss: 1.3307 - accuracy: 0.6239 - val_loss: 1.2024 - val_accuracy: 0.6706\n",
      "Epoch 5/10\n",
      "1811/1811 [==============================] - 313s 173ms/step - loss: 1.2068 - accuracy: 0.6603 - val_loss: 1.0343 - val_accuracy: 0.7093\n",
      "Epoch 6/10\n",
      "1811/1811 [==============================] - 339s 187ms/step - loss: 1.1144 - accuracy: 0.6882 - val_loss: 1.0484 - val_accuracy: 0.7158\n",
      "Epoch 7/10\n",
      "1811/1811 [==============================] - 333s 184ms/step - loss: 1.0497 - accuracy: 0.7063 - val_loss: 1.0144 - val_accuracy: 0.7282\n",
      "Epoch 8/10\n",
      "1811/1811 [==============================] - 318s 176ms/step - loss: 0.9992 - accuracy: 0.7203 - val_loss: 1.0292 - val_accuracy: 0.7277\n",
      "Epoch 9/10\n",
      "1811/1811 [==============================] - 329s 181ms/step - loss: 0.9536 - accuracy: 0.7311 - val_loss: 0.9564 - val_accuracy: 0.7448\n",
      "Epoch 10/10\n",
      "1811/1811 [==============================] - 335s 185ms/step - loss: 0.9225 - accuracy: 0.7423 - val_loss: 0.9438 - val_accuracy: 0.7551\n",
      "Running model with 64 units, 0.4 dropout rate, 10 epochs and 64 batch size\n",
      "Epoch 1/10\n",
      "906/906 [==============================] - 201s 202ms/step - loss: 3.0298 - accuracy: 0.1684 - val_loss: 2.0706 - val_accuracy: 0.3885\n",
      "Epoch 2/10\n",
      "906/906 [==============================] - 178s 197ms/step - loss: 1.9738 - accuracy: 0.4342 - val_loss: 1.5751 - val_accuracy: 0.5460\n",
      "Epoch 3/10\n",
      "906/906 [==============================] - 179s 197ms/step - loss: 1.5500 - accuracy: 0.5585 - val_loss: 1.3093 - val_accuracy: 0.6287\n",
      "Epoch 4/10\n",
      "906/906 [==============================] - 179s 198ms/step - loss: 1.3110 - accuracy: 0.6294 - val_loss: 1.1724 - val_accuracy: 0.6758\n",
      "Epoch 5/10\n",
      "906/906 [==============================] - 178s 197ms/step - loss: 1.1698 - accuracy: 0.6700 - val_loss: 1.0574 - val_accuracy: 0.7034\n",
      "Epoch 6/10\n",
      "906/906 [==============================] - 178s 196ms/step - loss: 1.0697 - accuracy: 0.6978 - val_loss: 1.0003 - val_accuracy: 0.7240\n",
      "Epoch 7/10\n",
      "906/906 [==============================] - 179s 197ms/step - loss: 1.0050 - accuracy: 0.7158 - val_loss: 0.9467 - val_accuracy: 0.7473\n",
      "Epoch 8/10\n",
      "906/906 [==============================] - 176s 195ms/step - loss: 0.9535 - accuracy: 0.7318 - val_loss: 0.9690 - val_accuracy: 0.7430\n",
      "Epoch 9/10\n",
      "906/906 [==============================] - 173s 191ms/step - loss: 0.9002 - accuracy: 0.7481 - val_loss: 0.9273 - val_accuracy: 0.7571\n",
      "Epoch 10/10\n",
      "906/906 [==============================] - 174s 192ms/step - loss: 0.8624 - accuracy: 0.7577 - val_loss: 0.9510 - val_accuracy: 0.7557\n",
      "Running model with 64 units, 0.4 dropout rate, 20 epochs and 32 batch size\n",
      "Epoch 1/20\n",
      "1811/1811 [==============================] - 378s 200ms/step - loss: 2.8722 - accuracy: 0.1976 - val_loss: 1.9758 - val_accuracy: 0.4259\n",
      "Epoch 2/20\n",
      "1811/1811 [==============================] - 380s 210ms/step - loss: 1.8928 - accuracy: 0.4520 - val_loss: 1.4281 - val_accuracy: 0.5837\n",
      "Epoch 3/20\n",
      "1811/1811 [==============================] - 390s 215ms/step - loss: 1.5408 - accuracy: 0.5597 - val_loss: 1.2735 - val_accuracy: 0.6437\n",
      "Epoch 4/20\n",
      "1811/1811 [==============================] - 387s 214ms/step - loss: 1.3381 - accuracy: 0.6230 - val_loss: 1.1302 - val_accuracy: 0.6842\n",
      "Epoch 5/20\n",
      "1811/1811 [==============================] - 388s 214ms/step - loss: 1.2103 - accuracy: 0.6587 - val_loss: 1.0444 - val_accuracy: 0.7115\n",
      "Epoch 6/20\n",
      "1811/1811 [==============================] - 398s 220ms/step - loss: 1.1175 - accuracy: 0.6845 - val_loss: 1.0384 - val_accuracy: 0.7161\n",
      "Epoch 7/20\n",
      "1811/1811 [==============================] - 424s 234ms/step - loss: 1.0529 - accuracy: 0.7047 - val_loss: 1.0182 - val_accuracy: 0.7342\n",
      "Epoch 8/20\n",
      "1811/1811 [==============================] - 430s 237ms/step - loss: 0.9945 - accuracy: 0.7219 - val_loss: 0.9475 - val_accuracy: 0.7449\n",
      "Epoch 9/20\n",
      "1811/1811 [==============================] - 385s 213ms/step - loss: 0.9527 - accuracy: 0.7324 - val_loss: 0.9105 - val_accuracy: 0.7588\n",
      "Epoch 10/20\n",
      "1811/1811 [==============================] - 385s 212ms/step - loss: 0.9154 - accuracy: 0.7443 - val_loss: 0.9463 - val_accuracy: 0.7564\n",
      "Epoch 11/20\n",
      "1811/1811 [==============================] - 383s 212ms/step - loss: 0.8826 - accuracy: 0.7519 - val_loss: 0.8953 - val_accuracy: 0.7710\n",
      "Epoch 12/20\n",
      "1811/1811 [==============================] - 382s 211ms/step - loss: 0.8483 - accuracy: 0.7625 - val_loss: 0.8936 - val_accuracy: 0.7655\n",
      "Epoch 13/20\n",
      "1811/1811 [==============================] - 382s 211ms/step - loss: 0.8264 - accuracy: 0.7701 - val_loss: 0.8615 - val_accuracy: 0.7779\n",
      "Epoch 14/20\n",
      "1811/1811 [==============================] - 380s 209ms/step - loss: 0.8018 - accuracy: 0.7771 - val_loss: 0.8662 - val_accuracy: 0.7814\n",
      "Epoch 15/20\n",
      "1811/1811 [==============================] - 371s 205ms/step - loss: 0.7768 - accuracy: 0.7821 - val_loss: 0.8780 - val_accuracy: 0.7751\n",
      "Epoch 16/20\n",
      "1811/1811 [==============================] - 372s 205ms/step - loss: 0.7673 - accuracy: 0.7861 - val_loss: 0.8705 - val_accuracy: 0.7810\n",
      "Epoch 17/20\n",
      "1811/1811 [==============================] - 374s 206ms/step - loss: 0.7433 - accuracy: 0.7934 - val_loss: 0.8134 - val_accuracy: 0.7907\n",
      "Epoch 18/20\n",
      "1811/1811 [==============================] - 375s 207ms/step - loss: 0.7239 - accuracy: 0.7975 - val_loss: 0.7981 - val_accuracy: 0.7896\n",
      "Epoch 19/20\n",
      "1811/1811 [==============================] - 373s 206ms/step - loss: 0.7137 - accuracy: 0.7997 - val_loss: 0.8127 - val_accuracy: 0.7882\n",
      "Epoch 20/20\n",
      "1811/1811 [==============================] - 375s 207ms/step - loss: 0.6955 - accuracy: 0.8061 - val_loss: 0.8091 - val_accuracy: 0.7948\n",
      "Running model with 64 units, 0.4 dropout rate, 20 epochs and 64 batch size\n",
      "Epoch 1/20\n",
      "906/906 [==============================] - 208s 214ms/step - loss: 3.0261 - accuracy: 0.1641 - val_loss: 2.1682 - val_accuracy: 0.3620\n",
      "Epoch 2/20\n",
      "906/906 [==============================] - 189s 208ms/step - loss: 1.9942 - accuracy: 0.4240 - val_loss: 1.5454 - val_accuracy: 0.5490\n",
      "Epoch 3/20\n",
      "906/906 [==============================] - 187s 206ms/step - loss: 1.5555 - accuracy: 0.5563 - val_loss: 1.2716 - val_accuracy: 0.6449\n",
      "Epoch 4/20\n",
      "906/906 [==============================] - 187s 207ms/step - loss: 1.3245 - accuracy: 0.6250 - val_loss: 1.1841 - val_accuracy: 0.6740\n",
      "Epoch 5/20\n",
      "906/906 [==============================] - 189s 208ms/step - loss: 1.1936 - accuracy: 0.6624 - val_loss: 1.1093 - val_accuracy: 0.6918\n",
      "Epoch 6/20\n",
      "906/906 [==============================] - 187s 206ms/step - loss: 1.0807 - accuracy: 0.6940 - val_loss: 1.0075 - val_accuracy: 0.7255\n",
      "Epoch 7/20\n",
      "906/906 [==============================] - 187s 206ms/step - loss: 1.0084 - accuracy: 0.7152 - val_loss: 1.0010 - val_accuracy: 0.7336\n",
      "Epoch 8/20\n",
      "906/906 [==============================] - 189s 208ms/step - loss: 0.9558 - accuracy: 0.7298 - val_loss: 0.9436 - val_accuracy: 0.7495\n",
      "Epoch 9/20\n",
      "906/906 [==============================] - 193s 213ms/step - loss: 0.9044 - accuracy: 0.7440 - val_loss: 0.9275 - val_accuracy: 0.7540\n",
      "Epoch 10/20\n",
      "906/906 [==============================] - 208s 229ms/step - loss: 0.8690 - accuracy: 0.7527 - val_loss: 0.9427 - val_accuracy: 0.7526\n",
      "Epoch 11/20\n",
      "906/906 [==============================] - 215s 237ms/step - loss: 0.8360 - accuracy: 0.7634 - val_loss: 0.9180 - val_accuracy: 0.7714\n",
      "Epoch 12/20\n",
      "906/906 [==============================] - 208s 229ms/step - loss: 0.8014 - accuracy: 0.7737 - val_loss: 0.8594 - val_accuracy: 0.7723\n",
      "Epoch 13/20\n",
      "906/906 [==============================] - 209s 231ms/step - loss: 0.7738 - accuracy: 0.7819 - val_loss: 0.8833 - val_accuracy: 0.7730\n",
      "Epoch 14/20\n",
      "906/906 [==============================] - 214s 236ms/step - loss: 0.7528 - accuracy: 0.7877 - val_loss: 0.8771 - val_accuracy: 0.7771\n",
      "Epoch 15/20\n",
      "906/906 [==============================] - 214s 236ms/step - loss: 0.7467 - accuracy: 0.7883 - val_loss: 0.9235 - val_accuracy: 0.7818\n",
      "Epoch 16/20\n",
      "906/906 [==============================] - 214s 236ms/step - loss: 0.7092 - accuracy: 0.7987 - val_loss: 0.8100 - val_accuracy: 0.7936\n",
      "Epoch 17/20\n",
      "906/906 [==============================] - 217s 239ms/step - loss: 0.6985 - accuracy: 0.8030 - val_loss: 0.8410 - val_accuracy: 0.7870\n",
      "Epoch 18/20\n",
      "906/906 [==============================] - 220s 243ms/step - loss: 0.6805 - accuracy: 0.8073 - val_loss: 0.8455 - val_accuracy: 0.7852\n",
      "Epoch 19/20\n",
      "906/906 [==============================] - 221s 244ms/step - loss: 0.6642 - accuracy: 0.8118 - val_loss: 0.8113 - val_accuracy: 0.7927\n",
      "Epoch 20/20\n",
      "906/906 [==============================] - 214s 236ms/step - loss: 0.6470 - accuracy: 0.8156 - val_loss: 0.8291 - val_accuracy: 0.7880\n",
      "Running model with 128 units, 0.2 dropout rate, 10 epochs and 32 batch size\n",
      "Epoch 1/10\n",
      "1811/1811 [==============================] - 668s 360ms/step - loss: 1.9494 - accuracy: 0.4494 - val_loss: 1.1921 - val_accuracy: 0.6574\n",
      "Epoch 2/10\n",
      "1811/1811 [==============================] - 646s 357ms/step - loss: 1.0881 - accuracy: 0.6869 - val_loss: 0.9664 - val_accuracy: 0.7254\n",
      "Epoch 3/10\n",
      "1811/1811 [==============================] - 652s 360ms/step - loss: 0.8788 - accuracy: 0.7457 - val_loss: 0.8291 - val_accuracy: 0.7677\n",
      "Epoch 4/10\n",
      "1811/1811 [==============================] - 653s 360ms/step - loss: 0.7712 - accuracy: 0.7764 - val_loss: 0.8340 - val_accuracy: 0.7627\n",
      "Epoch 5/10\n",
      "1811/1811 [==============================] - 654s 361ms/step - loss: 0.6929 - accuracy: 0.7998 - val_loss: 0.7899 - val_accuracy: 0.7798\n",
      "Epoch 6/10\n",
      " 390/1811 [=====>........................] - ETA: 7:04 - loss: 0.6014 - accuracy: 0.8266"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\deep\\Deep_Learning\\RNN\\models_lstm.ipynb Cell 6\u001b[0m in \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/deep/Deep_Learning/RNN/models_lstm.ipynb#W5sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/deep/Deep_Learning/RNN/models_lstm.ipynb#W5sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m# Train the model with your training set and validate it with your validation set\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/deep/Deep_Learning/RNN/models_lstm.ipynb#W5sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train\u001b[39m.\u001b[39;49mbatch(batch_size), epochs\u001b[39m=\u001b[39;49mepoch, validation_data\u001b[39m=\u001b[39;49mval\u001b[39m.\u001b[39;49mbatch(batch_size))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/deep/Deep_Learning/RNN/models_lstm.ipynb#W5sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m results \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((results, pd\u001b[39m.\u001b[39mDataFrame([[lstm_units, dropout_rate, epoch, batch_size, history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m], history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m], history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m], history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m]]], \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/deep/Deep_Learning/RNN/models_lstm.ipynb#W5sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m                                                 columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mlstm_units\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdropout_rate\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mloss_max\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39maccuracy_max\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mval_loss_max\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mval_accuracy_max\u001b[39m\u001b[39m'\u001b[39m])), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1642\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1643\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1644\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1648\u001b[0m ):\n\u001b[0;32m   1649\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1650\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1652\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    909\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    910\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    911\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 912\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_no_variable_creation_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    915\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m     args,\n\u001b[0;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1750\u001b[0m     executing_eagerly)\n\u001b[0;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set your model's hyperparameters\n",
    "for lstm_units in [64, 128]:\n",
    "    for dropout_rate in [0.2, 0.4]:\n",
    "            for epoch in [10, 20]:\n",
    "                  for batch_size in [32, 64]:\n",
    "                        print(f'Running model with {lstm_units} units, {dropout_rate} dropout rate, {epoch} epochs and {batch_size} batch size')\n",
    "\n",
    "                        num_classes = len(np.unique(labels))  # Number of unique classes in your dataset\n",
    "\n",
    "                        input_shape = (39, 44)\n",
    "\n",
    "                        model = Sequential([\n",
    "                            Bidirectional(LSTM(lstm_units, return_sequences=True), input_shape=input_shape),\n",
    "                            BatchNormalization(),\n",
    "                            Dropout(dropout_rate),\n",
    "                            Bidirectional(LSTM(lstm_units, return_sequences=True)),\n",
    "                            BatchNormalization(),\n",
    "                            Dropout(dropout_rate),\n",
    "                            LSTM(lstm_units, return_sequences=True),\n",
    "                            BatchNormalization(),\n",
    "                            Dropout(dropout_rate),\n",
    "                            TimeDistributed(Dense(64, activation='relu')),\n",
    "                            BatchNormalization(),\n",
    "                            Dropout(dropout_rate),\n",
    "                            TimeDistributed(Dense(32, activation='relu')),\n",
    "                            BatchNormalization(),\n",
    "                            Dropout(dropout_rate),\n",
    "                            LSTM(lstm_units),\n",
    "                            BatchNormalization(),\n",
    "                            Dropout(dropout_rate),\n",
    "                            Dense(num_classes, activation='softmax')\n",
    "                        ])\n",
    "\n",
    "\n",
    "                        # Compile the model\n",
    "                        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "                        # Train the model with your training set and validate it with your validation set\n",
    "                        history = model.fit(train.batch(batch_size), epochs=epoch, validation_data=val.batch(batch_size))\n",
    "\n",
    "                        results = np.concatenate((results, pd.DataFrame([[lstm_units, dropout_rate, epoch, batch_size, history.history['loss'][-1], history.history['loss'], history.history['accuracy'][-1], history.history['accuracy'], history.history['val_loss'][-1], history.history['val_loss'], history.history['val_accuracy'][-1], history.history['val_accuracy']]], \n",
    "                                                                        columns=['lstm_units', 'dropout_rate', 'epoch', 'batch', 'loss', 'loss_max', 'accuracy', 'accuracy_max', 'val_loss', 'val_loss_max', 'val_accuracy', 'val_accuracy_max'])), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_f = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>2.370784</td>\n",
       "      <td>[2.370784044265747]</td>\n",
       "      <td>0.333063</td>\n",
       "      <td>[0.3330628573894501]</td>\n",
       "      <td>1.522492</td>\n",
       "      <td>[1.5224920511245728]</td>\n",
       "      <td>0.5584</td>\n",
       "      <td>[0.5583995580673218]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>0.660897</td>\n",
       "      <td>[2.427072286605835, 1.4517465829849243, 1.1519...</td>\n",
       "      <td>0.807175</td>\n",
       "      <td>[0.31317439675331116, 0.581358015537262, 0.668...</td>\n",
       "      <td>0.76055</td>\n",
       "      <td>[1.5653058290481567, 1.1923205852508545, 1.008...</td>\n",
       "      <td>0.795528</td>\n",
       "      <td>[0.546190083026886, 0.655339777469635, 0.71697...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>0.600205</td>\n",
       "      <td>[2.488501787185669, 1.461273193359375, 1.12221...</td>\n",
       "      <td>0.823559</td>\n",
       "      <td>[0.30050238966941833, 0.5798560380935669, 0.67...</td>\n",
       "      <td>0.765887</td>\n",
       "      <td>[1.6190937757492065, 1.1751519441604614, 1.014...</td>\n",
       "      <td>0.790527</td>\n",
       "      <td>[0.5310385227203369, 0.6641659140586853, 0.712...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>0.459687</td>\n",
       "      <td>[2.3511674404144287, 1.395878791809082, 1.1104...</td>\n",
       "      <td>0.865408</td>\n",
       "      <td>[0.3353935480117798, 0.5998998880386353, 0.681...</td>\n",
       "      <td>0.708278</td>\n",
       "      <td>[1.5098788738250732, 1.139453411102295, 1.0019...</td>\n",
       "      <td>0.81627</td>\n",
       "      <td>[0.559723436832428, 0.6802000403404236, 0.7131...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>20</td>\n",
       "      <td>64</td>\n",
       "      <td>0.434148</td>\n",
       "      <td>[2.4646902084350586, 1.4764158725738525, 1.160...</td>\n",
       "      <td>0.870311</td>\n",
       "      <td>[0.3031783699989319, 0.5757989287376404, 0.666...</td>\n",
       "      <td>0.736218</td>\n",
       "      <td>[1.6360548734664917, 1.2466334104537964, 1.031...</td>\n",
       "      <td>0.816564</td>\n",
       "      <td>[0.5272138714790344, 0.6362165212631226, 0.707...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64</td>\n",
       "      <td>0.4</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>0.922474</td>\n",
       "      <td>[2.8702659606933594, 1.9048563241958618, 1.527...</td>\n",
       "      <td>0.74233</td>\n",
       "      <td>[0.19589799642562866, 0.4504428207874298, 0.56...</td>\n",
       "      <td>0.943816</td>\n",
       "      <td>[2.0041897296905518, 1.4960237741470337, 1.257...</td>\n",
       "      <td>0.755075</td>\n",
       "      <td>[0.41791704297065735, 0.5720800161361694, 0.64...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64</td>\n",
       "      <td>0.4</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>0.862444</td>\n",
       "      <td>[3.029785394668579, 1.9737733602523804, 1.5499...</td>\n",
       "      <td>0.757747</td>\n",
       "      <td>[0.16844776272773743, 0.4341798722743988, 0.55...</td>\n",
       "      <td>0.950969</td>\n",
       "      <td>[2.0705583095550537, 1.57509183883667, 1.30928...</td>\n",
       "      <td>0.755663</td>\n",
       "      <td>[0.38849660754203796, 0.5460429787635803, 0.62...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>64</td>\n",
       "      <td>0.4</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>0.695517</td>\n",
       "      <td>[2.872177839279175, 1.8928440809249878, 1.5408...</td>\n",
       "      <td>0.806105</td>\n",
       "      <td>[0.19755537807941437, 0.45203113555908203, 0.5...</td>\n",
       "      <td>0.809129</td>\n",
       "      <td>[1.9758355617523193, 1.4280952215194702, 1.273...</td>\n",
       "      <td>0.794793</td>\n",
       "      <td>[0.42586055397987366, 0.5837010741233826, 0.64...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>64</td>\n",
       "      <td>0.4</td>\n",
       "      <td>20</td>\n",
       "      <td>64</td>\n",
       "      <td>0.647044</td>\n",
       "      <td>[3.02612042427063, 1.9941836595535278, 1.55550...</td>\n",
       "      <td>0.815583</td>\n",
       "      <td>[0.1640971601009369, 0.42404571175575256, 0.55...</td>\n",
       "      <td>0.829114</td>\n",
       "      <td>[2.168159008026123, 1.5454410314559937, 1.2715...</td>\n",
       "      <td>0.788026</td>\n",
       "      <td>[0.3620182275772095, 0.5489850044250488, 0.644...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1   2   3         4   \\\n",
       "0  64  0.2   1  32  2.370784   \n",
       "1  64  0.2  10  32  0.660897   \n",
       "2  64  0.2  10  64  0.600205   \n",
       "3  64  0.2  20  32  0.459687   \n",
       "4  64  0.2  20  64  0.434148   \n",
       "5  64  0.4  10  32  0.922474   \n",
       "6  64  0.4  10  64  0.862444   \n",
       "7  64  0.4  20  32  0.695517   \n",
       "8  64  0.4  20  64  0.647044   \n",
       "\n",
       "                                                  5         6   \\\n",
       "0                                [2.370784044265747]  0.333063   \n",
       "1  [2.427072286605835, 1.4517465829849243, 1.1519...  0.807175   \n",
       "2  [2.488501787185669, 1.461273193359375, 1.12221...  0.823559   \n",
       "3  [2.3511674404144287, 1.395878791809082, 1.1104...  0.865408   \n",
       "4  [2.4646902084350586, 1.4764158725738525, 1.160...  0.870311   \n",
       "5  [2.8702659606933594, 1.9048563241958618, 1.527...   0.74233   \n",
       "6  [3.029785394668579, 1.9737733602523804, 1.5499...  0.757747   \n",
       "7  [2.872177839279175, 1.8928440809249878, 1.5408...  0.806105   \n",
       "8  [3.02612042427063, 1.9941836595535278, 1.55550...  0.815583   \n",
       "\n",
       "                                                  7         8   \\\n",
       "0                               [0.3330628573894501]  1.522492   \n",
       "1  [0.31317439675331116, 0.581358015537262, 0.668...   0.76055   \n",
       "2  [0.30050238966941833, 0.5798560380935669, 0.67...  0.765887   \n",
       "3  [0.3353935480117798, 0.5998998880386353, 0.681...  0.708278   \n",
       "4  [0.3031783699989319, 0.5757989287376404, 0.666...  0.736218   \n",
       "5  [0.19589799642562866, 0.4504428207874298, 0.56...  0.943816   \n",
       "6  [0.16844776272773743, 0.4341798722743988, 0.55...  0.950969   \n",
       "7  [0.19755537807941437, 0.45203113555908203, 0.5...  0.809129   \n",
       "8  [0.1640971601009369, 0.42404571175575256, 0.55...  0.829114   \n",
       "\n",
       "                                                  9         10  \\\n",
       "0                               [1.5224920511245728]    0.5584   \n",
       "1  [1.5653058290481567, 1.1923205852508545, 1.008...  0.795528   \n",
       "2  [1.6190937757492065, 1.1751519441604614, 1.014...  0.790527   \n",
       "3  [1.5098788738250732, 1.139453411102295, 1.0019...   0.81627   \n",
       "4  [1.6360548734664917, 1.2466334104537964, 1.031...  0.816564   \n",
       "5  [2.0041897296905518, 1.4960237741470337, 1.257...  0.755075   \n",
       "6  [2.0705583095550537, 1.57509183883667, 1.30928...  0.755663   \n",
       "7  [1.9758355617523193, 1.4280952215194702, 1.273...  0.794793   \n",
       "8  [2.168159008026123, 1.5454410314559937, 1.2715...  0.788026   \n",
       "\n",
       "                                                  11  \n",
       "0                               [0.5583995580673218]  \n",
       "1  [0.546190083026886, 0.655339777469635, 0.71697...  \n",
       "2  [0.5310385227203369, 0.6641659140586853, 0.712...  \n",
       "3  [0.559723436832428, 0.6802000403404236, 0.7131...  \n",
       "4  [0.5272138714790344, 0.6362165212631226, 0.707...  \n",
       "5  [0.41791704297065735, 0.5720800161361694, 0.64...  \n",
       "6  [0.38849660754203796, 0.5460429787635803, 0.62...  \n",
       "7  [0.42586055397987366, 0.5837010741233826, 0.64...  \n",
       "8  [0.3620182275772095, 0.5489850044250488, 0.644...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_f.to_pickle('results\\\\model_lstm_final_version.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "214/214 [==============================] - 24s 79ms/step - loss: 7.0679 - accuracy: 0.0974 - val_loss: 4.0350 - val_accuracy: 0.1478\n",
      "Epoch 2/10\n",
      "214/214 [==============================] - 16s 74ms/step - loss: 2.9956 - accuracy: 0.2135 - val_loss: 2.5939 - val_accuracy: 0.2307\n",
      "Epoch 3/10\n",
      "214/214 [==============================] - 16s 75ms/step - loss: 2.3891 - accuracy: 0.2976 - val_loss: 2.3668 - val_accuracy: 0.3070\n",
      "Epoch 4/10\n",
      "214/214 [==============================] - 16s 77ms/step - loss: 2.1566 - accuracy: 0.3582 - val_loss: 2.2170 - val_accuracy: 0.3557\n",
      "Epoch 5/10\n",
      "214/214 [==============================] - 16s 77ms/step - loss: 1.9021 - accuracy: 0.4253 - val_loss: 2.1590 - val_accuracy: 0.3886\n",
      "Epoch 6/10\n",
      "214/214 [==============================] - 17s 82ms/step - loss: 1.7554 - accuracy: 0.4759 - val_loss: 2.0464 - val_accuracy: 0.4235\n",
      "Epoch 7/10\n",
      "214/214 [==============================] - 17s 78ms/step - loss: 1.5497 - accuracy: 0.5342 - val_loss: 2.0235 - val_accuracy: 0.4553\n",
      "Epoch 8/10\n",
      "214/214 [==============================] - 17s 80ms/step - loss: 1.4081 - accuracy: 0.5743 - val_loss: 1.9285 - val_accuracy: 0.4707\n",
      "Epoch 9/10\n",
      "214/214 [==============================] - 16s 77ms/step - loss: 1.2639 - accuracy: 0.6206 - val_loss: 1.9814 - val_accuracy: 0.4769\n",
      "Epoch 10/10\n",
      "214/214 [==============================] - 16s 76ms/step - loss: 1.1530 - accuracy: 0.6538 - val_loss: 1.9833 - val_accuracy: 0.4921\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 19s 129ms/step - loss: 8.1597 - accuracy: 0.0670 - val_loss: 7.3030 - val_accuracy: 0.0815\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 14s 128ms/step - loss: 4.6201 - accuracy: 0.1165 - val_loss: 3.5234 - val_accuracy: 0.1293\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 14s 129ms/step - loss: 2.9787 - accuracy: 0.1899 - val_loss: 2.8644 - val_accuracy: 0.2061\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 14s 130ms/step - loss: 2.5482 - accuracy: 0.2533 - val_loss: 2.6199 - val_accuracy: 0.2454\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 14s 134ms/step - loss: 2.2535 - accuracy: 0.3261 - val_loss: 2.4200 - val_accuracy: 0.2998\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 14s 132ms/step - loss: 2.0015 - accuracy: 0.3940 - val_loss: 2.4180 - val_accuracy: 0.3503\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 13s 126ms/step - loss: 1.8026 - accuracy: 0.4549 - val_loss: 2.2331 - val_accuracy: 0.3885\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 14s 131ms/step - loss: 1.6417 - accuracy: 0.5005 - val_loss: 2.2714 - val_accuracy: 0.3973\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 14s 132ms/step - loss: 1.4811 - accuracy: 0.5469 - val_loss: 2.2330 - val_accuracy: 0.4207\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 13s 126ms/step - loss: 1.3481 - accuracy: 0.5832 - val_loss: 2.1527 - val_accuracy: 0.4328\n",
      "Epoch 1/10\n",
      "54/54 [==============================] - 20s 262ms/step - loss: 8.5656 - accuracy: 0.0683 - val_loss: 8.6474 - val_accuracy: 0.0731\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 14s 260ms/step - loss: 6.7229 - accuracy: 0.1065 - val_loss: 7.3296 - val_accuracy: 0.0908\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 14s 263ms/step - loss: 4.1290 - accuracy: 0.1513 - val_loss: 4.2149 - val_accuracy: 0.1414\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 14s 259ms/step - loss: 2.9740 - accuracy: 0.2066 - val_loss: 3.1875 - val_accuracy: 0.1730\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 14s 265ms/step - loss: 2.5382 - accuracy: 0.2676 - val_loss: 2.8308 - val_accuracy: 0.2193\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 14s 266ms/step - loss: 2.2748 - accuracy: 0.3197 - val_loss: 2.6625 - val_accuracy: 0.2690\n",
      "Epoch 7/10\n",
      "54/54 [==============================] - 15s 272ms/step - loss: 2.0755 - accuracy: 0.3766 - val_loss: 2.6192 - val_accuracy: 0.2854\n",
      "Epoch 8/10\n",
      "54/54 [==============================] - 15s 275ms/step - loss: 1.8885 - accuracy: 0.4215 - val_loss: 2.5402 - val_accuracy: 0.3173\n",
      "Epoch 9/10\n",
      "54/54 [==============================] - 15s 277ms/step - loss: 1.6941 - accuracy: 0.4732 - val_loss: 2.4512 - val_accuracy: 0.3578\n",
      "Epoch 10/10\n",
      "54/54 [==============================] - 15s 271ms/step - loss: 1.5866 - accuracy: 0.5096 - val_loss: 2.4329 - val_accuracy: 0.3747\n",
      "Epoch 1/20\n",
      "214/214 [==============================] - 27s 93ms/step - loss: 6.9976 - accuracy: 0.0746 - val_loss: 4.1619 - val_accuracy: 0.0987\n",
      "Epoch 2/20\n",
      "214/214 [==============================] - 19s 90ms/step - loss: 3.1049 - accuracy: 0.1567 - val_loss: 2.7697 - val_accuracy: 0.1881\n",
      "Epoch 3/20\n",
      "214/214 [==============================] - 18s 84ms/step - loss: 2.6071 - accuracy: 0.2279 - val_loss: 2.5867 - val_accuracy: 0.2411\n",
      "Epoch 4/20\n",
      "214/214 [==============================] - 18s 86ms/step - loss: 2.3011 - accuracy: 0.3121 - val_loss: 2.5347 - val_accuracy: 0.2823\n",
      "Epoch 5/20\n",
      "214/214 [==============================] - 20s 94ms/step - loss: 2.0655 - accuracy: 0.3871 - val_loss: 2.2193 - val_accuracy: 0.3538\n",
      "Epoch 6/20\n",
      "214/214 [==============================] - 24s 112ms/step - loss: 1.8670 - accuracy: 0.4420 - val_loss: 2.2733 - val_accuracy: 0.3807\n",
      "Epoch 7/20\n",
      "214/214 [==============================] - 24s 114ms/step - loss: 1.6989 - accuracy: 0.4957 - val_loss: 2.1128 - val_accuracy: 0.4209\n",
      "Epoch 8/20\n",
      "214/214 [==============================] - 25s 115ms/step - loss: 1.5359 - accuracy: 0.5435 - val_loss: 2.1348 - val_accuracy: 0.4300\n",
      "Epoch 9/20\n",
      "214/214 [==============================] - 24s 114ms/step - loss: 1.3788 - accuracy: 0.5830 - val_loss: 2.0927 - val_accuracy: 0.4416\n",
      "Epoch 10/20\n",
      "214/214 [==============================] - 24s 113ms/step - loss: 1.3009 - accuracy: 0.6102 - val_loss: 2.0433 - val_accuracy: 0.4766\n",
      "Epoch 11/20\n",
      "214/214 [==============================] - 20s 95ms/step - loss: 1.1647 - accuracy: 0.6516 - val_loss: 2.1197 - val_accuracy: 0.4819\n",
      "Epoch 12/20\n",
      "214/214 [==============================] - 23s 107ms/step - loss: 1.0269 - accuracy: 0.6882 - val_loss: 2.0099 - val_accuracy: 0.4979\n",
      "Epoch 13/20\n",
      "214/214 [==============================] - 25s 115ms/step - loss: 0.9724 - accuracy: 0.7030 - val_loss: 2.1107 - val_accuracy: 0.4932\n",
      "Epoch 14/20\n",
      "214/214 [==============================] - 26s 120ms/step - loss: 0.9154 - accuracy: 0.7150 - val_loss: 2.1318 - val_accuracy: 0.5007\n",
      "Epoch 15/20\n",
      "214/214 [==============================] - 26s 120ms/step - loss: 0.8471 - accuracy: 0.7422 - val_loss: 2.1437 - val_accuracy: 0.4943\n",
      "Epoch 16/20\n",
      "214/214 [==============================] - 25s 117ms/step - loss: 0.7899 - accuracy: 0.7563 - val_loss: 2.1848 - val_accuracy: 0.5090\n",
      "Epoch 17/20\n",
      "214/214 [==============================] - 24s 114ms/step - loss: 0.7355 - accuracy: 0.7789 - val_loss: 2.0544 - val_accuracy: 0.5199\n",
      "Epoch 18/20\n",
      "214/214 [==============================] - 24s 112ms/step - loss: 0.6723 - accuracy: 0.7879 - val_loss: 2.2667 - val_accuracy: 0.5184\n",
      "Epoch 19/20\n",
      "214/214 [==============================] - 24s 114ms/step - loss: 0.6669 - accuracy: 0.7966 - val_loss: 2.1855 - val_accuracy: 0.5394\n",
      "Epoch 20/20\n",
      "214/214 [==============================] - 24s 114ms/step - loss: 0.5972 - accuracy: 0.8094 - val_loss: 2.1903 - val_accuracy: 0.5337\n",
      "Epoch 1/20\n",
      "107/107 [==============================] - 34s 209ms/step - loss: 8.2656 - accuracy: 0.0715 - val_loss: 7.6677 - val_accuracy: 0.0830\n",
      "Epoch 2/20\n",
      "107/107 [==============================] - 15s 145ms/step - loss: 4.6485 - accuracy: 0.1437 - val_loss: 3.3839 - val_accuracy: 0.1587\n",
      "Epoch 3/20\n",
      "107/107 [==============================] - 19s 174ms/step - loss: 2.7805 - accuracy: 0.2361 - val_loss: 2.7547 - val_accuracy: 0.2376\n",
      "Epoch 4/20\n",
      "107/107 [==============================] - 26s 240ms/step - loss: 2.3154 - accuracy: 0.3137 - val_loss: 2.6240 - val_accuracy: 0.2702\n",
      "Epoch 5/20\n",
      "107/107 [==============================] - 25s 234ms/step - loss: 2.0444 - accuracy: 0.3743 - val_loss: 2.3347 - val_accuracy: 0.3219\n",
      "Epoch 6/20\n",
      "107/107 [==============================] - 26s 241ms/step - loss: 1.8619 - accuracy: 0.4341 - val_loss: 2.3996 - val_accuracy: 0.3555\n",
      "Epoch 7/20\n",
      "107/107 [==============================] - 24s 222ms/step - loss: 1.6742 - accuracy: 0.4832 - val_loss: 2.2945 - val_accuracy: 0.3786\n",
      "Epoch 8/20\n",
      "107/107 [==============================] - 26s 247ms/step - loss: 1.5153 - accuracy: 0.5314 - val_loss: 2.3106 - val_accuracy: 0.4035\n",
      "Epoch 9/20\n",
      "107/107 [==============================] - 26s 240ms/step - loss: 1.3778 - accuracy: 0.5748 - val_loss: 2.2447 - val_accuracy: 0.4294\n",
      "Epoch 10/20\n",
      "107/107 [==============================] - 27s 251ms/step - loss: 1.2629 - accuracy: 0.6067 - val_loss: 2.2621 - val_accuracy: 0.4362\n",
      "Epoch 11/20\n",
      "107/107 [==============================] - 25s 239ms/step - loss: 1.1386 - accuracy: 0.6465 - val_loss: 2.4361 - val_accuracy: 0.4344\n",
      "Epoch 12/20\n",
      "107/107 [==============================] - 25s 231ms/step - loss: 1.0243 - accuracy: 0.6772 - val_loss: 2.1989 - val_accuracy: 0.4666\n",
      "Epoch 13/20\n",
      "107/107 [==============================] - 25s 232ms/step - loss: 0.9611 - accuracy: 0.6999 - val_loss: 2.3378 - val_accuracy: 0.4594\n",
      "Epoch 14/20\n",
      "107/107 [==============================] - 22s 205ms/step - loss: 0.8740 - accuracy: 0.7270 - val_loss: 2.2546 - val_accuracy: 0.4803\n",
      "Epoch 15/20\n",
      "107/107 [==============================] - 26s 242ms/step - loss: 0.8037 - accuracy: 0.7492 - val_loss: 2.3939 - val_accuracy: 0.4741\n",
      "Epoch 16/20\n",
      "107/107 [==============================] - 25s 238ms/step - loss: 0.7143 - accuracy: 0.7740 - val_loss: 2.4012 - val_accuracy: 0.4971\n",
      "Epoch 17/20\n",
      "107/107 [==============================] - 26s 240ms/step - loss: 0.6938 - accuracy: 0.7802 - val_loss: 2.4125 - val_accuracy: 0.4854\n",
      "Epoch 18/20\n",
      "107/107 [==============================] - 25s 235ms/step - loss: 0.6484 - accuracy: 0.7895 - val_loss: 2.3975 - val_accuracy: 0.4951\n",
      "Epoch 19/20\n",
      "107/107 [==============================] - 25s 233ms/step - loss: 0.5791 - accuracy: 0.8174 - val_loss: 2.4468 - val_accuracy: 0.5016\n",
      "Epoch 20/20\n",
      "107/107 [==============================] - 25s 234ms/step - loss: 0.5732 - accuracy: 0.8140 - val_loss: 2.5099 - val_accuracy: 0.4971\n",
      "Epoch 1/20\n",
      "54/54 [==============================] - 55s 426ms/step - loss: 8.6456 - accuracy: 0.0639 - val_loss: 8.6110 - val_accuracy: 0.0934\n",
      "Epoch 2/20\n",
      "54/54 [==============================] - 18s 341ms/step - loss: 7.1500 - accuracy: 0.1527 - val_loss: 6.9634 - val_accuracy: 0.1383\n",
      "Epoch 3/20\n",
      "54/54 [==============================] - 23s 433ms/step - loss: 4.2134 - accuracy: 0.2026 - val_loss: 4.0020 - val_accuracy: 0.1826\n",
      "Epoch 4/20\n",
      "54/54 [==============================] - 26s 478ms/step - loss: 2.7190 - accuracy: 0.2824 - val_loss: 2.9305 - val_accuracy: 0.2221\n",
      "Epoch 5/20\n",
      "54/54 [==============================] - 25s 473ms/step - loss: 2.2556 - accuracy: 0.3463 - val_loss: 2.6296 - val_accuracy: 0.2852\n",
      "Epoch 6/20\n",
      "54/54 [==============================] - 22s 415ms/step - loss: 1.9787 - accuracy: 0.4056 - val_loss: 2.4977 - val_accuracy: 0.3147\n",
      "Epoch 7/20\n",
      "54/54 [==============================] - 24s 451ms/step - loss: 1.7729 - accuracy: 0.4563 - val_loss: 2.4587 - val_accuracy: 0.3582\n",
      "Epoch 8/20\n",
      "54/54 [==============================] - 24s 444ms/step - loss: 1.6062 - accuracy: 0.5163 - val_loss: 2.3804 - val_accuracy: 0.3723\n",
      "Epoch 9/20\n",
      "54/54 [==============================] - 20s 379ms/step - loss: 1.4455 - accuracy: 0.5523 - val_loss: 2.4712 - val_accuracy: 0.3909\n",
      "Epoch 10/20\n",
      "54/54 [==============================] - 20s 377ms/step - loss: 1.3261 - accuracy: 0.5915 - val_loss: 2.4856 - val_accuracy: 0.4100\n",
      "Epoch 11/20\n",
      "54/54 [==============================] - 22s 419ms/step - loss: 1.2026 - accuracy: 0.6263 - val_loss: 2.4964 - val_accuracy: 0.4148\n",
      "Epoch 12/20\n",
      "54/54 [==============================] - 23s 438ms/step - loss: 1.1190 - accuracy: 0.6582 - val_loss: 2.5527 - val_accuracy: 0.4103\n",
      "Epoch 13/20\n",
      "54/54 [==============================] - 25s 466ms/step - loss: 1.0109 - accuracy: 0.6841 - val_loss: 2.4919 - val_accuracy: 0.4401\n",
      "Epoch 14/20\n",
      "54/54 [==============================] - 21s 386ms/step - loss: 0.9556 - accuracy: 0.6990 - val_loss: 2.4979 - val_accuracy: 0.4453\n",
      "Epoch 15/20\n",
      "54/54 [==============================] - 25s 457ms/step - loss: 0.8737 - accuracy: 0.7289 - val_loss: 2.4132 - val_accuracy: 0.4618\n",
      "Epoch 16/20\n",
      "54/54 [==============================] - 25s 466ms/step - loss: 0.8092 - accuracy: 0.7454 - val_loss: 2.5038 - val_accuracy: 0.4670\n",
      "Epoch 17/20\n",
      "54/54 [==============================] - 24s 455ms/step - loss: 0.7457 - accuracy: 0.7621 - val_loss: 2.5719 - val_accuracy: 0.4648\n",
      "Epoch 18/20\n",
      "54/54 [==============================] - 25s 460ms/step - loss: 0.7130 - accuracy: 0.7741 - val_loss: 2.5424 - val_accuracy: 0.4728\n",
      "Epoch 19/20\n",
      "54/54 [==============================] - 25s 463ms/step - loss: 0.6925 - accuracy: 0.7804 - val_loss: 2.5761 - val_accuracy: 0.4779\n",
      "Epoch 20/20\n",
      "54/54 [==============================] - 25s 457ms/step - loss: 0.6198 - accuracy: 0.8045 - val_loss: 2.5163 - val_accuracy: 0.4900\n",
      "Epoch 1/30\n",
      "214/214 [==============================] - 66s 134ms/step - loss: 6.9826 - accuracy: 0.0828 - val_loss: 3.9669 - val_accuracy: 0.1340\n",
      "Epoch 2/30\n",
      "214/214 [==============================] - 21s 100ms/step - loss: 3.0718 - accuracy: 0.1678 - val_loss: 2.6871 - val_accuracy: 0.2121\n",
      "Epoch 3/30\n",
      "214/214 [==============================] - 25s 117ms/step - loss: 2.5010 - accuracy: 0.2508 - val_loss: 2.5020 - val_accuracy: 0.2727\n",
      "Epoch 4/30\n",
      "214/214 [==============================] - 27s 127ms/step - loss: 2.2247 - accuracy: 0.3343 - val_loss: 2.3381 - val_accuracy: 0.3252\n",
      "Epoch 5/30\n",
      "214/214 [==============================] - 26s 124ms/step - loss: 1.9977 - accuracy: 0.4097 - val_loss: 2.2083 - val_accuracy: 0.3678\n",
      "Epoch 6/30\n",
      "214/214 [==============================] - 25s 117ms/step - loss: 1.7954 - accuracy: 0.4644 - val_loss: 2.1485 - val_accuracy: 0.3961\n",
      "Epoch 7/30\n",
      "214/214 [==============================] - 28s 129ms/step - loss: 1.6058 - accuracy: 0.5168 - val_loss: 2.0914 - val_accuracy: 0.4251\n",
      "Epoch 8/30\n",
      "214/214 [==============================] - 27s 127ms/step - loss: 1.4673 - accuracy: 0.5555 - val_loss: 2.0391 - val_accuracy: 0.4503\n",
      "Epoch 9/30\n",
      "214/214 [==============================] - 27s 128ms/step - loss: 1.3345 - accuracy: 0.5930 - val_loss: 1.9640 - val_accuracy: 0.4653\n",
      "Epoch 10/30\n",
      "214/214 [==============================] - 27s 128ms/step - loss: 1.2026 - accuracy: 0.6369 - val_loss: 1.9732 - val_accuracy: 0.4812\n",
      "Epoch 11/30\n",
      "214/214 [==============================] - 27s 127ms/step - loss: 1.1275 - accuracy: 0.6505 - val_loss: 1.9848 - val_accuracy: 0.4926\n",
      "Epoch 12/30\n",
      "214/214 [==============================] - 25s 115ms/step - loss: 1.0156 - accuracy: 0.6939 - val_loss: 1.9866 - val_accuracy: 0.5050\n",
      "Epoch 13/30\n",
      "214/214 [==============================] - 28s 130ms/step - loss: 0.9491 - accuracy: 0.7138 - val_loss: 1.9992 - val_accuracy: 0.5046\n",
      "Epoch 14/30\n",
      "214/214 [==============================] - 28s 130ms/step - loss: 0.8727 - accuracy: 0.7393 - val_loss: 2.0771 - val_accuracy: 0.5106\n",
      "Epoch 15/30\n",
      "214/214 [==============================] - 28s 129ms/step - loss: 0.8163 - accuracy: 0.7497 - val_loss: 2.0610 - val_accuracy: 0.5199\n",
      "Epoch 16/30\n",
      "214/214 [==============================] - 28s 130ms/step - loss: 0.7585 - accuracy: 0.7745 - val_loss: 2.0668 - val_accuracy: 0.5337\n",
      "Epoch 17/30\n",
      "214/214 [==============================] - 28s 130ms/step - loss: 0.7104 - accuracy: 0.7829 - val_loss: 2.1186 - val_accuracy: 0.5306\n",
      "Epoch 18/30\n",
      "214/214 [==============================] - 28s 130ms/step - loss: 0.6489 - accuracy: 0.7985 - val_loss: 2.1550 - val_accuracy: 0.5246\n",
      "Epoch 19/30\n",
      "214/214 [==============================] - 28s 130ms/step - loss: 0.6426 - accuracy: 0.7987 - val_loss: 2.0900 - val_accuracy: 0.5437\n",
      "Epoch 20/30\n",
      "214/214 [==============================] - 25s 118ms/step - loss: 0.6031 - accuracy: 0.8143 - val_loss: 2.2478 - val_accuracy: 0.5212\n",
      "Epoch 21/30\n",
      "214/214 [==============================] - 22s 102ms/step - loss: 0.5634 - accuracy: 0.8259 - val_loss: 2.2508 - val_accuracy: 0.5365\n",
      "Epoch 22/30\n",
      "214/214 [==============================] - 22s 101ms/step - loss: 0.5289 - accuracy: 0.8320 - val_loss: 2.2618 - val_accuracy: 0.5413\n",
      "Epoch 23/30\n",
      "214/214 [==============================] - 24s 110ms/step - loss: 0.5091 - accuracy: 0.8478 - val_loss: 2.2378 - val_accuracy: 0.5349\n",
      "Epoch 24/30\n",
      "214/214 [==============================] - 24s 114ms/step - loss: 0.4909 - accuracy: 0.8497 - val_loss: 2.2624 - val_accuracy: 0.5388\n",
      "Epoch 25/30\n",
      "214/214 [==============================] - 24s 112ms/step - loss: 0.4643 - accuracy: 0.8578 - val_loss: 2.2581 - val_accuracy: 0.5480\n",
      "Epoch 26/30\n",
      "214/214 [==============================] - 24s 113ms/step - loss: 0.4388 - accuracy: 0.8639 - val_loss: 2.3735 - val_accuracy: 0.5341\n",
      "Epoch 27/30\n",
      "214/214 [==============================] - 25s 118ms/step - loss: 0.4240 - accuracy: 0.8647 - val_loss: 2.3628 - val_accuracy: 0.5449\n",
      "Epoch 28/30\n",
      "214/214 [==============================] - 25s 118ms/step - loss: 0.4198 - accuracy: 0.8714 - val_loss: 2.3963 - val_accuracy: 0.5437\n",
      "Epoch 29/30\n",
      "214/214 [==============================] - 25s 117ms/step - loss: 0.3986 - accuracy: 0.8761 - val_loss: 2.3051 - val_accuracy: 0.5468\n",
      "Epoch 30/30\n",
      "214/214 [==============================] - 24s 112ms/step - loss: 0.3866 - accuracy: 0.8784 - val_loss: 2.4636 - val_accuracy: 0.5415\n",
      "Epoch 1/30\n",
      "107/107 [==============================] - 39s 223ms/step - loss: 8.3453 - accuracy: 0.0740 - val_loss: 7.7017 - val_accuracy: 0.0986\n",
      "Epoch 2/30\n",
      "107/107 [==============================] - 21s 196ms/step - loss: 4.7049 - accuracy: 0.1463 - val_loss: 3.2921 - val_accuracy: 0.1884\n",
      "Epoch 3/30\n",
      "107/107 [==============================] - 19s 179ms/step - loss: 2.7342 - accuracy: 0.2481 - val_loss: 2.6754 - val_accuracy: 0.2487\n",
      "Epoch 4/30\n",
      "107/107 [==============================] - 21s 193ms/step - loss: 2.3025 - accuracy: 0.3147 - val_loss: 2.4794 - val_accuracy: 0.3016\n",
      "Epoch 5/30\n",
      "107/107 [==============================] - 21s 197ms/step - loss: 2.0252 - accuracy: 0.3810 - val_loss: 2.4558 - val_accuracy: 0.3248\n",
      "Epoch 6/30\n",
      "107/107 [==============================] - 21s 195ms/step - loss: 1.8434 - accuracy: 0.4379 - val_loss: 2.2914 - val_accuracy: 0.3505\n",
      "Epoch 7/30\n",
      "107/107 [==============================] - 21s 196ms/step - loss: 1.6861 - accuracy: 0.4803 - val_loss: 2.2999 - val_accuracy: 0.3860\n",
      "Epoch 8/30\n",
      "107/107 [==============================] - 21s 196ms/step - loss: 1.5082 - accuracy: 0.5260 - val_loss: 2.2567 - val_accuracy: 0.3950\n",
      "Epoch 9/30\n",
      "107/107 [==============================] - 21s 195ms/step - loss: 1.3970 - accuracy: 0.5675 - val_loss: 2.2509 - val_accuracy: 0.4331\n",
      "Epoch 10/30\n",
      "107/107 [==============================] - 21s 195ms/step - loss: 1.2794 - accuracy: 0.6007 - val_loss: 2.2319 - val_accuracy: 0.4379\n",
      "Epoch 11/30\n",
      "107/107 [==============================] - 21s 197ms/step - loss: 1.1586 - accuracy: 0.6411 - val_loss: 2.1868 - val_accuracy: 0.4507\n",
      "Epoch 12/30\n",
      "107/107 [==============================] - 21s 195ms/step - loss: 1.1014 - accuracy: 0.6575 - val_loss: 2.3151 - val_accuracy: 0.4426\n",
      "Epoch 13/30\n",
      "107/107 [==============================] - 21s 195ms/step - loss: 1.0224 - accuracy: 0.6790 - val_loss: 2.1566 - val_accuracy: 0.4732\n",
      "Epoch 14/30\n",
      "107/107 [==============================] - 21s 196ms/step - loss: 0.9432 - accuracy: 0.7119 - val_loss: 2.2165 - val_accuracy: 0.4850\n",
      "Epoch 15/30\n",
      "107/107 [==============================] - 21s 196ms/step - loss: 0.8618 - accuracy: 0.7314 - val_loss: 2.2321 - val_accuracy: 0.4806\n",
      "Epoch 16/30\n",
      "107/107 [==============================] - 21s 197ms/step - loss: 0.7902 - accuracy: 0.7517 - val_loss: 2.1818 - val_accuracy: 0.4910\n",
      "Epoch 17/30\n",
      "107/107 [==============================] - 21s 197ms/step - loss: 0.7168 - accuracy: 0.7710 - val_loss: 2.3100 - val_accuracy: 0.4959\n",
      "Epoch 18/30\n",
      "107/107 [==============================] - 19s 181ms/step - loss: 0.7075 - accuracy: 0.7759 - val_loss: 2.3535 - val_accuracy: 0.4943\n",
      "Epoch 19/30\n",
      "107/107 [==============================] - 17s 157ms/step - loss: 0.6400 - accuracy: 0.7974 - val_loss: 2.3981 - val_accuracy: 0.5099\n",
      "Epoch 20/30\n",
      "107/107 [==============================] - 17s 157ms/step - loss: 0.6184 - accuracy: 0.8061 - val_loss: 2.4101 - val_accuracy: 0.4991\n",
      "Epoch 21/30\n",
      "107/107 [==============================] - 18s 165ms/step - loss: 0.5853 - accuracy: 0.8203 - val_loss: 2.3784 - val_accuracy: 0.5040\n",
      "Epoch 22/30\n",
      "107/107 [==============================] - 19s 176ms/step - loss: 0.5469 - accuracy: 0.8279 - val_loss: 2.3915 - val_accuracy: 0.5087\n",
      "Epoch 23/30\n",
      "107/107 [==============================] - 19s 181ms/step - loss: 0.4961 - accuracy: 0.8440 - val_loss: 2.4948 - val_accuracy: 0.5079\n",
      "Epoch 24/30\n",
      "107/107 [==============================] - 20s 183ms/step - loss: 0.4969 - accuracy: 0.8449 - val_loss: 2.4717 - val_accuracy: 0.5075\n",
      "Epoch 25/30\n",
      "107/107 [==============================] - 19s 180ms/step - loss: 0.4700 - accuracy: 0.8484 - val_loss: 2.4975 - val_accuracy: 0.5091\n",
      "Epoch 26/30\n",
      "107/107 [==============================] - 18s 172ms/step - loss: 0.4308 - accuracy: 0.8641 - val_loss: 2.5310 - val_accuracy: 0.5213\n",
      "Epoch 27/30\n",
      "107/107 [==============================] - 20s 186ms/step - loss: 0.4202 - accuracy: 0.8721 - val_loss: 2.4894 - val_accuracy: 0.5269\n",
      "Epoch 28/30\n",
      "107/107 [==============================] - 20s 188ms/step - loss: 0.3865 - accuracy: 0.8775 - val_loss: 2.5426 - val_accuracy: 0.5199\n",
      "Epoch 29/30\n",
      "107/107 [==============================] - 20s 192ms/step - loss: 0.3695 - accuracy: 0.8824 - val_loss: 2.6710 - val_accuracy: 0.5222\n",
      "Epoch 30/30\n",
      "107/107 [==============================] - 20s 191ms/step - loss: 0.3905 - accuracy: 0.8745 - val_loss: 2.5133 - val_accuracy: 0.5252\n",
      "Epoch 1/30\n",
      "54/54 [==============================] - 57s 545ms/step - loss: 8.6000 - accuracy: 0.0653 - val_loss: 8.5139 - val_accuracy: 0.0800\n",
      "Epoch 2/30\n",
      "54/54 [==============================] - 25s 462ms/step - loss: 6.9185 - accuracy: 0.1042 - val_loss: 6.8641 - val_accuracy: 0.0803\n",
      "Epoch 3/30\n",
      "54/54 [==============================] - 26s 476ms/step - loss: 4.2049 - accuracy: 0.1479 - val_loss: 4.2247 - val_accuracy: 0.1439\n",
      "Epoch 4/30\n",
      "54/54 [==============================] - 25s 458ms/step - loss: 2.9353 - accuracy: 0.2257 - val_loss: 3.1953 - val_accuracy: 0.1968\n",
      "Epoch 5/30\n",
      "54/54 [==============================] - 23s 429ms/step - loss: 2.4678 - accuracy: 0.2793 - val_loss: 2.8471 - val_accuracy: 0.2277\n",
      "Epoch 6/30\n",
      "54/54 [==============================] - 26s 489ms/step - loss: 2.2068 - accuracy: 0.3377 - val_loss: 2.6838 - val_accuracy: 0.2743\n",
      "Epoch 7/30\n",
      "54/54 [==============================] - 25s 470ms/step - loss: 2.0042 - accuracy: 0.3810 - val_loss: 2.6446 - val_accuracy: 0.2966\n",
      "Epoch 8/30\n",
      "54/54 [==============================] - 25s 466ms/step - loss: 1.8553 - accuracy: 0.4183 - val_loss: 2.6893 - val_accuracy: 0.3107\n",
      "Epoch 9/30\n",
      "54/54 [==============================] - 25s 471ms/step - loss: 1.6917 - accuracy: 0.4718 - val_loss: 2.5973 - val_accuracy: 0.3463\n",
      "Epoch 10/30\n",
      "54/54 [==============================] - 25s 465ms/step - loss: 1.5808 - accuracy: 0.5008 - val_loss: 2.5229 - val_accuracy: 0.3695\n",
      "Epoch 11/30\n",
      "54/54 [==============================] - 25s 468ms/step - loss: 1.4383 - accuracy: 0.5393 - val_loss: 2.5869 - val_accuracy: 0.3828\n",
      "Epoch 12/30\n",
      "54/54 [==============================] - 25s 468ms/step - loss: 1.3311 - accuracy: 0.5791 - val_loss: 2.6017 - val_accuracy: 0.4029\n",
      "Epoch 13/30\n",
      "54/54 [==============================] - 25s 463ms/step - loss: 1.2569 - accuracy: 0.6013 - val_loss: 2.6120 - val_accuracy: 0.3995\n",
      "Epoch 14/30\n",
      "54/54 [==============================] - 25s 465ms/step - loss: 1.1607 - accuracy: 0.6320 - val_loss: 2.4814 - val_accuracy: 0.4303\n",
      "Epoch 15/30\n",
      "54/54 [==============================] - 25s 465ms/step - loss: 1.0460 - accuracy: 0.6723 - val_loss: 2.5817 - val_accuracy: 0.4313\n",
      "Epoch 16/30\n",
      "54/54 [==============================] - 26s 493ms/step - loss: 0.9650 - accuracy: 0.6911 - val_loss: 2.6625 - val_accuracy: 0.4404\n",
      "Epoch 17/30\n",
      "54/54 [==============================] - 23s 430ms/step - loss: 0.9062 - accuracy: 0.7140 - val_loss: 2.5529 - val_accuracy: 0.4478\n",
      "Epoch 18/30\n",
      "54/54 [==============================] - 23s 433ms/step - loss: 0.8499 - accuracy: 0.7258 - val_loss: 2.6545 - val_accuracy: 0.4463\n",
      "Epoch 19/30\n",
      "54/54 [==============================] - 26s 489ms/step - loss: 0.7782 - accuracy: 0.7560 - val_loss: 2.7783 - val_accuracy: 0.4453\n",
      "Epoch 20/30\n",
      "54/54 [==============================] - 27s 501ms/step - loss: 0.7489 - accuracy: 0.7620 - val_loss: 2.6383 - val_accuracy: 0.4659\n",
      "Epoch 21/30\n",
      "54/54 [==============================] - 25s 457ms/step - loss: 0.6995 - accuracy: 0.7827 - val_loss: 2.6686 - val_accuracy: 0.4597\n",
      "Epoch 22/30\n",
      "54/54 [==============================] - 26s 490ms/step - loss: 0.6614 - accuracy: 0.7874 - val_loss: 2.6569 - val_accuracy: 0.4706\n",
      "Epoch 23/30\n",
      "54/54 [==============================] - 27s 494ms/step - loss: 0.6012 - accuracy: 0.8097 - val_loss: 2.7619 - val_accuracy: 0.4729\n",
      "Epoch 24/30\n",
      "54/54 [==============================] - 26s 490ms/step - loss: 0.5723 - accuracy: 0.8165 - val_loss: 2.8144 - val_accuracy: 0.4698\n",
      "Epoch 25/30\n",
      "54/54 [==============================] - 26s 488ms/step - loss: 0.5361 - accuracy: 0.8348 - val_loss: 2.7737 - val_accuracy: 0.4772\n",
      "Epoch 26/30\n",
      "54/54 [==============================] - 26s 489ms/step - loss: 0.5038 - accuracy: 0.8416 - val_loss: 2.8504 - val_accuracy: 0.4645\n",
      "Epoch 27/30\n",
      "54/54 [==============================] - 26s 481ms/step - loss: 0.5003 - accuracy: 0.8398 - val_loss: 2.8314 - val_accuracy: 0.4744\n",
      "Epoch 28/30\n",
      "54/54 [==============================] - 21s 398ms/step - loss: 0.4504 - accuracy: 0.8590 - val_loss: 2.8946 - val_accuracy: 0.4701\n",
      "Epoch 29/30\n",
      "54/54 [==============================] - 26s 487ms/step - loss: 0.4290 - accuracy: 0.8639 - val_loss: 2.8793 - val_accuracy: 0.4800\n",
      "Epoch 30/30\n",
      "54/54 [==============================] - 25s 474ms/step - loss: 0.4099 - accuracy: 0.8723 - val_loss: 2.9370 - val_accuracy: 0.4875\n",
      "Epoch 1/40\n",
      "214/214 [==============================] - 52s 152ms/step - loss: 7.0045 - accuracy: 0.0721 - val_loss: 4.4580 - val_accuracy: 0.0897\n",
      "Epoch 2/40\n",
      "214/214 [==============================] - 29s 134ms/step - loss: 3.2134 - accuracy: 0.1399 - val_loss: 2.9023 - val_accuracy: 0.1447\n",
      "Epoch 3/40\n",
      "214/214 [==============================] - 28s 133ms/step - loss: 2.6479 - accuracy: 0.2224 - val_loss: 2.5579 - val_accuracy: 0.2538\n",
      "Epoch 4/40\n",
      "214/214 [==============================] - 28s 133ms/step - loss: 2.3200 - accuracy: 0.3093 - val_loss: 2.4693 - val_accuracy: 0.3010\n",
      "Epoch 5/40\n",
      "214/214 [==============================] - 29s 134ms/step - loss: 2.0898 - accuracy: 0.3778 - val_loss: 2.2810 - val_accuracy: 0.3514\n",
      "Epoch 6/40\n",
      "214/214 [==============================] - 27s 125ms/step - loss: 1.9031 - accuracy: 0.4281 - val_loss: 2.1675 - val_accuracy: 0.3866\n",
      "Epoch 7/40\n",
      "214/214 [==============================] - 28s 129ms/step - loss: 1.7047 - accuracy: 0.4911 - val_loss: 2.1804 - val_accuracy: 0.4073\n",
      "Epoch 8/40\n",
      "214/214 [==============================] - 27s 128ms/step - loss: 1.5170 - accuracy: 0.5421 - val_loss: 2.0845 - val_accuracy: 0.4401\n",
      "Epoch 9/40\n",
      "214/214 [==============================] - 28s 129ms/step - loss: 1.3884 - accuracy: 0.5873 - val_loss: 2.0870 - val_accuracy: 0.4448\n",
      "Epoch 10/40\n",
      "214/214 [==============================] - 26s 123ms/step - loss: 1.2593 - accuracy: 0.6260 - val_loss: 2.0269 - val_accuracy: 0.4679\n",
      "Epoch 11/40\n",
      "214/214 [==============================] - 26s 122ms/step - loss: 1.1328 - accuracy: 0.6547 - val_loss: 2.0572 - val_accuracy: 0.4762\n",
      "Epoch 12/40\n",
      "214/214 [==============================] - 26s 123ms/step - loss: 1.0469 - accuracy: 0.6780 - val_loss: 1.9063 - val_accuracy: 0.5110\n",
      "Epoch 13/40\n",
      "214/214 [==============================] - 26s 124ms/step - loss: 0.9516 - accuracy: 0.7121 - val_loss: 2.0205 - val_accuracy: 0.5137\n",
      "Epoch 14/40\n",
      "214/214 [==============================] - 26s 124ms/step - loss: 0.8729 - accuracy: 0.7317 - val_loss: 1.9865 - val_accuracy: 0.5204\n",
      "Epoch 15/40\n",
      "214/214 [==============================] - 27s 124ms/step - loss: 0.8204 - accuracy: 0.7517 - val_loss: 2.0457 - val_accuracy: 0.5213\n",
      "Epoch 16/40\n",
      "214/214 [==============================] - 26s 123ms/step - loss: 0.7669 - accuracy: 0.7677 - val_loss: 2.0592 - val_accuracy: 0.5324\n",
      "Epoch 17/40\n",
      "214/214 [==============================] - 26s 123ms/step - loss: 0.6986 - accuracy: 0.7833 - val_loss: 2.0364 - val_accuracy: 0.5325\n",
      "Epoch 18/40\n",
      "214/214 [==============================] - 25s 118ms/step - loss: 0.6583 - accuracy: 0.7960 - val_loss: 2.1536 - val_accuracy: 0.5281\n",
      "Epoch 19/40\n",
      "214/214 [==============================] - 25s 115ms/step - loss: 0.6419 - accuracy: 0.8013 - val_loss: 2.0430 - val_accuracy: 0.5471\n",
      "Epoch 20/40\n",
      "214/214 [==============================] - 26s 121ms/step - loss: 0.6027 - accuracy: 0.8143 - val_loss: 2.1327 - val_accuracy: 0.5422\n",
      "Epoch 21/40\n",
      "214/214 [==============================] - 25s 119ms/step - loss: 0.5614 - accuracy: 0.8294 - val_loss: 2.0837 - val_accuracy: 0.5472\n",
      "Epoch 22/40\n",
      "214/214 [==============================] - 27s 125ms/step - loss: 0.5021 - accuracy: 0.8432 - val_loss: 2.1961 - val_accuracy: 0.5393\n",
      "Epoch 23/40\n",
      "214/214 [==============================] - 27s 124ms/step - loss: 0.4929 - accuracy: 0.8470 - val_loss: 2.1795 - val_accuracy: 0.5508\n",
      "Epoch 24/40\n",
      "214/214 [==============================] - 26s 124ms/step - loss: 0.4901 - accuracy: 0.8499 - val_loss: 2.2802 - val_accuracy: 0.5290\n",
      "Epoch 25/40\n",
      "214/214 [==============================] - 27s 125ms/step - loss: 0.4529 - accuracy: 0.8587 - val_loss: 2.2117 - val_accuracy: 0.5560\n",
      "Epoch 26/40\n",
      "214/214 [==============================] - 27s 125ms/step - loss: 0.4331 - accuracy: 0.8623 - val_loss: 2.2687 - val_accuracy: 0.5410\n",
      "Epoch 27/40\n",
      "214/214 [==============================] - 27s 125ms/step - loss: 0.4084 - accuracy: 0.8729 - val_loss: 2.3097 - val_accuracy: 0.5538\n",
      "Epoch 28/40\n",
      "214/214 [==============================] - 26s 124ms/step - loss: 0.3838 - accuracy: 0.8784 - val_loss: 2.3765 - val_accuracy: 0.5549\n",
      "Epoch 29/40\n",
      "214/214 [==============================] - 26s 124ms/step - loss: 0.3904 - accuracy: 0.8799 - val_loss: 2.3722 - val_accuracy: 0.5478\n",
      "Epoch 30/40\n",
      "214/214 [==============================] - 26s 124ms/step - loss: 0.3641 - accuracy: 0.8890 - val_loss: 2.3883 - val_accuracy: 0.5584\n",
      "Epoch 31/40\n",
      "214/214 [==============================] - 26s 123ms/step - loss: 0.3492 - accuracy: 0.8900 - val_loss: 2.3630 - val_accuracy: 0.5588\n",
      "Epoch 32/40\n",
      "214/214 [==============================] - 26s 124ms/step - loss: 0.3376 - accuracy: 0.8966 - val_loss: 2.5140 - val_accuracy: 0.5469\n",
      "Epoch 33/40\n",
      "214/214 [==============================] - 27s 125ms/step - loss: 0.3344 - accuracy: 0.8941 - val_loss: 2.4068 - val_accuracy: 0.5606\n",
      "Epoch 34/40\n",
      "214/214 [==============================] - 27s 125ms/step - loss: 0.3063 - accuracy: 0.9081 - val_loss: 2.4792 - val_accuracy: 0.5512\n",
      "Epoch 35/40\n",
      "214/214 [==============================] - 27s 125ms/step - loss: 0.3366 - accuracy: 0.8971 - val_loss: 2.4066 - val_accuracy: 0.5616\n",
      "Epoch 36/40\n",
      "214/214 [==============================] - 26s 124ms/step - loss: 0.3187 - accuracy: 0.8969 - val_loss: 2.4859 - val_accuracy: 0.5491\n",
      "Epoch 37/40\n",
      "214/214 [==============================] - 28s 129ms/step - loss: 0.3111 - accuracy: 0.9061 - val_loss: 2.4642 - val_accuracy: 0.5543\n",
      "Epoch 38/40\n",
      "214/214 [==============================] - 27s 129ms/step - loss: 0.2938 - accuracy: 0.9113 - val_loss: 2.4591 - val_accuracy: 0.5618\n",
      "Epoch 39/40\n",
      "214/214 [==============================] - 27s 128ms/step - loss: 0.2939 - accuracy: 0.9103 - val_loss: 2.4820 - val_accuracy: 0.5500\n",
      "Epoch 40/40\n",
      "214/214 [==============================] - 26s 122ms/step - loss: 0.2717 - accuracy: 0.9143 - val_loss: 2.4574 - val_accuracy: 0.5637\n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 39s 221ms/step - loss: 8.1101 - accuracy: 0.0730 - val_loss: 7.3631 - val_accuracy: 0.0696\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 20s 190ms/step - loss: 4.3463 - accuracy: 0.1058 - val_loss: 3.3794 - val_accuracy: 0.1078\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 20s 190ms/step - loss: 2.9421 - accuracy: 0.1718 - val_loss: 2.8435 - val_accuracy: 0.1826\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 21s 193ms/step - loss: 2.5287 - accuracy: 0.2417 - val_loss: 2.6736 - val_accuracy: 0.2490\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 20s 190ms/step - loss: 2.2691 - accuracy: 0.3086 - val_loss: 2.5411 - val_accuracy: 0.2886\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 20s 190ms/step - loss: 2.0325 - accuracy: 0.3827 - val_loss: 2.6083 - val_accuracy: 0.3164\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 21s 192ms/step - loss: 1.8455 - accuracy: 0.4325 - val_loss: 2.3357 - val_accuracy: 0.3697\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 21s 193ms/step - loss: 1.6583 - accuracy: 0.4936 - val_loss: 2.3443 - val_accuracy: 0.3988\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 20s 189ms/step - loss: 1.5019 - accuracy: 0.5387 - val_loss: 2.2455 - val_accuracy: 0.4163\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 20s 192ms/step - loss: 1.3425 - accuracy: 0.5906 - val_loss: 2.2073 - val_accuracy: 0.4525\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 20s 189ms/step - loss: 1.2004 - accuracy: 0.6348 - val_loss: 2.1328 - val_accuracy: 0.4707\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 20s 183ms/step - loss: 1.1044 - accuracy: 0.6585 - val_loss: 2.2541 - val_accuracy: 0.4703\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 21s 197ms/step - loss: 1.0044 - accuracy: 0.6916 - val_loss: 2.2206 - val_accuracy: 0.4823\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 21s 195ms/step - loss: 0.9197 - accuracy: 0.7122 - val_loss: 2.2111 - val_accuracy: 0.4934\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 21s 194ms/step - loss: 0.8547 - accuracy: 0.7324 - val_loss: 2.2208 - val_accuracy: 0.5091\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 19s 177ms/step - loss: 0.7866 - accuracy: 0.7536 - val_loss: 2.1739 - val_accuracy: 0.5076\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 20s 189ms/step - loss: 0.7192 - accuracy: 0.7823 - val_loss: 2.2276 - val_accuracy: 0.5131\n",
      "Epoch 18/40\n",
      "107/107 [==============================] - 21s 196ms/step - loss: 0.6609 - accuracy: 0.7988 - val_loss: 2.2888 - val_accuracy: 0.5152\n",
      "Epoch 19/40\n",
      "107/107 [==============================] - 22s 204ms/step - loss: 0.5806 - accuracy: 0.8238 - val_loss: 2.2652 - val_accuracy: 0.5207\n",
      "Epoch 20/40\n",
      "107/107 [==============================] - 22s 205ms/step - loss: 0.5737 - accuracy: 0.8195 - val_loss: 2.2932 - val_accuracy: 0.5231\n",
      "Epoch 21/40\n",
      "107/107 [==============================] - 22s 203ms/step - loss: 0.5137 - accuracy: 0.8399 - val_loss: 2.4048 - val_accuracy: 0.5284\n",
      "Epoch 22/40\n",
      "107/107 [==============================] - 22s 202ms/step - loss: 0.5012 - accuracy: 0.8375 - val_loss: 2.4872 - val_accuracy: 0.5162\n",
      "Epoch 23/40\n",
      "107/107 [==============================] - 22s 202ms/step - loss: 0.4879 - accuracy: 0.8475 - val_loss: 2.5416 - val_accuracy: 0.5122\n",
      "Epoch 24/40\n",
      "107/107 [==============================] - 22s 203ms/step - loss: 0.4535 - accuracy: 0.8594 - val_loss: 2.4780 - val_accuracy: 0.5349\n",
      "Epoch 25/40\n",
      "107/107 [==============================] - 22s 206ms/step - loss: 0.4062 - accuracy: 0.8736 - val_loss: 2.5003 - val_accuracy: 0.5412\n",
      "Epoch 26/40\n",
      "107/107 [==============================] - 22s 203ms/step - loss: 0.3922 - accuracy: 0.8743 - val_loss: 2.3961 - val_accuracy: 0.5496\n",
      "Epoch 27/40\n",
      "107/107 [==============================] - 22s 202ms/step - loss: 0.3668 - accuracy: 0.8862 - val_loss: 2.5685 - val_accuracy: 0.5384\n",
      "Epoch 28/40\n",
      "107/107 [==============================] - 21s 198ms/step - loss: 0.3709 - accuracy: 0.8841 - val_loss: 2.4955 - val_accuracy: 0.5437\n",
      "Epoch 29/40\n",
      "107/107 [==============================] - 18s 172ms/step - loss: 0.3605 - accuracy: 0.8834 - val_loss: 2.5001 - val_accuracy: 0.5466\n",
      "Epoch 30/40\n",
      "107/107 [==============================] - 22s 203ms/step - loss: 0.3303 - accuracy: 0.8979 - val_loss: 2.5527 - val_accuracy: 0.5432\n",
      "Epoch 31/40\n",
      "107/107 [==============================] - 22s 209ms/step - loss: 0.3194 - accuracy: 0.8990 - val_loss: 2.6526 - val_accuracy: 0.5453\n",
      "Epoch 32/40\n",
      "107/107 [==============================] - 23s 220ms/step - loss: 0.3209 - accuracy: 0.8993 - val_loss: 2.5957 - val_accuracy: 0.5462\n",
      "Epoch 33/40\n",
      "107/107 [==============================] - 22s 204ms/step - loss: 0.2688 - accuracy: 0.9138 - val_loss: 2.6393 - val_accuracy: 0.5563\n",
      "Epoch 34/40\n",
      "107/107 [==============================] - 22s 207ms/step - loss: 0.2836 - accuracy: 0.9108 - val_loss: 2.6078 - val_accuracy: 0.5574\n",
      "Epoch 35/40\n",
      "107/107 [==============================] - 22s 207ms/step - loss: 0.2945 - accuracy: 0.9069 - val_loss: 2.6321 - val_accuracy: 0.5572\n",
      "Epoch 36/40\n",
      "107/107 [==============================] - 22s 209ms/step - loss: 0.2716 - accuracy: 0.9147 - val_loss: 2.5583 - val_accuracy: 0.5585\n",
      "Epoch 37/40\n",
      "107/107 [==============================] - 22s 208ms/step - loss: 0.2710 - accuracy: 0.9170 - val_loss: 2.6659 - val_accuracy: 0.5556\n",
      "Epoch 38/40\n",
      "107/107 [==============================] - 22s 208ms/step - loss: 0.2691 - accuracy: 0.9169 - val_loss: 2.6323 - val_accuracy: 0.5609\n",
      "Epoch 39/40\n",
      "107/107 [==============================] - 22s 208ms/step - loss: 0.2584 - accuracy: 0.9207 - val_loss: 2.6464 - val_accuracy: 0.5588\n",
      "Epoch 40/40\n",
      "107/107 [==============================] - 22s 207ms/step - loss: 0.2541 - accuracy: 0.9217 - val_loss: 2.6807 - val_accuracy: 0.5571\n",
      "Epoch 1/40\n",
      "54/54 [==============================] - 54s 633ms/step - loss: 8.6099 - accuracy: 0.0672 - val_loss: 8.5755 - val_accuracy: 0.0799\n",
      "Epoch 2/40\n",
      "54/54 [==============================] - 30s 564ms/step - loss: 6.9844 - accuracy: 0.1378 - val_loss: 6.8394 - val_accuracy: 0.1000\n",
      "Epoch 3/40\n",
      "54/54 [==============================] - 31s 586ms/step - loss: 4.1859 - accuracy: 0.1849 - val_loss: 4.4733 - val_accuracy: 0.1852\n",
      "Epoch 4/40\n",
      "54/54 [==============================] - 32s 587ms/step - loss: 2.8578 - accuracy: 0.2634 - val_loss: 3.0402 - val_accuracy: 0.2446\n",
      "Epoch 5/40\n",
      "54/54 [==============================] - 31s 579ms/step - loss: 2.3511 - accuracy: 0.3298 - val_loss: 2.7035 - val_accuracy: 0.2758\n",
      "Epoch 6/40\n",
      "54/54 [==============================] - 31s 586ms/step - loss: 2.0767 - accuracy: 0.3792 - val_loss: 2.5960 - val_accuracy: 0.3054\n",
      "Epoch 7/40\n",
      "54/54 [==============================] - 29s 543ms/step - loss: 1.8747 - accuracy: 0.4338 - val_loss: 2.5048 - val_accuracy: 0.3255\n",
      "Epoch 8/40\n",
      "54/54 [==============================] - 29s 540ms/step - loss: 1.6719 - accuracy: 0.4925 - val_loss: 2.4216 - val_accuracy: 0.3498\n",
      "Epoch 9/40\n",
      "54/54 [==============================] - 31s 575ms/step - loss: 1.5362 - accuracy: 0.5261 - val_loss: 2.4009 - val_accuracy: 0.3747\n",
      "Epoch 10/40\n",
      "54/54 [==============================] - 30s 556ms/step - loss: 1.3958 - accuracy: 0.5681 - val_loss: 2.4716 - val_accuracy: 0.3839\n",
      "Epoch 11/40\n",
      "54/54 [==============================] - 29s 542ms/step - loss: 1.2759 - accuracy: 0.6006 - val_loss: 2.4889 - val_accuracy: 0.3941\n",
      "Epoch 12/40\n",
      "54/54 [==============================] - 29s 544ms/step - loss: 1.1798 - accuracy: 0.6225 - val_loss: 2.4244 - val_accuracy: 0.4163\n",
      "Epoch 13/40\n",
      "54/54 [==============================] - 29s 538ms/step - loss: 1.1003 - accuracy: 0.6578 - val_loss: 2.4985 - val_accuracy: 0.4187\n",
      "Epoch 14/40\n",
      "54/54 [==============================] - 29s 547ms/step - loss: 0.9831 - accuracy: 0.6909 - val_loss: 2.5226 - val_accuracy: 0.4241\n",
      "Epoch 15/40\n",
      "54/54 [==============================] - 29s 539ms/step - loss: 0.9311 - accuracy: 0.7102 - val_loss: 2.6199 - val_accuracy: 0.4298\n",
      "Epoch 16/40\n",
      "54/54 [==============================] - 29s 542ms/step - loss: 0.8553 - accuracy: 0.7270 - val_loss: 2.5805 - val_accuracy: 0.4467\n",
      "Epoch 17/40\n",
      "54/54 [==============================] - 29s 531ms/step - loss: 0.7817 - accuracy: 0.7526 - val_loss: 2.6472 - val_accuracy: 0.4470\n",
      "Epoch 18/40\n",
      "54/54 [==============================] - 27s 511ms/step - loss: 0.7459 - accuracy: 0.7640 - val_loss: 2.7239 - val_accuracy: 0.4432\n",
      "Epoch 19/40\n",
      "54/54 [==============================] - 28s 529ms/step - loss: 0.6934 - accuracy: 0.7810 - val_loss: 2.7375 - val_accuracy: 0.4467\n",
      "Epoch 20/40\n",
      "54/54 [==============================] - 28s 526ms/step - loss: 0.6584 - accuracy: 0.7860 - val_loss: 2.7017 - val_accuracy: 0.4540\n",
      "Epoch 21/40\n",
      "54/54 [==============================] - 28s 521ms/step - loss: 0.5802 - accuracy: 0.8165 - val_loss: 2.7249 - val_accuracy: 0.4609\n",
      "Epoch 22/40\n",
      "54/54 [==============================] - 28s 523ms/step - loss: 0.5644 - accuracy: 0.8260 - val_loss: 2.7149 - val_accuracy: 0.4656\n",
      "Epoch 23/40\n",
      "54/54 [==============================] - 28s 528ms/step - loss: 0.5345 - accuracy: 0.8294 - val_loss: 2.7771 - val_accuracy: 0.4676\n",
      "Epoch 24/40\n",
      "54/54 [==============================] - 28s 518ms/step - loss: 0.4867 - accuracy: 0.8484 - val_loss: 2.8553 - val_accuracy: 0.4634\n",
      "Epoch 25/40\n",
      "54/54 [==============================] - 28s 524ms/step - loss: 0.4853 - accuracy: 0.8465 - val_loss: 2.8528 - val_accuracy: 0.4613\n",
      "Epoch 26/40\n",
      "54/54 [==============================] - 29s 532ms/step - loss: 0.4487 - accuracy: 0.8604 - val_loss: 2.9354 - val_accuracy: 0.4644\n",
      "Epoch 27/40\n",
      "54/54 [==============================] - 28s 528ms/step - loss: 0.4381 - accuracy: 0.8607 - val_loss: 2.8385 - val_accuracy: 0.4853\n",
      "Epoch 28/40\n",
      "54/54 [==============================] - 29s 537ms/step - loss: 0.3963 - accuracy: 0.8758 - val_loss: 2.9180 - val_accuracy: 0.4719\n",
      "Epoch 29/40\n",
      "54/54 [==============================] - 29s 530ms/step - loss: 0.3589 - accuracy: 0.8854 - val_loss: 2.9197 - val_accuracy: 0.4743\n",
      "Epoch 30/40\n",
      "54/54 [==============================] - 28s 520ms/step - loss: 0.3198 - accuracy: 0.8969 - val_loss: 2.9714 - val_accuracy: 0.4907\n",
      "Epoch 31/40\n",
      "54/54 [==============================] - 24s 450ms/step - loss: 0.3018 - accuracy: 0.9026 - val_loss: 3.0530 - val_accuracy: 0.4719\n",
      "Epoch 32/40\n",
      "54/54 [==============================] - 27s 498ms/step - loss: 0.3181 - accuracy: 0.9008 - val_loss: 2.9962 - val_accuracy: 0.4860\n",
      "Epoch 33/40\n",
      "54/54 [==============================] - 26s 490ms/step - loss: 0.2791 - accuracy: 0.9058 - val_loss: 3.1521 - val_accuracy: 0.4788\n",
      "Epoch 34/40\n",
      "54/54 [==============================] - 26s 493ms/step - loss: 0.3098 - accuracy: 0.9036 - val_loss: 3.0910 - val_accuracy: 0.4765\n",
      "Epoch 35/40\n",
      "54/54 [==============================] - 27s 496ms/step - loss: 0.2725 - accuracy: 0.9129 - val_loss: 3.1698 - val_accuracy: 0.4779\n",
      "Epoch 36/40\n",
      "54/54 [==============================] - 26s 485ms/step - loss: 0.2602 - accuracy: 0.9157 - val_loss: 3.1503 - val_accuracy: 0.4835\n",
      "Epoch 37/40\n",
      "54/54 [==============================] - 26s 483ms/step - loss: 0.2488 - accuracy: 0.9210 - val_loss: 3.1816 - val_accuracy: 0.4854\n",
      "Epoch 38/40\n",
      "54/54 [==============================] - 27s 506ms/step - loss: 0.2451 - accuracy: 0.9230 - val_loss: 3.2076 - val_accuracy: 0.4773\n",
      "Epoch 39/40\n",
      "54/54 [==============================] - 27s 509ms/step - loss: 0.2430 - accuracy: 0.9229 - val_loss: 3.2791 - val_accuracy: 0.4748\n",
      "Epoch 40/40\n",
      "54/54 [==============================] - 27s 505ms/step - loss: 0.2465 - accuracy: 0.9225 - val_loss: 3.2241 - val_accuracy: 0.4779\n",
      "Epoch 1/10\n",
      "214/214 [==============================] - 44s 148ms/step - loss: 7.8680 - accuracy: 0.0534 - val_loss: 5.6668 - val_accuracy: 0.0834\n",
      "Epoch 2/10\n",
      "214/214 [==============================] - 29s 135ms/step - loss: 3.6989 - accuracy: 0.1083 - val_loss: 3.0112 - val_accuracy: 0.1353\n",
      "Epoch 3/10\n",
      "214/214 [==============================] - 28s 133ms/step - loss: 2.9258 - accuracy: 0.1680 - val_loss: 2.7772 - val_accuracy: 0.1887\n",
      "Epoch 4/10\n",
      "214/214 [==============================] - 27s 127ms/step - loss: 2.7022 - accuracy: 0.2089 - val_loss: 2.6443 - val_accuracy: 0.2348\n",
      "Epoch 5/10\n",
      "214/214 [==============================] - 29s 137ms/step - loss: 2.5217 - accuracy: 0.2562 - val_loss: 2.5110 - val_accuracy: 0.2741\n",
      "Epoch 6/10\n",
      "214/214 [==============================] - 29s 136ms/step - loss: 2.3621 - accuracy: 0.2970 - val_loss: 2.4631 - val_accuracy: 0.2946\n",
      "Epoch 7/10\n",
      "214/214 [==============================] - 29s 136ms/step - loss: 2.2015 - accuracy: 0.3482 - val_loss: 2.2829 - val_accuracy: 0.3304\n",
      "Epoch 8/10\n",
      "214/214 [==============================] - 29s 136ms/step - loss: 2.0899 - accuracy: 0.3723 - val_loss: 2.2851 - val_accuracy: 0.3450\n",
      "Epoch 9/10\n",
      "214/214 [==============================] - 29s 136ms/step - loss: 1.9558 - accuracy: 0.4072 - val_loss: 2.2088 - val_accuracy: 0.3795\n",
      "Epoch 10/10\n",
      "214/214 [==============================] - 29s 137ms/step - loss: 1.8711 - accuracy: 0.4345 - val_loss: 2.1354 - val_accuracy: 0.4003\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 40s 225ms/step - loss: 8.4644 - accuracy: 0.0553 - val_loss: 8.1622 - val_accuracy: 0.0659\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 21s 201ms/step - loss: 5.4241 - accuracy: 0.0892 - val_loss: 3.8925 - val_accuracy: 0.1015\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 22s 202ms/step - loss: 3.3830 - accuracy: 0.1263 - val_loss: 3.0327 - val_accuracy: 0.1370\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 22s 202ms/step - loss: 2.9376 - accuracy: 0.1583 - val_loss: 2.8164 - val_accuracy: 0.1673\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 22s 202ms/step - loss: 2.7270 - accuracy: 0.1895 - val_loss: 2.6892 - val_accuracy: 0.2001\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 21s 201ms/step - loss: 2.5589 - accuracy: 0.2257 - val_loss: 2.6244 - val_accuracy: 0.2362\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 22s 206ms/step - loss: 2.4193 - accuracy: 0.2634 - val_loss: 2.5723 - val_accuracy: 0.2676\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 21s 192ms/step - loss: 2.3156 - accuracy: 0.2942 - val_loss: 2.5042 - val_accuracy: 0.2733\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 22s 205ms/step - loss: 2.1696 - accuracy: 0.3366 - val_loss: 2.5227 - val_accuracy: 0.3030\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 22s 208ms/step - loss: 2.0472 - accuracy: 0.3656 - val_loss: 2.3094 - val_accuracy: 0.3417\n",
      "Epoch 1/10\n",
      "54/54 [==============================] - 42s 523ms/step - loss: 8.7128 - accuracy: 0.0382 - val_loss: 8.6305 - val_accuracy: 0.0850\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 26s 477ms/step - loss: 7.7942 - accuracy: 0.0936 - val_loss: 7.2538 - val_accuracy: 0.0783\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 25s 471ms/step - loss: 5.4341 - accuracy: 0.1194 - val_loss: 5.0783 - val_accuracy: 0.1180\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 25s 471ms/step - loss: 3.6206 - accuracy: 0.1624 - val_loss: 3.5645 - val_accuracy: 0.1553\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 25s 471ms/step - loss: 3.0161 - accuracy: 0.1862 - val_loss: 3.0775 - val_accuracy: 0.1898\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 25s 456ms/step - loss: 2.7377 - accuracy: 0.2240 - val_loss: 2.9823 - val_accuracy: 0.2018\n",
      "Epoch 7/10\n",
      "54/54 [==============================] - 26s 487ms/step - loss: 2.5383 - accuracy: 0.2496 - val_loss: 2.8214 - val_accuracy: 0.2237\n",
      "Epoch 8/10\n",
      "54/54 [==============================] - 26s 480ms/step - loss: 2.4215 - accuracy: 0.2847 - val_loss: 2.7517 - val_accuracy: 0.2493\n",
      "Epoch 9/10\n",
      "54/54 [==============================] - 26s 486ms/step - loss: 2.2798 - accuracy: 0.2988 - val_loss: 2.6616 - val_accuracy: 0.2804\n",
      "Epoch 10/10\n",
      "54/54 [==============================] - 24s 446ms/step - loss: 2.1696 - accuracy: 0.3277 - val_loss: 2.6991 - val_accuracy: 0.2902\n",
      "Epoch 1/20\n",
      "214/214 [==============================] - 46s 150ms/step - loss: 7.5343 - accuracy: 0.0546 - val_loss: 5.4851 - val_accuracy: 0.0668\n",
      "Epoch 2/20\n",
      "214/214 [==============================] - 29s 136ms/step - loss: 3.5819 - accuracy: 0.0935 - val_loss: 3.1286 - val_accuracy: 0.1097\n",
      "Epoch 3/20\n",
      "214/214 [==============================] - 29s 137ms/step - loss: 3.0102 - accuracy: 0.1320 - val_loss: 2.9395 - val_accuracy: 0.1487\n",
      "Epoch 4/20\n",
      "214/214 [==============================] - 29s 137ms/step - loss: 2.8186 - accuracy: 0.1706 - val_loss: 2.7589 - val_accuracy: 0.1884\n",
      "Epoch 5/20\n",
      "214/214 [==============================] - 29s 136ms/step - loss: 2.6312 - accuracy: 0.2219 - val_loss: 2.5660 - val_accuracy: 0.2523\n",
      "Epoch 6/20\n",
      "214/214 [==============================] - 30s 140ms/step - loss: 2.4869 - accuracy: 0.2628 - val_loss: 2.5289 - val_accuracy: 0.2751\n",
      "Epoch 7/20\n",
      "214/214 [==============================] - 30s 142ms/step - loss: 2.3254 - accuracy: 0.3103 - val_loss: 2.4271 - val_accuracy: 0.3016\n",
      "Epoch 8/20\n",
      "214/214 [==============================] - 28s 133ms/step - loss: 2.2165 - accuracy: 0.3448 - val_loss: 2.3039 - val_accuracy: 0.3450\n",
      "Epoch 9/20\n",
      "214/214 [==============================] - 27s 128ms/step - loss: 2.0562 - accuracy: 0.3841 - val_loss: 2.2181 - val_accuracy: 0.3580\n",
      "Epoch 10/20\n",
      "214/214 [==============================] - 29s 136ms/step - loss: 1.9481 - accuracy: 0.4107 - val_loss: 2.1878 - val_accuracy: 0.3923\n",
      "Epoch 11/20\n",
      "214/214 [==============================] - 29s 135ms/step - loss: 1.8160 - accuracy: 0.4518 - val_loss: 2.0985 - val_accuracy: 0.4129\n",
      "Epoch 12/20\n",
      "214/214 [==============================] - 29s 134ms/step - loss: 1.7415 - accuracy: 0.4696 - val_loss: 2.0462 - val_accuracy: 0.4264\n",
      "Epoch 13/20\n",
      "214/214 [==============================] - 29s 134ms/step - loss: 1.6596 - accuracy: 0.5027 - val_loss: 2.0292 - val_accuracy: 0.4540\n",
      "Epoch 14/20\n",
      "214/214 [==============================] - 29s 135ms/step - loss: 1.5837 - accuracy: 0.5156 - val_loss: 2.0587 - val_accuracy: 0.4413\n",
      "Epoch 15/20\n",
      "214/214 [==============================] - 29s 135ms/step - loss: 1.5161 - accuracy: 0.5472 - val_loss: 2.0679 - val_accuracy: 0.4598\n",
      "Epoch 16/20\n",
      "214/214 [==============================] - 29s 135ms/step - loss: 1.4410 - accuracy: 0.5639 - val_loss: 2.0307 - val_accuracy: 0.4643\n",
      "Epoch 17/20\n",
      "214/214 [==============================] - 29s 135ms/step - loss: 1.3887 - accuracy: 0.5754 - val_loss: 2.0595 - val_accuracy: 0.4706\n",
      "Epoch 18/20\n",
      "214/214 [==============================] - 29s 136ms/step - loss: 1.3136 - accuracy: 0.6007 - val_loss: 1.9821 - val_accuracy: 0.4919\n",
      "Epoch 19/20\n",
      "214/214 [==============================] - 29s 135ms/step - loss: 1.2792 - accuracy: 0.6157 - val_loss: 2.0430 - val_accuracy: 0.4850\n",
      "Epoch 20/20\n",
      "214/214 [==============================] - 29s 134ms/step - loss: 1.2322 - accuracy: 0.6313 - val_loss: 2.0370 - val_accuracy: 0.4937\n",
      "Epoch 1/20\n",
      "107/107 [==============================] - 46s 246ms/step - loss: 8.5235 - accuracy: 0.0505 - val_loss: 8.2823 - val_accuracy: 0.0516\n",
      "Epoch 2/20\n",
      "107/107 [==============================] - 23s 219ms/step - loss: 5.6496 - accuracy: 0.0974 - val_loss: 4.1160 - val_accuracy: 0.0943\n",
      "Epoch 3/20\n",
      "107/107 [==============================] - 23s 215ms/step - loss: 3.3787 - accuracy: 0.1343 - val_loss: 3.1237 - val_accuracy: 0.1280\n",
      "Epoch 4/20\n",
      "107/107 [==============================] - 23s 219ms/step - loss: 2.9388 - accuracy: 0.1554 - val_loss: 2.8750 - val_accuracy: 0.1739\n",
      "Epoch 5/20\n",
      "107/107 [==============================] - 23s 218ms/step - loss: 2.7532 - accuracy: 0.1915 - val_loss: 2.7982 - val_accuracy: 0.1946\n",
      "Epoch 6/20\n",
      "107/107 [==============================] - 22s 208ms/step - loss: 2.6000 - accuracy: 0.2255 - val_loss: 2.7254 - val_accuracy: 0.2212\n",
      "Epoch 7/20\n",
      "107/107 [==============================] - 22s 204ms/step - loss: 2.4463 - accuracy: 0.2651 - val_loss: 2.6395 - val_accuracy: 0.2707\n",
      "Epoch 8/20\n",
      "107/107 [==============================] - 23s 216ms/step - loss: 2.3007 - accuracy: 0.3039 - val_loss: 2.4768 - val_accuracy: 0.2888\n",
      "Epoch 9/20\n",
      "107/107 [==============================] - 23s 218ms/step - loss: 2.1505 - accuracy: 0.3378 - val_loss: 2.4081 - val_accuracy: 0.3067\n",
      "Epoch 10/20\n",
      "107/107 [==============================] - 23s 216ms/step - loss: 2.0692 - accuracy: 0.3584 - val_loss: 2.4674 - val_accuracy: 0.3213\n",
      "Epoch 11/20\n",
      "107/107 [==============================] - 23s 219ms/step - loss: 1.9562 - accuracy: 0.3931 - val_loss: 2.3433 - val_accuracy: 0.3482\n",
      "Epoch 12/20\n",
      "107/107 [==============================] - 23s 217ms/step - loss: 1.8526 - accuracy: 0.4301 - val_loss: 2.3236 - val_accuracy: 0.3817\n",
      "Epoch 13/20\n",
      "107/107 [==============================] - 23s 218ms/step - loss: 1.7658 - accuracy: 0.4546 - val_loss: 2.3379 - val_accuracy: 0.3810\n",
      "Epoch 14/20\n",
      "107/107 [==============================] - 21s 201ms/step - loss: 1.6650 - accuracy: 0.4799 - val_loss: 2.2099 - val_accuracy: 0.4134\n",
      "Epoch 15/20\n",
      "107/107 [==============================] - 24s 225ms/step - loss: 1.5723 - accuracy: 0.5151 - val_loss: 2.3328 - val_accuracy: 0.4192\n",
      "Epoch 16/20\n",
      "107/107 [==============================] - 24s 225ms/step - loss: 1.5282 - accuracy: 0.5287 - val_loss: 2.1941 - val_accuracy: 0.4373\n",
      "Epoch 17/20\n",
      "107/107 [==============================] - 24s 225ms/step - loss: 1.4584 - accuracy: 0.5460 - val_loss: 2.2009 - val_accuracy: 0.4470\n",
      "Epoch 18/20\n",
      "107/107 [==============================] - 24s 223ms/step - loss: 1.3711 - accuracy: 0.5725 - val_loss: 2.2802 - val_accuracy: 0.4588\n",
      "Epoch 19/20\n",
      "107/107 [==============================] - 22s 206ms/step - loss: 1.3067 - accuracy: 0.6026 - val_loss: 2.2809 - val_accuracy: 0.4540\n",
      "Epoch 20/20\n",
      "107/107 [==============================] - 23s 217ms/step - loss: 1.2610 - accuracy: 0.6075 - val_loss: 2.1367 - val_accuracy: 0.4804\n",
      "Epoch 1/20\n",
      "54/54 [==============================] - 49s 586ms/step - loss: 8.7258 - accuracy: 0.0375 - val_loss: 8.7009 - val_accuracy: 0.0374\n",
      "Epoch 2/20\n",
      "54/54 [==============================] - 28s 520ms/step - loss: 7.7706 - accuracy: 0.0800 - val_loss: 7.7425 - val_accuracy: 0.0721\n",
      "Epoch 3/20\n",
      "54/54 [==============================] - 28s 521ms/step - loss: 5.3490 - accuracy: 0.0794 - val_loss: 5.8999 - val_accuracy: 0.0944\n",
      "Epoch 4/20\n",
      "54/54 [==============================] - 27s 507ms/step - loss: 3.6925 - accuracy: 0.1052 - val_loss: 3.8235 - val_accuracy: 0.1037\n",
      "Epoch 5/20\n",
      "54/54 [==============================] - 25s 474ms/step - loss: 3.2192 - accuracy: 0.1222 - val_loss: 3.3330 - val_accuracy: 0.1252\n",
      "Epoch 6/20\n",
      "54/54 [==============================] - 27s 503ms/step - loss: 2.9687 - accuracy: 0.1405 - val_loss: 3.0047 - val_accuracy: 0.1381\n",
      "Epoch 7/20\n",
      "54/54 [==============================] - 27s 500ms/step - loss: 2.8352 - accuracy: 0.1614 - val_loss: 2.9912 - val_accuracy: 0.1534\n",
      "Epoch 8/20\n",
      "54/54 [==============================] - 27s 494ms/step - loss: 2.7220 - accuracy: 0.1857 - val_loss: 2.8966 - val_accuracy: 0.1712\n",
      "Epoch 9/20\n",
      "54/54 [==============================] - 27s 508ms/step - loss: 2.5965 - accuracy: 0.2186 - val_loss: 2.8087 - val_accuracy: 0.2070\n",
      "Epoch 10/20\n",
      "54/54 [==============================] - 28s 514ms/step - loss: 2.5069 - accuracy: 0.2372 - val_loss: 2.8141 - val_accuracy: 0.2182\n",
      "Epoch 11/20\n",
      "54/54 [==============================] - 28s 522ms/step - loss: 2.3853 - accuracy: 0.2635 - val_loss: 2.8138 - val_accuracy: 0.2508\n",
      "Epoch 12/20\n",
      "54/54 [==============================] - 27s 510ms/step - loss: 2.2827 - accuracy: 0.2989 - val_loss: 2.7219 - val_accuracy: 0.2704\n",
      "Epoch 13/20\n",
      "54/54 [==============================] - 27s 500ms/step - loss: 2.2076 - accuracy: 0.3274 - val_loss: 2.6739 - val_accuracy: 0.2870\n",
      "Epoch 14/20\n",
      "54/54 [==============================] - 27s 498ms/step - loss: 2.0718 - accuracy: 0.3609 - val_loss: 2.5598 - val_accuracy: 0.3266\n",
      "Epoch 15/20\n",
      "54/54 [==============================] - 24s 454ms/step - loss: 1.9719 - accuracy: 0.3980 - val_loss: 2.7449 - val_accuracy: 0.3085\n",
      "Epoch 16/20\n",
      "54/54 [==============================] - 29s 533ms/step - loss: 1.9048 - accuracy: 0.4101 - val_loss: 2.5210 - val_accuracy: 0.3388\n",
      "Epoch 17/20\n",
      "54/54 [==============================] - 29s 533ms/step - loss: 1.8049 - accuracy: 0.4396 - val_loss: 2.5491 - val_accuracy: 0.3594\n",
      "Epoch 18/20\n",
      "54/54 [==============================] - 29s 539ms/step - loss: 1.7321 - accuracy: 0.4647 - val_loss: 2.6003 - val_accuracy: 0.3648\n",
      "Epoch 19/20\n",
      "54/54 [==============================] - 27s 511ms/step - loss: 1.6363 - accuracy: 0.4903 - val_loss: 2.5223 - val_accuracy: 0.3806\n",
      "Epoch 20/20\n",
      "54/54 [==============================] - 27s 503ms/step - loss: 1.5934 - accuracy: 0.4992 - val_loss: 2.4540 - val_accuracy: 0.3913\n",
      "Epoch 1/30\n",
      "214/214 [==============================] - 52s 165ms/step - loss: 7.8291 - accuracy: 0.0489 - val_loss: 5.2803 - val_accuracy: 0.0862\n",
      "Epoch 2/30\n",
      "214/214 [==============================] - 31s 145ms/step - loss: 3.6401 - accuracy: 0.1131 - val_loss: 3.0452 - val_accuracy: 0.1236\n",
      "Epoch 3/30\n",
      "214/214 [==============================] - 32s 151ms/step - loss: 2.9440 - accuracy: 0.1505 - val_loss: 2.8824 - val_accuracy: 0.1701\n",
      "Epoch 4/30\n",
      "214/214 [==============================] - 32s 151ms/step - loss: 2.7243 - accuracy: 0.1960 - val_loss: 2.7007 - val_accuracy: 0.2039\n",
      "Epoch 5/30\n",
      "214/214 [==============================] - 33s 154ms/step - loss: 2.5694 - accuracy: 0.2386 - val_loss: 2.5862 - val_accuracy: 0.2389\n",
      "Epoch 6/30\n",
      "214/214 [==============================] - 33s 153ms/step - loss: 2.4383 - accuracy: 0.2629 - val_loss: 2.4756 - val_accuracy: 0.2743\n",
      "Epoch 7/30\n",
      "214/214 [==============================] - 32s 151ms/step - loss: 2.2868 - accuracy: 0.3078 - val_loss: 2.3828 - val_accuracy: 0.3089\n",
      "Epoch 8/30\n",
      "214/214 [==============================] - 31s 144ms/step - loss: 2.1611 - accuracy: 0.3466 - val_loss: 2.3706 - val_accuracy: 0.3289\n",
      "Epoch 9/30\n",
      "214/214 [==============================] - 32s 151ms/step - loss: 2.0118 - accuracy: 0.3862 - val_loss: 2.2308 - val_accuracy: 0.3658\n",
      "Epoch 10/30\n",
      "214/214 [==============================] - 32s 151ms/step - loss: 1.9120 - accuracy: 0.4192 - val_loss: 2.3113 - val_accuracy: 0.3706\n",
      "Epoch 11/30\n",
      "214/214 [==============================] - 32s 150ms/step - loss: 1.7991 - accuracy: 0.4481 - val_loss: 2.1580 - val_accuracy: 0.3925\n",
      "Epoch 12/30\n",
      "214/214 [==============================] - 31s 147ms/step - loss: 1.7272 - accuracy: 0.4756 - val_loss: 2.1321 - val_accuracy: 0.4213\n",
      "Epoch 13/30\n",
      "214/214 [==============================] - 32s 148ms/step - loss: 1.6254 - accuracy: 0.5116 - val_loss: 2.1321 - val_accuracy: 0.4281\n",
      "Epoch 14/30\n",
      "214/214 [==============================] - 31s 146ms/step - loss: 1.5575 - accuracy: 0.5264 - val_loss: 2.1894 - val_accuracy: 0.4334\n",
      "Epoch 15/30\n",
      "214/214 [==============================] - 31s 145ms/step - loss: 1.4777 - accuracy: 0.5489 - val_loss: 2.1339 - val_accuracy: 0.4535\n",
      "Epoch 16/30\n",
      "214/214 [==============================] - 33s 153ms/step - loss: 1.4411 - accuracy: 0.5624 - val_loss: 2.0311 - val_accuracy: 0.4813\n",
      "Epoch 17/30\n",
      "214/214 [==============================] - 33s 153ms/step - loss: 1.3838 - accuracy: 0.5789 - val_loss: 2.1333 - val_accuracy: 0.4728\n",
      "Epoch 18/30\n",
      "214/214 [==============================] - 32s 150ms/step - loss: 1.2988 - accuracy: 0.6016 - val_loss: 2.0955 - val_accuracy: 0.4825\n",
      "Epoch 19/30\n",
      "175/214 [=======================>......] - ETA: 4s - loss: 1.2401 - accuracy: 0.6288"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense, Bidirectional, TimeDistributed, BatchNormalization\n",
    "\n",
    "results = pd.DataFrame(columns=['lstm_units', 'dropout_rate', 'epoch', 'batch', 'loss', 'loss_max', 'accuracy', 'accuracy_max', 'val_loss', 'val_loss_max', 'val_accuracy', 'val_accuracy_max'])\n",
    "\n",
    "# Set your model's hyperparameters\n",
    "for lstm_units in [64, 128, 256]:\n",
    "    for dropout_rate in [0.2, 0.4, 0.6]:\n",
    "            for epoch in [10, 20, 30, 40]:\n",
    "                  for batch in [32, 64, 128]:\n",
    "\n",
    "                        num_classes = len(y_train_encoded)  # Number of unique classes in your dataset\n",
    "\n",
    "                        input_shape = (39, 44)\n",
    "\n",
    "                        model = Sequential([\n",
    "                            Bidirectional(LSTM(lstm_units, return_sequences=True), input_shape=input_shape),\n",
    "                            BatchNormalization(),\n",
    "                            Dropout(dropout_rate),\n",
    "                            Bidirectional(LSTM(lstm_units, return_sequences=True)),\n",
    "                            BatchNormalization(),\n",
    "                            Dropout(dropout_rate),\n",
    "                            LSTM(lstm_units, return_sequences=True),\n",
    "                            BatchNormalization(),\n",
    "                            Dropout(dropout_rate),\n",
    "                            TimeDistributed(Dense(64, activation='relu')),\n",
    "                            BatchNormalization(),\n",
    "                            Dropout(dropout_rate),\n",
    "                            TimeDistributed(Dense(32, activation='relu')),\n",
    "                            BatchNormalization(),\n",
    "                            Dropout(dropout_rate),\n",
    "                            LSTM(lstm_units),\n",
    "                            BatchNormalization(),\n",
    "                            Dropout(dropout_rate),\n",
    "                            Dense(num_classes, activation='softmax')\n",
    "                        ])\n",
    "\n",
    "\n",
    "                        # Compile the model\n",
    "                        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "                        # Train the model with your training set and validate it with your validation set\n",
    "                        epochs = epoch\n",
    "                        batch_size = batch\n",
    "                        history = model.fit(X_train, y_train_encoded, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val_encoded))\n",
    "\n",
    "                        results = np.concatenate((results, pd.DataFrame([[lstm_units, dropout_rate, epoch, batch, history.history['loss'][-1], history.history['loss'], history.history['accuracy'][-1], history.history['accuracy'], history.history['val_loss'][-1], history.history['val_loss'], history.history['val_accuracy'][-1], history.history['val_accuracy']]], \n",
    "                                                                        columns=['lstm_units', 'dropout_rate', 'epoch', 'batch', 'loss', 'loss_max', 'accuracy', 'accuracy_max', 'val_loss', 'val_loss_max', 'val_accuracy', 'val_accuracy_max'])), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[64, 0.2, 2, 32, 3.100442886352539,\n",
       "        list([6.995808124542236, 3.100442886352539]),\n",
       "        0.16634966433048248, 0.16634966433048248, 2.812389373779297,\n",
       "        3.762976884841919, 0.18740805983543396, 0.18740805983543396]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.to_pickle('results\\\\model_lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
