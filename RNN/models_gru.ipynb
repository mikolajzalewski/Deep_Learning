{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dataset import LABELS\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_pickle('extracted_features\\\\features_training.pkl')\n",
    "val = pd.read_pickle('extracted_features\\\\features_validation.pkl')\n",
    "\n",
    "X_train = np.array([x[0] for x in train])\n",
    "y_train = np.array([x[1] for x in train])\n",
    "X_val = np.array([x[0] for x in val])\n",
    "y_val = np.array([x[1] for x in val])\n",
    "\n",
    "# Create a label encoder object\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the label encoder using your labels (combine both train and val labels if they have different classes)\n",
    "label_encoder.fit(np.concatenate((y_train, y_val)))\n",
    "\n",
    "# Transform your string labels to integer labels for both training and validation sets\n",
    "y_train_encoded = label_encoder.transform(y_train)\n",
    "y_val_encoded = label_encoder.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "214/214 [==============================] - 29s 69ms/step - loss: 6.9579 - accuracy: 0.0613 - val_loss: 3.6162 - val_accuracy: 0.0596\n",
      "Epoch 2/10\n",
      "214/214 [==============================] - 12s 56ms/step - loss: 2.8994 - accuracy: 0.1918 - val_loss: 2.5313 - val_accuracy: 0.2439\n",
      "Epoch 3/10\n",
      "214/214 [==============================] - 13s 60ms/step - loss: 2.4038 - accuracy: 0.2900 - val_loss: 2.0998 - val_accuracy: 0.3616\n",
      "Epoch 4/10\n",
      "214/214 [==============================] - 12s 57ms/step - loss: 2.0500 - accuracy: 0.3930 - val_loss: 1.8843 - val_accuracy: 0.4451\n",
      "Epoch 5/10\n",
      "214/214 [==============================] - 13s 62ms/step - loss: 1.8284 - accuracy: 0.4449 - val_loss: 1.6862 - val_accuracy: 0.4878\n",
      "Epoch 6/10\n",
      "214/214 [==============================] - 12s 56ms/step - loss: 1.7079 - accuracy: 0.4755 - val_loss: 1.6471 - val_accuracy: 0.5157\n",
      "Epoch 7/10\n",
      "214/214 [==============================] - 13s 61ms/step - loss: 1.6029 - accuracy: 0.5110 - val_loss: 1.7111 - val_accuracy: 0.4846\n",
      "Epoch 8/10\n",
      "214/214 [==============================] - 12s 56ms/step - loss: 1.4772 - accuracy: 0.5429 - val_loss: 1.3925 - val_accuracy: 0.5940\n",
      "Epoch 9/10\n",
      "214/214 [==============================] - 13s 60ms/step - loss: 1.4434 - accuracy: 0.5593 - val_loss: 1.3605 - val_accuracy: 0.5877\n",
      "Epoch 10/10\n",
      "214/214 [==============================] - 12s 57ms/step - loss: 1.3525 - accuracy: 0.5852 - val_loss: 1.5537 - val_accuracy: 0.5327\n",
      "Epoch 1/20\n",
      "214/214 [==============================] - 32s 74ms/step - loss: 7.0433 - accuracy: 0.0601 - val_loss: 3.7041 - val_accuracy: 0.0825\n",
      "Epoch 2/20\n",
      "214/214 [==============================] - 13s 59ms/step - loss: 2.9475 - accuracy: 0.1612 - val_loss: 2.6197 - val_accuracy: 0.2352\n",
      "Epoch 3/20\n",
      "214/214 [==============================] - 13s 60ms/step - loss: 2.4830 - accuracy: 0.2714 - val_loss: 2.4180 - val_accuracy: 0.2440\n",
      "Epoch 4/20\n",
      "214/214 [==============================] - 14s 63ms/step - loss: 2.2000 - accuracy: 0.3486 - val_loss: 2.0087 - val_accuracy: 0.3954\n",
      "Epoch 5/20\n",
      "214/214 [==============================] - 13s 61ms/step - loss: 2.0040 - accuracy: 0.3947 - val_loss: 1.8612 - val_accuracy: 0.4391\n",
      "Epoch 6/20\n",
      "214/214 [==============================] - 14s 65ms/step - loss: 1.7949 - accuracy: 0.4582 - val_loss: 1.6778 - val_accuracy: 0.5038\n",
      "Epoch 7/20\n",
      "214/214 [==============================] - 12s 57ms/step - loss: 1.6568 - accuracy: 0.4979 - val_loss: 1.6263 - val_accuracy: 0.5074\n",
      "Epoch 8/20\n",
      "214/214 [==============================] - 13s 62ms/step - loss: 1.5562 - accuracy: 0.5257 - val_loss: 1.5525 - val_accuracy: 0.5432\n",
      "Epoch 9/20\n",
      "214/214 [==============================] - 12s 57ms/step - loss: 1.4460 - accuracy: 0.5596 - val_loss: 1.4088 - val_accuracy: 0.5755\n",
      "Epoch 10/20\n",
      "214/214 [==============================] - 13s 60ms/step - loss: 1.3738 - accuracy: 0.5808 - val_loss: 1.3234 - val_accuracy: 0.6034\n",
      "Epoch 11/20\n",
      "214/214 [==============================] - 12s 56ms/step - loss: 1.3215 - accuracy: 0.5972 - val_loss: 1.3095 - val_accuracy: 0.6165\n",
      "Epoch 12/20\n",
      "214/214 [==============================] - 13s 59ms/step - loss: 1.2586 - accuracy: 0.6228 - val_loss: 1.3344 - val_accuracy: 0.6078\n",
      "Epoch 13/20\n",
      "214/214 [==============================] - 12s 56ms/step - loss: 1.2080 - accuracy: 0.6317 - val_loss: 1.2495 - val_accuracy: 0.6239\n",
      "Epoch 14/20\n",
      "214/214 [==============================] - 13s 61ms/step - loss: 1.1354 - accuracy: 0.6506 - val_loss: 1.2837 - val_accuracy: 0.6208\n",
      "Epoch 15/20\n",
      "214/214 [==============================] - 12s 56ms/step - loss: 1.0749 - accuracy: 0.6679 - val_loss: 1.2364 - val_accuracy: 0.6302\n",
      "Epoch 16/20\n",
      "214/214 [==============================] - 13s 60ms/step - loss: 1.0549 - accuracy: 0.6783 - val_loss: 1.2053 - val_accuracy: 0.6565\n",
      "Epoch 17/20\n",
      "214/214 [==============================] - 12s 56ms/step - loss: 1.0081 - accuracy: 0.6963 - val_loss: 1.2228 - val_accuracy: 0.6484\n",
      "Epoch 18/20\n",
      "214/214 [==============================] - 10s 46ms/step - loss: 0.9734 - accuracy: 0.7046 - val_loss: 1.1869 - val_accuracy: 0.6556\n",
      "Epoch 19/20\n",
      "214/214 [==============================] - 13s 62ms/step - loss: 0.9531 - accuracy: 0.7132 - val_loss: 1.1757 - val_accuracy: 0.6556\n",
      "Epoch 20/20\n",
      "214/214 [==============================] - 12s 58ms/step - loss: 0.8807 - accuracy: 0.7359 - val_loss: 1.1120 - val_accuracy: 0.6752\n",
      "Epoch 1/30\n",
      "214/214 [==============================] - 31s 72ms/step - loss: 6.9051 - accuracy: 0.0533 - val_loss: 3.5724 - val_accuracy: 0.0884\n",
      "Epoch 2/30\n",
      "214/214 [==============================] - 16s 77ms/step - loss: 3.0638 - accuracy: 0.1432 - val_loss: 2.7562 - val_accuracy: 0.1831\n",
      "Epoch 3/30\n",
      "214/214 [==============================] - 16s 74ms/step - loss: 2.6700 - accuracy: 0.2117 - val_loss: 2.4194 - val_accuracy: 0.2816\n",
      "Epoch 4/30\n",
      "214/214 [==============================] - 16s 74ms/step - loss: 2.3523 - accuracy: 0.3017 - val_loss: 2.1408 - val_accuracy: 0.3460\n",
      "Epoch 5/30\n",
      "214/214 [==============================] - 16s 75ms/step - loss: 2.0523 - accuracy: 0.3814 - val_loss: 1.9107 - val_accuracy: 0.4219\n",
      "Epoch 6/30\n",
      "214/214 [==============================] - 16s 77ms/step - loss: 1.8623 - accuracy: 0.4328 - val_loss: 1.6799 - val_accuracy: 0.4915\n",
      "Epoch 7/30\n",
      "214/214 [==============================] - 15s 69ms/step - loss: 1.7306 - accuracy: 0.4767 - val_loss: 1.8279 - val_accuracy: 0.4532\n",
      "Epoch 8/30\n",
      "214/214 [==============================] - 16s 77ms/step - loss: 1.5679 - accuracy: 0.5194 - val_loss: 1.5297 - val_accuracy: 0.5487\n",
      "Epoch 9/30\n",
      "214/214 [==============================] - 17s 78ms/step - loss: 1.4944 - accuracy: 0.5489 - val_loss: 1.8609 - val_accuracy: 0.4631\n",
      "Epoch 10/30\n",
      "214/214 [==============================] - 17s 78ms/step - loss: 1.3754 - accuracy: 0.5811 - val_loss: 1.4511 - val_accuracy: 0.5612\n",
      "Epoch 11/30\n",
      "214/214 [==============================] - 16s 74ms/step - loss: 1.3142 - accuracy: 0.5962 - val_loss: 1.6520 - val_accuracy: 0.5063\n",
      "Epoch 12/30\n",
      "214/214 [==============================] - 17s 81ms/step - loss: 1.2475 - accuracy: 0.6212 - val_loss: 1.4921 - val_accuracy: 0.5530\n",
      "Epoch 13/30\n",
      "214/214 [==============================] - 16s 77ms/step - loss: 1.1977 - accuracy: 0.6356 - val_loss: 1.3856 - val_accuracy: 0.5883\n",
      "Epoch 14/30\n",
      "214/214 [==============================] - 16s 74ms/step - loss: 1.1326 - accuracy: 0.6516 - val_loss: 1.4644 - val_accuracy: 0.5816\n",
      "Epoch 15/30\n",
      "214/214 [==============================] - 16s 75ms/step - loss: 1.1059 - accuracy: 0.6676 - val_loss: 1.4233 - val_accuracy: 0.5866\n",
      "Epoch 16/30\n",
      "214/214 [==============================] - 16s 74ms/step - loss: 1.0603 - accuracy: 0.6844 - val_loss: 1.3383 - val_accuracy: 0.6167\n",
      "Epoch 17/30\n",
      "214/214 [==============================] - 16s 73ms/step - loss: 1.0167 - accuracy: 0.6873 - val_loss: 1.3003 - val_accuracy: 0.6299\n",
      "Epoch 18/30\n",
      "214/214 [==============================] - 14s 64ms/step - loss: 0.9844 - accuracy: 0.6989 - val_loss: 1.2893 - val_accuracy: 0.6399\n",
      "Epoch 19/30\n",
      "214/214 [==============================] - 16s 77ms/step - loss: 0.9126 - accuracy: 0.7257 - val_loss: 1.3397 - val_accuracy: 0.6200\n",
      "Epoch 20/30\n",
      "214/214 [==============================] - 16s 77ms/step - loss: 0.9105 - accuracy: 0.7293 - val_loss: 1.3537 - val_accuracy: 0.6242\n",
      "Epoch 21/30\n",
      "214/214 [==============================] - 17s 78ms/step - loss: 0.9157 - accuracy: 0.7217 - val_loss: 1.1880 - val_accuracy: 0.6593\n",
      "Epoch 22/30\n",
      "214/214 [==============================] - 17s 77ms/step - loss: 0.8420 - accuracy: 0.7469 - val_loss: 1.2463 - val_accuracy: 0.6512\n",
      "Epoch 23/30\n",
      "214/214 [==============================] - 16s 77ms/step - loss: 0.8305 - accuracy: 0.7448 - val_loss: 1.2248 - val_accuracy: 0.6527\n",
      "Epoch 24/30\n",
      "214/214 [==============================] - 17s 78ms/step - loss: 0.8228 - accuracy: 0.7523 - val_loss: 1.2024 - val_accuracy: 0.6561\n",
      "Epoch 25/30\n",
      "214/214 [==============================] - 16s 76ms/step - loss: 0.7958 - accuracy: 0.7546 - val_loss: 1.2288 - val_accuracy: 0.6649\n",
      "Epoch 26/30\n",
      "214/214 [==============================] - 16s 76ms/step - loss: 0.7639 - accuracy: 0.7661 - val_loss: 1.1902 - val_accuracy: 0.6684\n",
      "Epoch 27/30\n",
      "214/214 [==============================] - 17s 78ms/step - loss: 0.7293 - accuracy: 0.7802 - val_loss: 1.4078 - val_accuracy: 0.6174\n",
      "Epoch 28/30\n",
      "214/214 [==============================] - 14s 68ms/step - loss: 0.7016 - accuracy: 0.7819 - val_loss: 1.4334 - val_accuracy: 0.6258\n",
      "Epoch 29/30\n",
      "214/214 [==============================] - 14s 65ms/step - loss: 0.6995 - accuracy: 0.7908 - val_loss: 1.2373 - val_accuracy: 0.6698\n",
      "Epoch 30/30\n",
      "214/214 [==============================] - 14s 64ms/step - loss: 0.6693 - accuracy: 0.7928 - val_loss: 1.3256 - val_accuracy: 0.6462\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 59s 192ms/step - loss: 8.3429 - accuracy: 0.0461 - val_loss: 7.4951 - val_accuracy: 0.0743\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 14s 132ms/step - loss: 4.4138 - accuracy: 0.1140 - val_loss: 3.2584 - val_accuracy: 0.0743\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 14s 132ms/step - loss: 2.9274 - accuracy: 0.1764 - val_loss: 2.7914 - val_accuracy: 0.1723\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 14s 132ms/step - loss: 2.5817 - accuracy: 0.2417 - val_loss: 2.3677 - val_accuracy: 0.2938\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 14s 131ms/step - loss: 2.2904 - accuracy: 0.3198 - val_loss: 2.1464 - val_accuracy: 0.3395\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 14s 127ms/step - loss: 2.0537 - accuracy: 0.3924 - val_loss: 1.9141 - val_accuracy: 0.4188\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 11s 102ms/step - loss: 1.8429 - accuracy: 0.4500 - val_loss: 1.7669 - val_accuracy: 0.4576\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 14s 129ms/step - loss: 1.6742 - accuracy: 0.4931 - val_loss: 1.5686 - val_accuracy: 0.5199\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 14s 127ms/step - loss: 1.5556 - accuracy: 0.5312 - val_loss: 1.4759 - val_accuracy: 0.5547\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 14s 132ms/step - loss: 1.4483 - accuracy: 0.5650 - val_loss: 1.5240 - val_accuracy: 0.5382\n",
      "Epoch 1/20\n",
      "107/107 [==============================] - 72s 201ms/step - loss: 8.3628 - accuracy: 0.0492 - val_loss: 7.5054 - val_accuracy: 0.0562\n",
      "Epoch 2/20\n",
      "107/107 [==============================] - 15s 138ms/step - loss: 4.3262 - accuracy: 0.1366 - val_loss: 3.3106 - val_accuracy: 0.0893\n",
      "Epoch 3/20\n",
      "107/107 [==============================] - 15s 142ms/step - loss: 2.6514 - accuracy: 0.2497 - val_loss: 2.5653 - val_accuracy: 0.2482\n",
      "Epoch 4/20\n",
      "107/107 [==============================] - 14s 128ms/step - loss: 2.2688 - accuracy: 0.3255 - val_loss: 2.1358 - val_accuracy: 0.3650\n",
      "Epoch 5/20\n",
      "107/107 [==============================] - 12s 115ms/step - loss: 2.0394 - accuracy: 0.3814 - val_loss: 2.0232 - val_accuracy: 0.3882\n",
      "Epoch 6/20\n",
      "107/107 [==============================] - 15s 136ms/step - loss: 1.8691 - accuracy: 0.4279 - val_loss: 1.7886 - val_accuracy: 0.4590\n",
      "Epoch 7/20\n",
      "107/107 [==============================] - 15s 138ms/step - loss: 1.7005 - accuracy: 0.4775 - val_loss: 1.5619 - val_accuracy: 0.5265\n",
      "Epoch 8/20\n",
      "107/107 [==============================] - 15s 141ms/step - loss: 1.5951 - accuracy: 0.5112 - val_loss: 1.6718 - val_accuracy: 0.4918\n",
      "Epoch 9/20\n",
      "107/107 [==============================] - 15s 137ms/step - loss: 1.4862 - accuracy: 0.5311 - val_loss: 1.5485 - val_accuracy: 0.5334\n",
      "Epoch 10/20\n",
      "107/107 [==============================] - 15s 140ms/step - loss: 1.4114 - accuracy: 0.5652 - val_loss: 1.4867 - val_accuracy: 0.5550\n",
      "Epoch 11/20\n",
      "107/107 [==============================] - 15s 138ms/step - loss: 1.3064 - accuracy: 0.5927 - val_loss: 1.4195 - val_accuracy: 0.5793\n",
      "Epoch 12/20\n",
      "107/107 [==============================] - 15s 139ms/step - loss: 1.2338 - accuracy: 0.6157 - val_loss: 1.4493 - val_accuracy: 0.5716\n",
      "Epoch 13/20\n",
      "107/107 [==============================] - 15s 140ms/step - loss: 1.1957 - accuracy: 0.6263 - val_loss: 1.2520 - val_accuracy: 0.6296\n",
      "Epoch 14/20\n",
      "107/107 [==============================] - 15s 139ms/step - loss: 1.1372 - accuracy: 0.6477 - val_loss: 1.3404 - val_accuracy: 0.6047\n",
      "Epoch 15/20\n",
      "107/107 [==============================] - 15s 137ms/step - loss: 1.0871 - accuracy: 0.6595 - val_loss: 1.2558 - val_accuracy: 0.6283\n",
      "Epoch 16/20\n",
      "107/107 [==============================] - 13s 121ms/step - loss: 1.0566 - accuracy: 0.6753 - val_loss: 1.3120 - val_accuracy: 0.6087\n",
      "Epoch 17/20\n",
      "107/107 [==============================] - 12s 116ms/step - loss: 1.0077 - accuracy: 0.6869 - val_loss: 1.3003 - val_accuracy: 0.6168\n",
      "Epoch 18/20\n",
      "107/107 [==============================] - 12s 117ms/step - loss: 0.9694 - accuracy: 0.7033 - val_loss: 1.2277 - val_accuracy: 0.6393\n",
      "Epoch 19/20\n",
      "107/107 [==============================] - 13s 122ms/step - loss: 0.9582 - accuracy: 0.7086 - val_loss: 1.1671 - val_accuracy: 0.6623\n",
      "Epoch 20/20\n",
      "107/107 [==============================] - 15s 140ms/step - loss: 0.8884 - accuracy: 0.7321 - val_loss: 1.2016 - val_accuracy: 0.6525\n",
      "Epoch 1/30\n",
      "107/107 [==============================] - 54s 200ms/step - loss: 8.3468 - accuracy: 0.0525 - val_loss: 8.6673 - val_accuracy: 0.0407\n",
      "Epoch 2/30\n",
      "107/107 [==============================] - 16s 154ms/step - loss: 4.3760 - accuracy: 0.1245 - val_loss: 3.4172 - val_accuracy: 0.1083\n",
      "Epoch 3/30\n",
      "107/107 [==============================] - 16s 149ms/step - loss: 2.7519 - accuracy: 0.2224 - val_loss: 2.7985 - val_accuracy: 0.1893\n",
      "Epoch 4/30\n",
      "107/107 [==============================] - 16s 152ms/step - loss: 2.3802 - accuracy: 0.3029 - val_loss: 2.1827 - val_accuracy: 0.3420\n",
      "Epoch 5/30\n",
      "107/107 [==============================] - 13s 119ms/step - loss: 2.1121 - accuracy: 0.3772 - val_loss: 2.0110 - val_accuracy: 0.3913\n",
      "Epoch 6/30\n",
      "107/107 [==============================] - 16s 147ms/step - loss: 1.9245 - accuracy: 0.4296 - val_loss: 1.9511 - val_accuracy: 0.3992\n",
      "Epoch 7/30\n",
      "107/107 [==============================] - 17s 155ms/step - loss: 1.7435 - accuracy: 0.4682 - val_loss: 1.6947 - val_accuracy: 0.4819\n",
      "Epoch 8/30\n",
      "107/107 [==============================] - 16s 150ms/step - loss: 1.6156 - accuracy: 0.5086 - val_loss: 1.5664 - val_accuracy: 0.5237\n",
      "Epoch 9/30\n",
      "107/107 [==============================] - 17s 155ms/step - loss: 1.5066 - accuracy: 0.5435 - val_loss: 1.4485 - val_accuracy: 0.5703\n",
      "Epoch 10/30\n",
      "107/107 [==============================] - 16s 150ms/step - loss: 1.3992 - accuracy: 0.5666 - val_loss: 1.3999 - val_accuracy: 0.5758\n",
      "Epoch 11/30\n",
      "107/107 [==============================] - 16s 152ms/step - loss: 1.3325 - accuracy: 0.5971 - val_loss: 1.3934 - val_accuracy: 0.5818\n",
      "Epoch 12/30\n",
      "107/107 [==============================] - 17s 155ms/step - loss: 1.2557 - accuracy: 0.6164 - val_loss: 1.3154 - val_accuracy: 0.6069\n",
      "Epoch 13/30\n",
      "107/107 [==============================] - 16s 150ms/step - loss: 1.2010 - accuracy: 0.6294 - val_loss: 1.3169 - val_accuracy: 0.6099\n",
      "Epoch 14/30\n",
      "107/107 [==============================] - 17s 157ms/step - loss: 1.1401 - accuracy: 0.6524 - val_loss: 1.4306 - val_accuracy: 0.5741\n",
      "Epoch 15/30\n",
      "107/107 [==============================] - 14s 132ms/step - loss: 1.0986 - accuracy: 0.6609 - val_loss: 1.2652 - val_accuracy: 0.6330\n",
      "Epoch 16/30\n",
      "107/107 [==============================] - 15s 139ms/step - loss: 1.0815 - accuracy: 0.6634 - val_loss: 1.1975 - val_accuracy: 0.6486\n",
      "Epoch 17/30\n",
      "107/107 [==============================] - 17s 158ms/step - loss: 0.9899 - accuracy: 0.6945 - val_loss: 1.2283 - val_accuracy: 0.6386\n",
      "Epoch 18/30\n",
      "107/107 [==============================] - 16s 153ms/step - loss: 0.9463 - accuracy: 0.7087 - val_loss: 1.1994 - val_accuracy: 0.6534\n",
      "Epoch 19/30\n",
      "107/107 [==============================] - 17s 158ms/step - loss: 0.9244 - accuracy: 0.7140 - val_loss: 1.1858 - val_accuracy: 0.6555\n",
      "Epoch 20/30\n",
      "107/107 [==============================] - 16s 154ms/step - loss: 0.8808 - accuracy: 0.7298 - val_loss: 1.3737 - val_accuracy: 0.6021\n",
      "Epoch 21/30\n",
      "107/107 [==============================] - 17s 156ms/step - loss: 0.8691 - accuracy: 0.7298 - val_loss: 1.1265 - val_accuracy: 0.6784\n",
      "Epoch 22/30\n",
      "107/107 [==============================] - 17s 157ms/step - loss: 0.8320 - accuracy: 0.7374 - val_loss: 1.0893 - val_accuracy: 0.6905\n",
      "Epoch 23/30\n",
      "107/107 [==============================] - 16s 152ms/step - loss: 0.7950 - accuracy: 0.7564 - val_loss: 1.1373 - val_accuracy: 0.6742\n",
      "Epoch 24/30\n",
      "107/107 [==============================] - 17s 159ms/step - loss: 0.7885 - accuracy: 0.7605 - val_loss: 1.1152 - val_accuracy: 0.6736\n",
      "Epoch 25/30\n",
      "107/107 [==============================] - 16s 154ms/step - loss: 0.7610 - accuracy: 0.7650 - val_loss: 1.0783 - val_accuracy: 0.6896\n",
      "Epoch 26/30\n",
      "107/107 [==============================] - 17s 157ms/step - loss: 0.7199 - accuracy: 0.7776 - val_loss: 1.0572 - val_accuracy: 0.6964\n",
      "Epoch 27/30\n",
      "107/107 [==============================] - 17s 155ms/step - loss: 0.7120 - accuracy: 0.7819 - val_loss: 1.1540 - val_accuracy: 0.6696\n",
      "Epoch 28/30\n",
      "107/107 [==============================] - 16s 154ms/step - loss: 0.6881 - accuracy: 0.7899 - val_loss: 1.1242 - val_accuracy: 0.6789\n",
      "Epoch 29/30\n",
      "107/107 [==============================] - 16s 149ms/step - loss: 0.6817 - accuracy: 0.7899 - val_loss: 1.0723 - val_accuracy: 0.6930\n",
      "Epoch 30/30\n",
      "107/107 [==============================] - 13s 120ms/step - loss: 0.6398 - accuracy: 0.8031 - val_loss: 1.1086 - val_accuracy: 0.6815\n",
      "Epoch 1/10\n",
      "54/54 [==============================] - 56s 441ms/step - loss: 8.6960 - accuracy: 0.0341 - val_loss: 8.6882 - val_accuracy: 0.0259\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 19s 351ms/step - loss: 7.2206 - accuracy: 0.0764 - val_loss: 7.6456 - val_accuracy: 0.0346\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 18s 337ms/step - loss: 4.2527 - accuracy: 0.1276 - val_loss: 5.6083 - val_accuracy: 0.0388\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 16s 305ms/step - loss: 3.1073 - accuracy: 0.1716 - val_loss: 3.9642 - val_accuracy: 0.0902\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 18s 343ms/step - loss: 2.6839 - accuracy: 0.2394 - val_loss: 2.9942 - val_accuracy: 0.1828\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 19s 355ms/step - loss: 2.3857 - accuracy: 0.2977 - val_loss: 2.3869 - val_accuracy: 0.3008\n",
      "Epoch 7/10\n",
      "54/54 [==============================] - 19s 347ms/step - loss: 2.1894 - accuracy: 0.3544 - val_loss: 2.3284 - val_accuracy: 0.3154\n",
      "Epoch 8/10\n",
      "54/54 [==============================] - 19s 348ms/step - loss: 2.0403 - accuracy: 0.3857 - val_loss: 2.0037 - val_accuracy: 0.4095\n",
      "Epoch 9/10\n",
      "54/54 [==============================] - 19s 350ms/step - loss: 1.9107 - accuracy: 0.4271 - val_loss: 1.8836 - val_accuracy: 0.4387\n",
      "Epoch 10/10\n",
      "54/54 [==============================] - 19s 359ms/step - loss: 1.7874 - accuracy: 0.4613 - val_loss: 1.8424 - val_accuracy: 0.4619\n",
      "Epoch 1/20\n",
      "54/54 [==============================] - 41s 412ms/step - loss: 8.6832 - accuracy: 0.0410 - val_loss: 8.4885 - val_accuracy: 0.0363\n",
      "Epoch 2/20\n",
      "54/54 [==============================] - 19s 361ms/step - loss: 6.9175 - accuracy: 0.0945 - val_loss: 5.1615 - val_accuracy: 0.0844\n",
      "Epoch 3/20\n",
      "54/54 [==============================] - 19s 346ms/step - loss: 3.8346 - accuracy: 0.1505 - val_loss: 3.1494 - val_accuracy: 0.0891\n",
      "Epoch 4/20\n",
      "54/54 [==============================] - 18s 327ms/step - loss: 2.8827 - accuracy: 0.2108 - val_loss: 2.8984 - val_accuracy: 0.1342\n",
      "Epoch 5/20\n",
      "54/54 [==============================] - 19s 358ms/step - loss: 2.5728 - accuracy: 0.2628 - val_loss: 2.4879 - val_accuracy: 0.2607\n",
      "Epoch 6/20\n",
      "54/54 [==============================] - 19s 361ms/step - loss: 2.3419 - accuracy: 0.3115 - val_loss: 2.2945 - val_accuracy: 0.3214\n",
      "Epoch 7/20\n",
      "54/54 [==============================] - 19s 356ms/step - loss: 2.1429 - accuracy: 0.3674 - val_loss: 1.9825 - val_accuracy: 0.4107\n",
      "Epoch 8/20\n",
      "54/54 [==============================] - 19s 356ms/step - loss: 1.9820 - accuracy: 0.4116 - val_loss: 1.9123 - val_accuracy: 0.4116\n",
      "Epoch 9/20\n",
      "54/54 [==============================] - 19s 359ms/step - loss: 1.7590 - accuracy: 0.4676 - val_loss: 1.6838 - val_accuracy: 0.4959\n",
      "Epoch 10/20\n",
      "54/54 [==============================] - 19s 354ms/step - loss: 1.6221 - accuracy: 0.5146 - val_loss: 1.8302 - val_accuracy: 0.4737\n",
      "Epoch 11/20\n",
      "54/54 [==============================] - 19s 354ms/step - loss: 1.5208 - accuracy: 0.5266 - val_loss: 1.6006 - val_accuracy: 0.5265\n",
      "Epoch 12/20\n",
      "54/54 [==============================] - 19s 357ms/step - loss: 1.4533 - accuracy: 0.5484 - val_loss: 1.4694 - val_accuracy: 0.5625\n",
      "Epoch 13/20\n",
      "54/54 [==============================] - 19s 357ms/step - loss: 1.3628 - accuracy: 0.5854 - val_loss: 1.4248 - val_accuracy: 0.5734\n",
      "Epoch 14/20\n",
      "54/54 [==============================] - 19s 356ms/step - loss: 1.2974 - accuracy: 0.5985 - val_loss: 1.3169 - val_accuracy: 0.6137\n",
      "Epoch 15/20\n",
      "54/54 [==============================] - 19s 358ms/step - loss: 1.2285 - accuracy: 0.6250 - val_loss: 1.2788 - val_accuracy: 0.6144\n",
      "Epoch 16/20\n",
      "54/54 [==============================] - 19s 358ms/step - loss: 1.1675 - accuracy: 0.6442 - val_loss: 1.2509 - val_accuracy: 0.6290\n",
      "Epoch 17/20\n",
      "54/54 [==============================] - 19s 356ms/step - loss: 1.1061 - accuracy: 0.6613 - val_loss: 1.2098 - val_accuracy: 0.6406\n",
      "Epoch 18/20\n",
      "54/54 [==============================] - 19s 355ms/step - loss: 1.0713 - accuracy: 0.6685 - val_loss: 1.2237 - val_accuracy: 0.6322\n",
      "Epoch 19/20\n",
      "54/54 [==============================] - 19s 356ms/step - loss: 1.0397 - accuracy: 0.6774 - val_loss: 1.2762 - val_accuracy: 0.6334\n",
      "Epoch 20/20\n",
      "54/54 [==============================] - 17s 311ms/step - loss: 1.0036 - accuracy: 0.6916 - val_loss: 1.2740 - val_accuracy: 0.6264\n",
      "Epoch 1/30\n",
      "54/54 [==============================] - 60s 468ms/step - loss: 8.6953 - accuracy: 0.0375 - val_loss: 8.4761 - val_accuracy: 0.0387\n",
      "Epoch 2/30\n",
      "54/54 [==============================] - 21s 385ms/step - loss: 7.1219 - accuracy: 0.0967 - val_loss: 7.2628 - val_accuracy: 0.0438\n",
      "Epoch 3/30\n",
      "54/54 [==============================] - 21s 386ms/step - loss: 4.0549 - accuracy: 0.1494 - val_loss: 5.3226 - val_accuracy: 0.0480\n",
      "Epoch 4/30\n",
      "54/54 [==============================] - 20s 375ms/step - loss: 2.9604 - accuracy: 0.2164 - val_loss: 3.2636 - val_accuracy: 0.1571\n",
      "Epoch 5/30\n",
      "54/54 [==============================] - 20s 374ms/step - loss: 2.5425 - accuracy: 0.2761 - val_loss: 2.4530 - val_accuracy: 0.2891\n",
      "Epoch 6/30\n",
      "54/54 [==============================] - 21s 395ms/step - loss: 2.3195 - accuracy: 0.3219 - val_loss: 2.2652 - val_accuracy: 0.3283\n",
      "Epoch 7/30\n",
      "54/54 [==============================] - 22s 401ms/step - loss: 2.0795 - accuracy: 0.3820 - val_loss: 2.0398 - val_accuracy: 0.3869\n",
      "Epoch 8/30\n",
      "54/54 [==============================] - 22s 404ms/step - loss: 1.9134 - accuracy: 0.4291 - val_loss: 1.9169 - val_accuracy: 0.4363\n",
      "Epoch 9/30\n",
      "54/54 [==============================] - 19s 348ms/step - loss: 1.7872 - accuracy: 0.4677 - val_loss: 1.7210 - val_accuracy: 0.4940\n",
      "Epoch 10/30\n",
      "54/54 [==============================] - 17s 319ms/step - loss: 1.6563 - accuracy: 0.4974 - val_loss: 1.6902 - val_accuracy: 0.4976\n",
      "Epoch 11/30\n",
      "54/54 [==============================] - 20s 366ms/step - loss: 1.5374 - accuracy: 0.5266 - val_loss: 1.5907 - val_accuracy: 0.5138\n",
      "Epoch 12/30\n",
      "54/54 [==============================] - 20s 365ms/step - loss: 1.4538 - accuracy: 0.5546 - val_loss: 1.5060 - val_accuracy: 0.5447\n",
      "Epoch 13/30\n",
      "54/54 [==============================] - 21s 383ms/step - loss: 1.3753 - accuracy: 0.5767 - val_loss: 1.3702 - val_accuracy: 0.5972\n",
      "Epoch 14/30\n",
      "54/54 [==============================] - 22s 401ms/step - loss: 1.2922 - accuracy: 0.6061 - val_loss: 1.3609 - val_accuracy: 0.6049\n",
      "Epoch 15/30\n",
      "54/54 [==============================] - 21s 381ms/step - loss: 1.2325 - accuracy: 0.6195 - val_loss: 1.3045 - val_accuracy: 0.6115\n",
      "Epoch 16/30\n",
      "54/54 [==============================] - 19s 346ms/step - loss: 1.1996 - accuracy: 0.6329 - val_loss: 1.3964 - val_accuracy: 0.5968\n",
      "Epoch 17/30\n",
      "54/54 [==============================] - 21s 391ms/step - loss: 1.1199 - accuracy: 0.6541 - val_loss: 1.2429 - val_accuracy: 0.6411\n",
      "Epoch 18/30\n",
      "54/54 [==============================] - 22s 403ms/step - loss: 1.1052 - accuracy: 0.6604 - val_loss: 1.2267 - val_accuracy: 0.6421\n",
      "Epoch 19/30\n",
      "54/54 [==============================] - 21s 392ms/step - loss: 1.0736 - accuracy: 0.6683 - val_loss: 1.2646 - val_accuracy: 0.6289\n",
      "Epoch 20/30\n",
      "54/54 [==============================] - 21s 389ms/step - loss: 1.0045 - accuracy: 0.6884 - val_loss: 1.2691 - val_accuracy: 0.6259\n",
      "Epoch 21/30\n",
      "54/54 [==============================] - 21s 391ms/step - loss: 0.9610 - accuracy: 0.7039 - val_loss: 1.1567 - val_accuracy: 0.6624\n",
      "Epoch 22/30\n",
      "54/54 [==============================] - 21s 384ms/step - loss: 0.9318 - accuracy: 0.7178 - val_loss: 1.1774 - val_accuracy: 0.6606\n",
      "Epoch 23/30\n",
      "54/54 [==============================] - 21s 386ms/step - loss: 0.9039 - accuracy: 0.7229 - val_loss: 1.1701 - val_accuracy: 0.6565\n",
      "Epoch 24/30\n",
      "54/54 [==============================] - 21s 387ms/step - loss: 0.8910 - accuracy: 0.7233 - val_loss: 1.1604 - val_accuracy: 0.6724\n",
      "Epoch 25/30\n",
      "54/54 [==============================] - 21s 384ms/step - loss: 0.8436 - accuracy: 0.7397 - val_loss: 1.1659 - val_accuracy: 0.6712\n",
      "Epoch 26/30\n",
      "54/54 [==============================] - 21s 386ms/step - loss: 0.8314 - accuracy: 0.7384 - val_loss: 1.1607 - val_accuracy: 0.6723\n",
      "Epoch 27/30\n",
      "54/54 [==============================] - 21s 384ms/step - loss: 0.7693 - accuracy: 0.7582 - val_loss: 1.2005 - val_accuracy: 0.6664\n",
      "Epoch 28/30\n",
      "54/54 [==============================] - 21s 381ms/step - loss: 0.7611 - accuracy: 0.7663 - val_loss: 1.1441 - val_accuracy: 0.6858\n",
      "Epoch 29/30\n",
      "54/54 [==============================] - 21s 390ms/step - loss: 0.7576 - accuracy: 0.7650 - val_loss: 1.1158 - val_accuracy: 0.6884\n",
      "Epoch 30/30\n",
      "54/54 [==============================] - 22s 416ms/step - loss: 0.7219 - accuracy: 0.7756 - val_loss: 1.1015 - val_accuracy: 0.6939\n",
      "Epoch 1/10\n",
      "214/214 [==============================] - 59s 138ms/step - loss: 7.6407 - accuracy: 0.0272 - val_loss: 6.3628 - val_accuracy: 0.0371\n",
      "Epoch 2/10\n",
      "214/214 [==============================] - 25s 115ms/step - loss: 3.6563 - accuracy: 0.0416 - val_loss: 3.5027 - val_accuracy: 0.0385\n",
      "Epoch 3/10\n",
      "214/214 [==============================] - 23s 108ms/step - loss: 3.3790 - accuracy: 0.0584 - val_loss: 3.3863 - val_accuracy: 0.0519\n",
      "Epoch 4/10\n",
      "214/214 [==============================] - 23s 107ms/step - loss: 3.2447 - accuracy: 0.0840 - val_loss: 3.3434 - val_accuracy: 0.0581\n",
      "Epoch 5/10\n",
      "214/214 [==============================] - 24s 111ms/step - loss: 3.1106 - accuracy: 0.1090 - val_loss: 3.2034 - val_accuracy: 0.0768\n",
      "Epoch 6/10\n",
      "214/214 [==============================] - 24s 112ms/step - loss: 2.9721 - accuracy: 0.1407 - val_loss: 3.2022 - val_accuracy: 0.0590\n",
      "Epoch 7/10\n",
      "214/214 [==============================] - 24s 112ms/step - loss: 2.7840 - accuracy: 0.1851 - val_loss: 3.1261 - val_accuracy: 0.0962\n",
      "Epoch 8/10\n",
      "214/214 [==============================] - 24s 111ms/step - loss: 2.6585 - accuracy: 0.2132 - val_loss: 3.2379 - val_accuracy: 0.0691\n",
      "Epoch 9/10\n",
      "214/214 [==============================] - 24s 112ms/step - loss: 2.5643 - accuracy: 0.2345 - val_loss: 3.1529 - val_accuracy: 0.0709\n",
      "Epoch 10/10\n",
      "214/214 [==============================] - 24s 112ms/step - loss: 2.5075 - accuracy: 0.2571 - val_loss: 3.0531 - val_accuracy: 0.0928\n",
      "Epoch 1/20\n",
      "214/214 [==============================] - 59s 156ms/step - loss: 7.6124 - accuracy: 0.0290 - val_loss: 5.0708 - val_accuracy: 0.0397\n",
      "Epoch 2/20\n",
      "214/214 [==============================] - 26s 123ms/step - loss: 3.6629 - accuracy: 0.0410 - val_loss: 3.5386 - val_accuracy: 0.0515\n",
      "Epoch 3/20\n",
      "214/214 [==============================] - 28s 132ms/step - loss: 3.4113 - accuracy: 0.0522 - val_loss: 3.4701 - val_accuracy: 0.0513\n",
      "Epoch 4/20\n",
      "214/214 [==============================] - 29s 134ms/step - loss: 3.2679 - accuracy: 0.0718 - val_loss: 3.5072 - val_accuracy: 0.0468\n",
      "Epoch 5/20\n",
      "214/214 [==============================] - 30s 139ms/step - loss: 3.1596 - accuracy: 0.0853 - val_loss: 3.2331 - val_accuracy: 0.0650\n",
      "Epoch 6/20\n",
      "214/214 [==============================] - 29s 138ms/step - loss: 3.0465 - accuracy: 0.1089 - val_loss: 3.2744 - val_accuracy: 0.0799\n",
      "Epoch 7/20\n",
      "214/214 [==============================] - 30s 140ms/step - loss: 2.8993 - accuracy: 0.1415 - val_loss: 2.9531 - val_accuracy: 0.1486\n",
      "Epoch 8/20\n",
      "214/214 [==============================] - 28s 130ms/step - loss: 2.7607 - accuracy: 0.1827 - val_loss: 2.8858 - val_accuracy: 0.1306\n",
      "Epoch 9/20\n",
      "214/214 [==============================] - 28s 130ms/step - loss: 2.6890 - accuracy: 0.1909 - val_loss: 2.8315 - val_accuracy: 0.1427\n",
      "Epoch 10/20\n",
      "214/214 [==============================] - 28s 130ms/step - loss: 2.5833 - accuracy: 0.2206 - val_loss: 2.8545 - val_accuracy: 0.1296\n",
      "Epoch 11/20\n",
      "214/214 [==============================] - 28s 130ms/step - loss: 2.5153 - accuracy: 0.2402 - val_loss: 2.7437 - val_accuracy: 0.1652\n",
      "Epoch 12/20\n",
      "214/214 [==============================] - 26s 123ms/step - loss: 2.4434 - accuracy: 0.2486 - val_loss: 2.7354 - val_accuracy: 0.1745\n",
      "Epoch 13/20\n",
      "214/214 [==============================] - 26s 122ms/step - loss: 2.3876 - accuracy: 0.2673 - val_loss: 2.7026 - val_accuracy: 0.1723\n",
      "Epoch 14/20\n",
      "214/214 [==============================] - 26s 122ms/step - loss: 2.2967 - accuracy: 0.2913 - val_loss: 2.6316 - val_accuracy: 0.1609\n",
      "Epoch 15/20\n",
      "214/214 [==============================] - 26s 123ms/step - loss: 2.2610 - accuracy: 0.3045 - val_loss: 2.7259 - val_accuracy: 0.1489\n",
      "Epoch 16/20\n",
      "214/214 [==============================] - 26s 123ms/step - loss: 2.1848 - accuracy: 0.3289 - val_loss: 2.6762 - val_accuracy: 0.1523\n",
      "Epoch 17/20\n",
      "214/214 [==============================] - 26s 124ms/step - loss: 2.1461 - accuracy: 0.3457 - val_loss: 2.6048 - val_accuracy: 0.1608\n",
      "Epoch 18/20\n",
      "214/214 [==============================] - 26s 123ms/step - loss: 2.0719 - accuracy: 0.3611 - val_loss: 2.4964 - val_accuracy: 0.2048\n",
      "Epoch 19/20\n",
      "214/214 [==============================] - 26s 122ms/step - loss: 2.0546 - accuracy: 0.3747 - val_loss: 3.0179 - val_accuracy: 0.1102\n",
      "Epoch 20/20\n",
      "214/214 [==============================] - 26s 123ms/step - loss: 1.9842 - accuracy: 0.3922 - val_loss: 2.7053 - val_accuracy: 0.1486\n",
      "Epoch 1/30\n",
      "214/214 [==============================] - 55s 150ms/step - loss: 7.6077 - accuracy: 0.0255 - val_loss: 6.3048 - val_accuracy: 0.0355\n",
      "Epoch 2/30\n",
      "214/214 [==============================] - 27s 128ms/step - loss: 3.6763 - accuracy: 0.0407 - val_loss: 3.6138 - val_accuracy: 0.0387\n",
      "Epoch 3/30\n",
      "214/214 [==============================] - 29s 136ms/step - loss: 3.4164 - accuracy: 0.0502 - val_loss: 3.5350 - val_accuracy: 0.0374\n",
      "Epoch 4/30\n",
      "214/214 [==============================] - 29s 136ms/step - loss: 3.3103 - accuracy: 0.0654 - val_loss: 3.4398 - val_accuracy: 0.0560\n",
      "Epoch 5/30\n",
      "214/214 [==============================] - 29s 134ms/step - loss: 3.1998 - accuracy: 0.0783 - val_loss: 3.8442 - val_accuracy: 0.0487\n",
      "Epoch 6/30\n",
      "214/214 [==============================] - 29s 137ms/step - loss: 3.0635 - accuracy: 0.1129 - val_loss: 3.6193 - val_accuracy: 0.0472\n",
      "Epoch 7/30\n",
      "214/214 [==============================] - 29s 137ms/step - loss: 2.9482 - accuracy: 0.1403 - val_loss: 3.0812 - val_accuracy: 0.1028\n",
      "Epoch 8/30\n",
      "214/214 [==============================] - 29s 136ms/step - loss: 2.8086 - accuracy: 0.1684 - val_loss: 3.1497 - val_accuracy: 0.0777\n",
      "Epoch 9/30\n",
      "214/214 [==============================] - 29s 135ms/step - loss: 2.6743 - accuracy: 0.1968 - val_loss: 2.9683 - val_accuracy: 0.1062\n",
      "Epoch 10/30\n",
      "214/214 [==============================] - 29s 135ms/step - loss: 2.5646 - accuracy: 0.2237 - val_loss: 2.8905 - val_accuracy: 0.1272\n",
      "Epoch 11/30\n",
      "214/214 [==============================] - 29s 134ms/step - loss: 2.4562 - accuracy: 0.2480 - val_loss: 3.0217 - val_accuracy: 0.0968\n",
      "Epoch 12/30\n",
      "214/214 [==============================] - 29s 134ms/step - loss: 2.3439 - accuracy: 0.2854 - val_loss: 2.8542 - val_accuracy: 0.1471\n",
      "Epoch 13/30\n",
      "214/214 [==============================] - 29s 137ms/step - loss: 2.2958 - accuracy: 0.2964 - val_loss: 2.6205 - val_accuracy: 0.1862\n",
      "Epoch 14/30\n",
      "214/214 [==============================] - 29s 137ms/step - loss: 2.2045 - accuracy: 0.3233 - val_loss: 3.0113 - val_accuracy: 0.1503\n",
      "Epoch 15/30\n",
      "214/214 [==============================] - 29s 136ms/step - loss: 2.1456 - accuracy: 0.3485 - val_loss: 3.0305 - val_accuracy: 0.1061\n",
      "Epoch 16/30\n",
      "214/214 [==============================] - 30s 138ms/step - loss: 2.0589 - accuracy: 0.3683 - val_loss: 2.6883 - val_accuracy: 0.1655\n",
      "Epoch 17/30\n",
      "214/214 [==============================] - 31s 144ms/step - loss: 2.0002 - accuracy: 0.3842 - val_loss: 2.7958 - val_accuracy: 0.1575\n",
      "Epoch 18/30\n",
      "214/214 [==============================] - 31s 144ms/step - loss: 1.9336 - accuracy: 0.4063 - val_loss: 2.6311 - val_accuracy: 0.1924\n",
      "Epoch 19/30\n",
      "214/214 [==============================] - 29s 137ms/step - loss: 1.9015 - accuracy: 0.4159 - val_loss: 2.4952 - val_accuracy: 0.2327\n",
      "Epoch 20/30\n",
      "214/214 [==============================] - 25s 117ms/step - loss: 1.8155 - accuracy: 0.4396 - val_loss: 2.5379 - val_accuracy: 0.2208\n",
      "Epoch 21/30\n",
      "214/214 [==============================] - 30s 140ms/step - loss: 1.7616 - accuracy: 0.4581 - val_loss: 2.9012 - val_accuracy: 0.1289\n",
      "Epoch 22/30\n",
      "214/214 [==============================] - 30s 142ms/step - loss: 1.7308 - accuracy: 0.4701 - val_loss: 3.0173 - val_accuracy: 0.1495\n",
      "Epoch 23/30\n",
      "214/214 [==============================] - 30s 141ms/step - loss: 1.6903 - accuracy: 0.4882 - val_loss: 3.1102 - val_accuracy: 0.1530\n",
      "Epoch 24/30\n",
      "214/214 [==============================] - 31s 143ms/step - loss: 1.6401 - accuracy: 0.4948 - val_loss: 2.9288 - val_accuracy: 0.1246\n",
      "Epoch 25/30\n",
      "214/214 [==============================] - 31s 144ms/step - loss: 1.6004 - accuracy: 0.5093 - val_loss: 2.6909 - val_accuracy: 0.2234\n",
      "Epoch 26/30\n",
      "214/214 [==============================] - 31s 144ms/step - loss: 1.5720 - accuracy: 0.5230 - val_loss: 3.0861 - val_accuracy: 0.0849\n",
      "Epoch 27/30\n",
      "214/214 [==============================] - 31s 143ms/step - loss: 1.5460 - accuracy: 0.5342 - val_loss: 3.0862 - val_accuracy: 0.0940\n",
      "Epoch 28/30\n",
      "214/214 [==============================] - 30s 140ms/step - loss: 1.5005 - accuracy: 0.5434 - val_loss: 3.1784 - val_accuracy: 0.0877\n",
      "Epoch 29/30\n",
      "214/214 [==============================] - 32s 148ms/step - loss: 1.4367 - accuracy: 0.5573 - val_loss: 3.2768 - val_accuracy: 0.1218\n",
      "Epoch 30/30\n",
      "214/214 [==============================] - 32s 149ms/step - loss: 1.4314 - accuracy: 0.5709 - val_loss: 3.4443 - val_accuracy: 0.0794\n",
      "Epoch 1/10\n",
      "107/107 [==============================] - 60s 260ms/step - loss: 8.5679 - accuracy: 0.0238 - val_loss: 7.9406 - val_accuracy: 0.0338\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 24s 223ms/step - loss: 5.7353 - accuracy: 0.0360 - val_loss: 3.5704 - val_accuracy: 0.0277\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 24s 224ms/step - loss: 3.6253 - accuracy: 0.0417 - val_loss: 3.4716 - val_accuracy: 0.0382\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 24s 224ms/step - loss: 3.4319 - accuracy: 0.0481 - val_loss: 3.3987 - val_accuracy: 0.0488\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 24s 223ms/step - loss: 3.3538 - accuracy: 0.0622 - val_loss: 3.3120 - val_accuracy: 0.0660\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 24s 223ms/step - loss: 3.2870 - accuracy: 0.0746 - val_loss: 3.2615 - val_accuracy: 0.0743\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 24s 224ms/step - loss: 3.2132 - accuracy: 0.0920 - val_loss: 3.1983 - val_accuracy: 0.0872\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 24s 223ms/step - loss: 3.1077 - accuracy: 0.1124 - val_loss: 3.1568 - val_accuracy: 0.0933\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 24s 222ms/step - loss: 3.0130 - accuracy: 0.1320 - val_loss: 3.0376 - val_accuracy: 0.1149\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 24s 220ms/step - loss: 2.8656 - accuracy: 0.1642 - val_loss: 3.0000 - val_accuracy: 0.1111\n",
      "Epoch 1/20\n",
      "107/107 [==============================] - 58s 275ms/step - loss: 8.5766 - accuracy: 0.0290 - val_loss: 7.6757 - val_accuracy: 0.0363\n",
      "Epoch 2/20\n",
      "107/107 [==============================] - 25s 231ms/step - loss: 5.7774 - accuracy: 0.0367 - val_loss: 3.5707 - val_accuracy: 0.0256\n",
      "Epoch 3/20\n",
      "107/107 [==============================] - 23s 217ms/step - loss: 3.6383 - accuracy: 0.0401 - val_loss: 3.4301 - val_accuracy: 0.0381\n",
      "Epoch 4/20\n",
      "107/107 [==============================] - 23s 219ms/step - loss: 3.4291 - accuracy: 0.0557 - val_loss: 3.4169 - val_accuracy: 0.0474\n",
      "Epoch 5/20\n",
      "107/107 [==============================] - 23s 218ms/step - loss: 3.3058 - accuracy: 0.0753 - val_loss: 3.3118 - val_accuracy: 0.0759\n",
      "Epoch 6/20\n",
      "107/107 [==============================] - 23s 219ms/step - loss: 3.1518 - accuracy: 0.1061 - val_loss: 3.2522 - val_accuracy: 0.0837\n",
      "Epoch 7/20\n",
      "107/107 [==============================] - 24s 221ms/step - loss: 3.0188 - accuracy: 0.1339 - val_loss: 3.0768 - val_accuracy: 0.1096\n",
      "Epoch 8/20\n",
      "107/107 [==============================] - 23s 218ms/step - loss: 2.9296 - accuracy: 0.1551 - val_loss: 3.0910 - val_accuracy: 0.0937\n",
      "Epoch 9/20\n",
      "107/107 [==============================] - 23s 219ms/step - loss: 2.8200 - accuracy: 0.1723 - val_loss: 2.9121 - val_accuracy: 0.1447\n",
      "Epoch 10/20\n",
      "107/107 [==============================] - 21s 197ms/step - loss: 2.6948 - accuracy: 0.2099 - val_loss: 2.8344 - val_accuracy: 0.1753\n",
      "Epoch 11/20\n",
      "107/107 [==============================] - 19s 178ms/step - loss: 2.5828 - accuracy: 0.2300 - val_loss: 2.9087 - val_accuracy: 0.1128\n",
      "Epoch 12/20\n",
      "107/107 [==============================] - 22s 205ms/step - loss: 2.4771 - accuracy: 0.2503 - val_loss: 2.8410 - val_accuracy: 0.1336\n",
      "Epoch 13/20\n",
      "107/107 [==============================] - 21s 194ms/step - loss: 2.3989 - accuracy: 0.2711 - val_loss: 2.7500 - val_accuracy: 0.1662\n",
      "Epoch 14/20\n",
      "107/107 [==============================] - 23s 212ms/step - loss: 2.3299 - accuracy: 0.2914 - val_loss: 2.7609 - val_accuracy: 0.1527\n",
      "Epoch 15/20\n",
      "107/107 [==============================] - 23s 216ms/step - loss: 2.2765 - accuracy: 0.3074 - val_loss: 2.7898 - val_accuracy: 0.1308\n",
      "Epoch 16/20\n",
      "107/107 [==============================] - 23s 214ms/step - loss: 2.1938 - accuracy: 0.3293 - val_loss: 2.6956 - val_accuracy: 0.1389\n",
      "Epoch 17/20\n",
      "107/107 [==============================] - 23s 212ms/step - loss: 2.1271 - accuracy: 0.3539 - val_loss: 2.7525 - val_accuracy: 0.1464\n",
      "Epoch 18/20\n",
      "107/107 [==============================] - 23s 212ms/step - loss: 2.0833 - accuracy: 0.3593 - val_loss: 2.6285 - val_accuracy: 0.1904\n",
      "Epoch 19/20\n",
      "107/107 [==============================] - 23s 213ms/step - loss: 1.9867 - accuracy: 0.3845 - val_loss: 2.8375 - val_accuracy: 0.1555\n",
      "Epoch 20/20\n",
      "107/107 [==============================] - 23s 215ms/step - loss: 1.9679 - accuracy: 0.3887 - val_loss: 2.7543 - val_accuracy: 0.1755\n",
      "Epoch 1/30\n",
      "107/107 [==============================] - 54s 254ms/step - loss: 8.5978 - accuracy: 0.0241 - val_loss: 7.8583 - val_accuracy: 0.0257\n",
      "Epoch 2/30\n",
      "107/107 [==============================] - 24s 221ms/step - loss: 5.8947 - accuracy: 0.0411 - val_loss: 3.5241 - val_accuracy: 0.0330\n",
      "Epoch 3/30\n",
      "107/107 [==============================] - 22s 209ms/step - loss: 3.6506 - accuracy: 0.0446 - val_loss: 3.4169 - val_accuracy: 0.0540\n",
      "Epoch 4/30\n",
      "107/107 [==============================] - 21s 199ms/step - loss: 3.4279 - accuracy: 0.0575 - val_loss: 3.3771 - val_accuracy: 0.0630\n",
      "Epoch 5/30\n",
      "107/107 [==============================] - 22s 203ms/step - loss: 3.3346 - accuracy: 0.0729 - val_loss: 3.3670 - val_accuracy: 0.0631\n",
      "Epoch 6/30\n",
      "107/107 [==============================] - 21s 200ms/step - loss: 3.2260 - accuracy: 0.0928 - val_loss: 3.2759 - val_accuracy: 0.0688\n",
      "Epoch 7/30\n",
      "107/107 [==============================] - 22s 204ms/step - loss: 3.1317 - accuracy: 0.1043 - val_loss: 3.2186 - val_accuracy: 0.0761\n",
      "Epoch 8/30\n",
      "107/107 [==============================] - 22s 204ms/step - loss: 3.0668 - accuracy: 0.1151 - val_loss: 3.1435 - val_accuracy: 0.0828\n",
      "Epoch 9/30\n",
      "107/107 [==============================] - 22s 202ms/step - loss: 2.9936 - accuracy: 0.1270 - val_loss: 3.1323 - val_accuracy: 0.0931\n",
      "Epoch 10/30\n",
      "107/107 [==============================] - 22s 202ms/step - loss: 2.9417 - accuracy: 0.1364 - val_loss: 3.0135 - val_accuracy: 0.1121\n",
      "Epoch 11/30\n",
      "107/107 [==============================] - 22s 203ms/step - loss: 2.8699 - accuracy: 0.1548 - val_loss: 2.9865 - val_accuracy: 0.1306\n",
      "Epoch 12/30\n",
      "107/107 [==============================] - 22s 202ms/step - loss: 2.7785 - accuracy: 0.1658 - val_loss: 2.9534 - val_accuracy: 0.1228\n",
      "Epoch 13/30\n",
      "107/107 [==============================] - 20s 186ms/step - loss: 2.6975 - accuracy: 0.1892 - val_loss: 2.8921 - val_accuracy: 0.1233\n",
      "Epoch 14/30\n",
      "107/107 [==============================] - 21s 192ms/step - loss: 2.6072 - accuracy: 0.2146 - val_loss: 2.8603 - val_accuracy: 0.1397\n",
      "Epoch 15/30\n",
      "107/107 [==============================] - 21s 197ms/step - loss: 2.5243 - accuracy: 0.2449 - val_loss: 2.8537 - val_accuracy: 0.1358\n",
      "Epoch 16/30\n",
      "107/107 [==============================] - 21s 196ms/step - loss: 2.4132 - accuracy: 0.2672 - val_loss: 2.8277 - val_accuracy: 0.1311\n",
      "Epoch 17/30\n",
      "107/107 [==============================] - 21s 194ms/step - loss: 2.3374 - accuracy: 0.2898 - val_loss: 2.7675 - val_accuracy: 0.1380\n",
      "Epoch 18/30\n",
      "107/107 [==============================] - 21s 195ms/step - loss: 2.2559 - accuracy: 0.3159 - val_loss: 2.6296 - val_accuracy: 0.1733\n",
      "Epoch 19/30\n",
      "107/107 [==============================] - 21s 197ms/step - loss: 2.1869 - accuracy: 0.3349 - val_loss: 2.5757 - val_accuracy: 0.1737\n",
      "Epoch 20/30\n",
      "107/107 [==============================] - 21s 197ms/step - loss: 2.1039 - accuracy: 0.3577 - val_loss: 2.5970 - val_accuracy: 0.1661\n",
      "Epoch 21/30\n",
      "107/107 [==============================] - 21s 196ms/step - loss: 2.0389 - accuracy: 0.3671 - val_loss: 2.5201 - val_accuracy: 0.2029\n",
      "Epoch 22/30\n",
      "107/107 [==============================] - 21s 195ms/step - loss: 1.9986 - accuracy: 0.3789 - val_loss: 2.4863 - val_accuracy: 0.2152\n",
      "Epoch 23/30\n",
      "107/107 [==============================] - 21s 197ms/step - loss: 1.9380 - accuracy: 0.3966 - val_loss: 2.4691 - val_accuracy: 0.2036\n",
      "Epoch 24/30\n",
      "107/107 [==============================] - 21s 200ms/step - loss: 1.8949 - accuracy: 0.4139 - val_loss: 2.3428 - val_accuracy: 0.2460\n",
      "Epoch 25/30\n",
      "107/107 [==============================] - 21s 198ms/step - loss: 1.8391 - accuracy: 0.4272 - val_loss: 2.0932 - val_accuracy: 0.3358\n",
      "Epoch 26/30\n",
      "107/107 [==============================] - 22s 202ms/step - loss: 1.8000 - accuracy: 0.4404 - val_loss: 2.1410 - val_accuracy: 0.3249\n",
      "Epoch 27/30\n",
      "107/107 [==============================] - 21s 201ms/step - loss: 1.7532 - accuracy: 0.4556 - val_loss: 2.3527 - val_accuracy: 0.2479\n",
      "Epoch 28/30\n",
      "107/107 [==============================] - 21s 198ms/step - loss: 1.6929 - accuracy: 0.4664 - val_loss: 2.0769 - val_accuracy: 0.3605\n",
      "Epoch 29/30\n",
      "107/107 [==============================] - 21s 201ms/step - loss: 1.6613 - accuracy: 0.4800 - val_loss: 2.2904 - val_accuracy: 0.2745\n",
      "Epoch 30/30\n",
      "107/107 [==============================] - 21s 201ms/step - loss: 1.6418 - accuracy: 0.4931 - val_loss: 2.0305 - val_accuracy: 0.3628\n",
      "Epoch 1/10\n",
      "54/54 [==============================] - 56s 679ms/step - loss: 8.7600 - accuracy: 0.0196 - val_loss: 8.7080 - val_accuracy: 0.0387\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 34s 624ms/step - loss: 8.2317 - accuracy: 0.0337 - val_loss: 7.9319 - val_accuracy: 0.0356\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 33s 620ms/step - loss: 6.2632 - accuracy: 0.0364 - val_loss: 5.1785 - val_accuracy: 0.0387\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 32s 604ms/step - loss: 4.1740 - accuracy: 0.0410 - val_loss: 3.6850 - val_accuracy: 0.0409\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 34s 629ms/step - loss: 3.6179 - accuracy: 0.0394 - val_loss: 3.4795 - val_accuracy: 0.0506\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 34s 638ms/step - loss: 3.4891 - accuracy: 0.0483 - val_loss: 3.3871 - val_accuracy: 0.0494\n",
      "Epoch 7/10\n",
      "54/54 [==============================] - 35s 642ms/step - loss: 3.4088 - accuracy: 0.0576 - val_loss: 3.3228 - val_accuracy: 0.0655\n",
      "Epoch 8/10\n",
      "54/54 [==============================] - 32s 589ms/step - loss: 3.3307 - accuracy: 0.0705 - val_loss: 3.2166 - val_accuracy: 0.0994\n",
      "Epoch 9/10\n",
      "54/54 [==============================] - 34s 636ms/step - loss: 3.2260 - accuracy: 0.0890 - val_loss: 3.1571 - val_accuracy: 0.1006\n",
      "Epoch 10/10\n",
      "54/54 [==============================] - 35s 641ms/step - loss: 3.1493 - accuracy: 0.1072 - val_loss: 3.1063 - val_accuracy: 0.1036\n",
      "Epoch 1/20\n",
      "54/54 [==============================] - 60s 675ms/step - loss: 8.7690 - accuracy: 0.0184 - val_loss: 8.5618 - val_accuracy: 0.0352\n",
      "Epoch 2/20\n",
      "54/54 [==============================] - 33s 617ms/step - loss: 8.2444 - accuracy: 0.0296 - val_loss: 7.3850 - val_accuracy: 0.0387\n",
      "Epoch 3/20\n",
      "54/54 [==============================] - 33s 619ms/step - loss: 6.3000 - accuracy: 0.0370 - val_loss: 5.2844 - val_accuracy: 0.0384\n",
      "Epoch 4/20\n",
      "54/54 [==============================] - 33s 621ms/step - loss: 4.1813 - accuracy: 0.0348 - val_loss: 3.6658 - val_accuracy: 0.0353\n",
      "Epoch 5/20\n",
      "54/54 [==============================] - 33s 615ms/step - loss: 3.6137 - accuracy: 0.0433 - val_loss: 3.4962 - val_accuracy: 0.0356\n",
      "Epoch 6/20\n",
      "54/54 [==============================] - 28s 526ms/step - loss: 3.4708 - accuracy: 0.0522 - val_loss: 3.5655 - val_accuracy: 0.0327\n",
      "Epoch 7/20\n",
      "54/54 [==============================] - 34s 630ms/step - loss: 3.3718 - accuracy: 0.0663 - val_loss: 3.5656 - val_accuracy: 0.0418\n",
      "Epoch 8/20\n",
      "54/54 [==============================] - 33s 617ms/step - loss: 3.2711 - accuracy: 0.0895 - val_loss: 3.6005 - val_accuracy: 0.0418\n",
      "Epoch 9/20\n",
      "54/54 [==============================] - 34s 642ms/step - loss: 3.1712 - accuracy: 0.0999 - val_loss: 3.8518 - val_accuracy: 0.0287\n",
      "Epoch 10/20\n",
      "54/54 [==============================] - 33s 613ms/step - loss: 3.0689 - accuracy: 0.1113 - val_loss: 3.6705 - val_accuracy: 0.0472\n",
      "Epoch 11/20\n",
      "54/54 [==============================] - 35s 643ms/step - loss: 2.9936 - accuracy: 0.1244 - val_loss: 3.6851 - val_accuracy: 0.0459\n",
      "Epoch 12/20\n",
      "54/54 [==============================] - 33s 611ms/step - loss: 2.9058 - accuracy: 0.1331 - val_loss: 3.4318 - val_accuracy: 0.0638\n",
      "Epoch 13/20\n",
      "54/54 [==============================] - 31s 569ms/step - loss: 2.8390 - accuracy: 0.1541 - val_loss: 3.3976 - val_accuracy: 0.0616\n",
      "Epoch 14/20\n",
      "54/54 [==============================] - 33s 607ms/step - loss: 2.7687 - accuracy: 0.1697 - val_loss: 3.1365 - val_accuracy: 0.0908\n",
      "Epoch 15/20\n",
      "54/54 [==============================] - 33s 622ms/step - loss: 2.7066 - accuracy: 0.1860 - val_loss: 3.2357 - val_accuracy: 0.0756\n",
      "Epoch 16/20\n",
      "54/54 [==============================] - 34s 623ms/step - loss: 2.6630 - accuracy: 0.1912 - val_loss: 3.1489 - val_accuracy: 0.0840\n",
      "Epoch 17/20\n",
      "54/54 [==============================] - 33s 618ms/step - loss: 2.5956 - accuracy: 0.2132 - val_loss: 3.0764 - val_accuracy: 0.0977\n",
      "Epoch 18/20\n",
      "54/54 [==============================] - 33s 611ms/step - loss: 2.5549 - accuracy: 0.2183 - val_loss: 3.1855 - val_accuracy: 0.0880\n",
      "Epoch 19/20\n",
      "54/54 [==============================] - 34s 640ms/step - loss: 2.4995 - accuracy: 0.2323 - val_loss: 3.0971 - val_accuracy: 0.0914\n",
      "Epoch 20/20\n",
      "54/54 [==============================] - 35s 641ms/step - loss: 2.4646 - accuracy: 0.2473 - val_loss: 3.1707 - val_accuracy: 0.0969\n",
      "Epoch 1/30\n",
      "54/54 [==============================] - 60s 667ms/step - loss: 8.7653 - accuracy: 0.0183 - val_loss: 8.6092 - val_accuracy: 0.0278\n",
      "Epoch 2/30\n",
      "54/54 [==============================] - 34s 641ms/step - loss: 8.2575 - accuracy: 0.0348 - val_loss: 7.3404 - val_accuracy: 0.0338\n",
      "Epoch 3/30\n",
      "54/54 [==============================] - 35s 650ms/step - loss: 6.3265 - accuracy: 0.0391 - val_loss: 5.5368 - val_accuracy: 0.0338\n",
      "Epoch 4/30\n",
      "54/54 [==============================] - 35s 647ms/step - loss: 4.2024 - accuracy: 0.0439 - val_loss: 3.5305 - val_accuracy: 0.0338\n",
      "Epoch 5/30\n",
      "54/54 [==============================] - 35s 649ms/step - loss: 3.6229 - accuracy: 0.0435 - val_loss: 3.4494 - val_accuracy: 0.0402\n",
      "Epoch 6/30\n",
      "54/54 [==============================] - 37s 679ms/step - loss: 3.4686 - accuracy: 0.0495 - val_loss: 3.3984 - val_accuracy: 0.0516\n",
      "Epoch 7/30\n",
      "54/54 [==============================] - 34s 635ms/step - loss: 3.3959 - accuracy: 0.0598 - val_loss: 3.3474 - val_accuracy: 0.0563\n",
      "Epoch 8/30\n",
      "54/54 [==============================] - 32s 587ms/step - loss: 3.3273 - accuracy: 0.0701 - val_loss: 3.3237 - val_accuracy: 0.0566\n",
      "Epoch 9/30\n",
      "54/54 [==============================] - 35s 644ms/step - loss: 3.2655 - accuracy: 0.0840 - val_loss: 3.2341 - val_accuracy: 0.0744\n",
      "Epoch 10/30\n",
      "54/54 [==============================] - 34s 640ms/step - loss: 3.2030 - accuracy: 0.0989 - val_loss: 3.1895 - val_accuracy: 0.0796\n",
      "Epoch 11/30\n",
      "54/54 [==============================] - 35s 643ms/step - loss: 3.1375 - accuracy: 0.1075 - val_loss: 3.0922 - val_accuracy: 0.0805\n",
      "Epoch 12/30\n",
      "54/54 [==============================] - 34s 633ms/step - loss: 3.0388 - accuracy: 0.1257 - val_loss: 3.1110 - val_accuracy: 0.0759\n",
      "Epoch 13/30\n",
      "54/54 [==============================] - 34s 631ms/step - loss: 2.9448 - accuracy: 0.1378 - val_loss: 3.0002 - val_accuracy: 0.1106\n",
      "Epoch 14/30\n",
      "54/54 [==============================] - 35s 642ms/step - loss: 2.8690 - accuracy: 0.1586 - val_loss: 2.9983 - val_accuracy: 0.1037\n",
      "Epoch 15/30\n",
      "54/54 [==============================] - 35s 641ms/step - loss: 2.8047 - accuracy: 0.1697 - val_loss: 2.9431 - val_accuracy: 0.1256\n",
      "Epoch 16/30\n",
      "54/54 [==============================] - 34s 641ms/step - loss: 2.7499 - accuracy: 0.1848 - val_loss: 2.8707 - val_accuracy: 0.1450\n",
      "Epoch 17/30\n",
      "54/54 [==============================] - 34s 637ms/step - loss: 2.6594 - accuracy: 0.1996 - val_loss: 2.8426 - val_accuracy: 0.1531\n",
      "Epoch 18/30\n",
      "54/54 [==============================] - 28s 524ms/step - loss: 2.6205 - accuracy: 0.2155 - val_loss: 2.7507 - val_accuracy: 0.1615\n",
      "Epoch 19/30\n",
      "54/54 [==============================] - 34s 641ms/step - loss: 2.5543 - accuracy: 0.2257 - val_loss: 2.8442 - val_accuracy: 0.1328\n",
      "Epoch 20/30\n",
      "54/54 [==============================] - 35s 648ms/step - loss: 2.4846 - accuracy: 0.2385 - val_loss: 2.8307 - val_accuracy: 0.1331\n",
      "Epoch 21/30\n",
      "54/54 [==============================] - 35s 653ms/step - loss: 2.4241 - accuracy: 0.2691 - val_loss: 2.8229 - val_accuracy: 0.1133\n",
      "Epoch 22/30\n",
      "54/54 [==============================] - 35s 642ms/step - loss: 2.3801 - accuracy: 0.2755 - val_loss: 2.5698 - val_accuracy: 0.1793\n",
      "Epoch 23/30\n",
      "54/54 [==============================] - 33s 605ms/step - loss: 2.3037 - accuracy: 0.2955 - val_loss: 2.6911 - val_accuracy: 0.1671\n",
      "Epoch 24/30\n",
      "54/54 [==============================] - 35s 648ms/step - loss: 2.2371 - accuracy: 0.3122 - val_loss: 2.6304 - val_accuracy: 0.1808\n",
      "Epoch 25/30\n",
      "54/54 [==============================] - 35s 656ms/step - loss: 2.1728 - accuracy: 0.3282 - val_loss: 2.6417 - val_accuracy: 0.1883\n",
      "Epoch 26/30\n",
      "54/54 [==============================] - 35s 646ms/step - loss: 2.1090 - accuracy: 0.3538 - val_loss: 2.4893 - val_accuracy: 0.2286\n",
      "Epoch 27/30\n",
      "54/54 [==============================] - 35s 651ms/step - loss: 2.0695 - accuracy: 0.3715 - val_loss: 2.5734 - val_accuracy: 0.1898\n",
      "Epoch 28/30\n",
      "54/54 [==============================] - 33s 621ms/step - loss: 2.0286 - accuracy: 0.3823 - val_loss: 2.4504 - val_accuracy: 0.2439\n",
      "Epoch 29/30\n",
      "54/54 [==============================] - 36s 671ms/step - loss: 1.9488 - accuracy: 0.3937 - val_loss: 2.4381 - val_accuracy: 0.1945\n",
      "Epoch 30/30\n",
      "54/54 [==============================] - 36s 672ms/step - loss: 1.9157 - accuracy: 0.4180 - val_loss: 2.4646 - val_accuracy: 0.2257\n",
      "Epoch 1/10\n",
      "214/214 [==============================] - 76s 195ms/step - loss: 7.9708 - accuracy: 0.0263 - val_loss: 4.4891 - val_accuracy: 0.0452\n",
      "Epoch 2/10\n",
      "214/214 [==============================] - 42s 199ms/step - loss: 4.0390 - accuracy: 0.0350 - val_loss: 3.4266 - val_accuracy: 0.0350\n",
      "Epoch 3/10\n",
      "214/214 [==============================] - 43s 201ms/step - loss: 3.5220 - accuracy: 0.0394 - val_loss: 3.4100 - val_accuracy: 0.0366\n",
      "Epoch 4/10\n",
      "214/214 [==============================] - 40s 186ms/step - loss: 3.4797 - accuracy: 0.0358 - val_loss: 3.4283 - val_accuracy: 0.0332\n",
      "Epoch 5/10\n",
      "214/214 [==============================] - 41s 193ms/step - loss: 3.4468 - accuracy: 0.0364 - val_loss: 3.4066 - val_accuracy: 0.0374\n",
      "Epoch 6/10\n",
      "214/214 [==============================] - 41s 192ms/step - loss: 3.4451 - accuracy: 0.0307 - val_loss: 3.4160 - val_accuracy: 0.0382\n",
      "Epoch 7/10\n",
      "214/214 [==============================] - 42s 194ms/step - loss: 3.4344 - accuracy: 0.0360 - val_loss: 3.4314 - val_accuracy: 0.0382\n",
      "Epoch 8/10\n",
      "214/214 [==============================] - 43s 202ms/step - loss: 3.4365 - accuracy: 0.0364 - val_loss: 3.4169 - val_accuracy: 0.0371\n",
      "Epoch 9/10\n",
      "214/214 [==============================] - 42s 194ms/step - loss: 3.4355 - accuracy: 0.0356 - val_loss: 3.4178 - val_accuracy: 0.0396\n",
      "Epoch 10/10\n",
      "214/214 [==============================] - 41s 193ms/step - loss: 3.4233 - accuracy: 0.0361 - val_loss: 3.4170 - val_accuracy: 0.0359\n",
      "Epoch 1/20\n",
      "214/214 [==============================] - 76s 228ms/step - loss: 7.9263 - accuracy: 0.0271 - val_loss: 5.1164 - val_accuracy: 0.0382\n",
      "Epoch 2/20\n",
      "214/214 [==============================] - 44s 207ms/step - loss: 4.0093 - accuracy: 0.0372 - val_loss: 3.4348 - val_accuracy: 0.0363\n",
      "Epoch 3/20\n",
      "214/214 [==============================] - 42s 197ms/step - loss: 3.5248 - accuracy: 0.0361 - val_loss: 3.4568 - val_accuracy: 0.0343\n",
      "Epoch 4/20\n",
      "214/214 [==============================] - 39s 182ms/step - loss: 3.4642 - accuracy: 0.0357 - val_loss: 3.4502 - val_accuracy: 0.0418\n",
      "Epoch 5/20\n",
      "214/214 [==============================] - 39s 183ms/step - loss: 3.4487 - accuracy: 0.0414 - val_loss: 3.4344 - val_accuracy: 0.0382\n",
      "Epoch 6/20\n",
      "214/214 [==============================] - 40s 188ms/step - loss: 3.4396 - accuracy: 0.0420 - val_loss: 3.4585 - val_accuracy: 0.0349\n",
      "Epoch 7/20\n",
      "214/214 [==============================] - 41s 190ms/step - loss: 3.4359 - accuracy: 0.0392 - val_loss: 3.4653 - val_accuracy: 0.0382\n",
      "Epoch 8/20\n",
      "214/214 [==============================] - 42s 196ms/step - loss: 3.4370 - accuracy: 0.0332 - val_loss: 3.4354 - val_accuracy: 0.0382\n",
      "Epoch 9/20\n",
      "214/214 [==============================] - 41s 191ms/step - loss: 3.4342 - accuracy: 0.0395 - val_loss: 3.4204 - val_accuracy: 0.0478\n",
      "Epoch 10/20\n",
      "214/214 [==============================] - 38s 178ms/step - loss: 3.4341 - accuracy: 0.0342 - val_loss: 3.4171 - val_accuracy: 0.0381\n",
      "Epoch 11/20\n",
      "214/214 [==============================] - 41s 190ms/step - loss: 3.4279 - accuracy: 0.0385 - val_loss: 3.4241 - val_accuracy: 0.0382\n",
      "Epoch 12/20\n",
      "214/214 [==============================] - 40s 188ms/step - loss: 3.4282 - accuracy: 0.0364 - val_loss: 3.4352 - val_accuracy: 0.0338\n",
      "Epoch 13/20\n",
      "214/214 [==============================] - 39s 184ms/step - loss: 3.4234 - accuracy: 0.0350 - val_loss: 3.4437 - val_accuracy: 0.0338\n",
      "Epoch 14/20\n",
      "214/214 [==============================] - 39s 181ms/step - loss: 3.4169 - accuracy: 0.0392 - val_loss: 3.4327 - val_accuracy: 0.0382\n",
      "Epoch 15/20\n",
      "214/214 [==============================] - 39s 182ms/step - loss: 3.4260 - accuracy: 0.0375 - val_loss: 3.4605 - val_accuracy: 0.0382\n",
      "Epoch 16/20\n",
      "214/214 [==============================] - 40s 185ms/step - loss: 3.4185 - accuracy: 0.0399 - val_loss: 3.4297 - val_accuracy: 0.0359\n",
      "Epoch 17/20\n",
      "214/214 [==============================] - 41s 193ms/step - loss: 3.4229 - accuracy: 0.0358 - val_loss: 3.4102 - val_accuracy: 0.0382\n",
      "Epoch 18/20\n",
      "214/214 [==============================] - 40s 185ms/step - loss: 3.4082 - accuracy: 0.0380 - val_loss: 3.4431 - val_accuracy: 0.0382\n",
      "Epoch 19/20\n",
      "213/214 [============================>.] - ETA: 0s - loss: 3.4122 - accuracy: 0.0359"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dropout, Dense, Bidirectional, TimeDistributed, BatchNormalization, Conv1D, MaxPooling1D, Flatten, GlobalMaxPooling1D\n",
    "\n",
    "results = pd.DataFrame(columns=['lstm_units', 'dropout_rate', 'epoch', 'batch', 'loss', 'loss_max', 'accuracy', 'accuracy_max', 'val_loss', 'val_loss_max', 'val_accuracy', 'val_accuracy_max'])\n",
    "\n",
    "for gru_units in [64, 128, 256]:\n",
    "    for dropout_rate in [0.2, 0.4, 0.6]:\n",
    "        for batch_size in [32, 64, 128]:\n",
    "            for epochs in [10, 20, 30]:\n",
    "                num_classes = len(y_train_encoded)  # Number of unique classes in your dataset\n",
    "                input_shape = (39, 44)\n",
    "\n",
    "                model = Sequential([\n",
    "                    Conv1D(filters=128, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "                    BatchNormalization(),\n",
    "                    MaxPooling1D(pool_size=2),\n",
    "                    Dropout(dropout_rate),\n",
    "                    Bidirectional(GRU(gru_units, return_sequences=True)),\n",
    "                    BatchNormalization(),\n",
    "                    Dropout(dropout_rate),\n",
    "                    Bidirectional(GRU(gru_units, return_sequences=True)),\n",
    "                    BatchNormalization(),\n",
    "                    Dropout(dropout_rate),\n",
    "                    GRU(gru_units, return_sequences=True),\n",
    "                    BatchNormalization(),\n",
    "                    Dropout(dropout_rate),\n",
    "                    GRU(gru_units, return_sequences=True),\n",
    "                    BatchNormalization(),\n",
    "                    Dropout(dropout_rate),\n",
    "                    TimeDistributed(Dense(256, activation='relu')),\n",
    "                    BatchNormalization(),\n",
    "                    Dropout(dropout_rate),\n",
    "                    TimeDistributed(Dense(128, activation='relu')),\n",
    "                    BatchNormalization(),\n",
    "                    Dropout(dropout_rate),\n",
    "                    TimeDistributed(Dense(64, activation='relu')),\n",
    "                    BatchNormalization(),\n",
    "                    Dropout(dropout_rate),\n",
    "                    GlobalMaxPooling1D(),\n",
    "                    Dense(512, activation='relu'),\n",
    "                    BatchNormalization(),\n",
    "                    Dropout(dropout_rate),\n",
    "                    Dense(256, activation='relu'),\n",
    "                    BatchNormalization(),\n",
    "                    Dropout(dropout_rate),\n",
    "                    Dense(128, activation='relu'),\n",
    "                    BatchNormalization(),\n",
    "                    Dropout(dropout_rate),\n",
    "                    Dense(num_classes, activation='softmax')\n",
    "                ])\n",
    "\n",
    "                # Compile the model\n",
    "                model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "                # Train the model with your training set and validate it with your validation set\n",
    "                epochs = epochs\n",
    "                batch_size = batch_size\n",
    "                history = model.fit(X_train, y_train_encoded, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val_encoded))\n",
    "\n",
    "                results = np.concatenate((results, pd.DataFrame([[gru_units, dropout_rate, epochs, batch_size, history.history['loss'][-1], history.history['loss'], history.history['accuracy'][-1], history.history['accuracy'], history.history['val_loss'][-1], history.history['val_loss'], history.history['val_accuracy'][-1], history.history['val_accuracy']]], \n",
    "                                                                    columns=['lstm_units', 'dropout_rate', 'epoch', 'batch', 'loss', 'loss_max', 'accuracy', 'accuracy_max', 'val_loss', 'val_loss_max', 'val_accuracy', 'val_accuracy_max'])), axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 37, 128)           17024     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 37, 128)          512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 18, 128)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 18, 128)           0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 18, 256)          198144    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 18, 256)          1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 18, 256)           0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 18, 256)          296448    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 18, 256)          1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 18, 256)           0         \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 18, 128)           148224    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 18, 128)          512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 18, 128)           0         \n",
      "                                                                 \n",
      " gru_3 (GRU)                 (None, 18, 128)           99072     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 18, 128)          512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 18, 128)           0         \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 18, 256)          33024     \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 18, 256)          1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 18, 256)           0         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 18, 128)          32896     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 18, 128)          512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 18, 128)           0         \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 18, 64)           8256      \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 18, 64)           256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 18, 64)            0         \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 64)               0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 512)               33280     \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,040,842\n",
      "Trainable params: 1,036,362\n",
      "Non-trainable params: 4,480\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "opt = Adam(lr=0.0001, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_pickle('results\\\\model_gru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
