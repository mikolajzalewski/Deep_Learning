{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "# num_classes = 10\n",
    "# learning_rate = 0.001\n",
    "# batch_size = 64\n",
    "# num_epochs = 5\n",
    "# optimizer = optim.Adam\n",
    "# activation_func = nn.ReLU()\n",
    "# dropout_rate = 0.1\n",
    "# no_neurons = 128\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# kernel_size=3\n",
    "# stride=1\n",
    "# padding=1\n",
    "# number_of_filters0=32\n",
    "# number_of_filters1=32\n",
    "# length_of_input0=32\n",
    "\n",
    "\n",
    "\n",
    "class CNN_3_class(nn.Module):\n",
    "    def __init__(self, num_classes = 10\n",
    "                    ,kernel_size=3\n",
    "                    ,stride=1\n",
    "                    ,padding=1\n",
    "                    ,number_of_filters0=32\n",
    "                    ,number_of_filters1=32\n",
    "                    ,length_of_input0=32\n",
    "                    ,no_neurons = 128):\n",
    "        super(CNN_3_class, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, number_of_filters0, kernel_size, stride, padding)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        length_of_input1 = self.Conv2d_output_size(length_of_input0, kernel_size, stride, padding)/2\n",
    "        self.conv2 = nn.Conv2d(number_of_filters0, number_of_filters1, kernel_size, stride, padding)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        length_of_input2 = self.Conv2d_output_size(length_of_input1, kernel_size, stride, padding)/2\n",
    "        self.fc1 = nn.Linear(int(number_of_filters1*length_of_input2*length_of_input2), no_neurons)\n",
    "        self.fc2 = nn.Linear(no_neurons, num_classes)\n",
    "        # parameters\n",
    "        self.num_classes = num_classes\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.number_of_filters0 = number_of_filters0\n",
    "        self.number_of_filters1 = number_of_filters1\n",
    "        self.length_of_input0 = length_of_input0\n",
    "        self.no_neurons = no_neurons\n",
    "\n",
    "\n",
    "    def Conv2d_output_size(self, w, k, s, p):\n",
    "        '''\n",
    "        w - width of input image\n",
    "        k - kernel size\n",
    "        s - stride\n",
    "        p - padding\n",
    "        '''\n",
    "        return (w - k + 2 * p) / s + 1\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(torch.relu(self.conv1(x)))\n",
    "        length_of_input1 = self.Conv2d_output_size(self.length_of_input0, self.kernel_size, self.stride, self.padding)/2\n",
    "        x = self.pool2(torch.relu(self.conv2(x)))\n",
    "        length_of_input2 = self.Conv2d_output_size(length_of_input1, self.kernel_size, self.stride, self.padding)/2\n",
    "        x = x.view(-1, int(self.number_of_filters1*length_of_input2*length_of_input2))\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def train_step(self, data, optimizer, criterion):\n",
    "        x, y = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = self(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        accuracy = (logits.argmax(dim=1) == y).float().mean()\n",
    "\n",
    "        return {'loss': loss, 'accuracy': accuracy}\n",
    "\n",
    "    def test_step(self, data, criterion):\n",
    "        x, y = data\n",
    "\n",
    "        logits = self(x)\n",
    "        loss = criterion(logits, y)\n",
    "        accuracy = (logits.argmax(dim=1) == y).float().mean()\n",
    "\n",
    "        return {'loss': loss, 'accuracy': accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_loader = datasets.val_loader\n",
    "train_loader = datasets.train_loader\n",
    "augmentation1_loader = datasets.augmentation1_loader\n",
    "augmentation2_loader = datasets.augmentation2_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Załaduj dane CIFAR10\n",
    "transform = transforms.Compose([transforms.Resize(256),\n",
    "                                transforms.CenterCrop(224),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                     std=[0.229, 0.224, 0.225])])\n",
    "cifar10_train = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "cifar10_test = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "# Utwórz DataLoader dla danych trenujących i testowych\n",
    "trainloader = torch.utils.data.DataLoader(cifar10_train, batch_size=4, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(cifar10_test, batch_size=4, shuffle=False)\n",
    "\n",
    "# Załaduj model AlexNet z wytrenowanymi wagami na zbiorze ImageNet\n",
    "model = models.alexnet(pretrained=True)\n",
    "\n",
    "# Zmień rozmiar ostatniej warstwy klasyfikatora na 10 wyjść\n",
    "num_features = model.classifier[6].in_features\n",
    "model.classifier[6] = nn.Linear(num_features, 10)\n",
    "\n",
    "# Przenieś model na kartę graficzną, jeśli jest dostępna\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Zdefiniuj funkcję straty i optymalizator\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Trenuj model\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(\"Epoch %d, loss: %.3f\" % (epoch + 1, running_loss / len(trainloader)))\n",
    "\n",
    "# Oblicz metryki na danych testowych\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in testloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Oblicz dokładność i inne metryki\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average=\"macro\")\n",
    "recall = recall_score(y_true, y_pred, average=\"macro\")\n",
    "f1 = f1_score(y_true, y_pred, average=\"macro\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: %.3f\" % accuracy)\n",
    "print(\"Precision: %.3f\" % precision)\n",
    "print(\"Recall: %.3f\" % recall)\n",
    "print(\"F1 score: %.3f\" % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 25/1250 [00:02<02:20,  8.73it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mikol\\OneDrive\\Desktop\\Deep_Learning\\CNN.ipynb Cell 4\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mikol/OneDrive/Desktop/Deep_Learning/CNN.ipynb#W3sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m train_accuracies \u001b[39m=\u001b[39m []\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mikol/OneDrive/Desktop/Deep_Learning/CNN.ipynb#W3sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m tqdm(train_loader):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mikol/OneDrive/Desktop/Deep_Learning/CNN.ipynb#W3sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     results \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain_step(data, optimizer, criterion)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mikol/OneDrive/Desktop/Deep_Learning/CNN.ipynb#W3sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     train_losses\u001b[39m.\u001b[39mappend(results[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mitem())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mikol/OneDrive/Desktop/Deep_Learning/CNN.ipynb#W3sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     train_accuracies\u001b[39m.\u001b[39mappend(results[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mitem())\n",
      "\u001b[1;32mc:\\Users\\mikol\\OneDrive\\Desktop\\Deep_Learning\\CNN.ipynb Cell 4\u001b[0m in \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mikol/OneDrive/Desktop/Deep_Learning/CNN.ipynb#W3sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m x, y \u001b[39m=\u001b[39m data\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mikol/OneDrive/Desktop/Deep_Learning/CNN.ipynb#W3sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mikol/OneDrive/Desktop/Deep_Learning/CNN.ipynb#W3sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mikol/OneDrive/Desktop/Deep_Learning/CNN.ipynb#W3sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(logits, y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mikol/OneDrive/Desktop/Deep_Learning/CNN.ipynb#W3sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\mikol\\OneDrive\\Desktop\\Deep_Learning\\CNN.ipynb Cell 4\u001b[0m in \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mikol/OneDrive/Desktop/Deep_Learning/CNN.ipynb#W3sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mikol/OneDrive/Desktop/Deep_Learning/CNN.ipynb#W3sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool1(torch\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mikol/OneDrive/Desktop/Deep_Learning/CNN.ipynb#W3sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     length_of_input1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mConv2d_output_size(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength_of_input0, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding)\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mikol/OneDrive/Desktop/Deep_Learning/CNN.ipynb#W3sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool2(torch\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x)))\n",
      "File \u001b[1;32mc:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "# batch_size = 64 TEGO NIE UZYWAMY A JESLI CHCEMY TO W LOADERZE TRZEBA DODAC\n",
    "num_epochs = 2\n",
    "optimizer = optim.Adam\n",
    "activation_func = nn.ReLU()\n",
    "# dropout_rate = 0.1\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Create model, criterion, and optimizer\n",
    "model = CNN_3_class(num_classes = 10,\n",
    "                    kernel_size=3,\n",
    "                    stride=1,\n",
    "                    padding=1,\n",
    "                    number_of_filters0=64,\n",
    "                    number_of_filters1=64,\n",
    "                    length_of_input0=32,\n",
    "                    no_neurons = 16)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "epochs = num_epochs\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch {epoch+1}/{epochs}')\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    for data in tqdm(train_loader):\n",
    "        results = model.train_step(data, optimizer, criterion)\n",
    "        train_losses.append(results['loss'].item())\n",
    "        train_accuracies.append(results['accuracy'].item())\n",
    "\n",
    "    # Calculate average training loss and accuracy for the epoch\n",
    "    avg_train_loss = sum(train_losses) / len(train_losses)\n",
    "    avg_train_accuracy = sum(train_accuracies) / len(train_accuracies)\n",
    "    print(f'Train loss: {avg_train_loss:.4f}, Train accuracy: {avg_train_accuracy:.4f}')\n",
    "\n",
    "    # Test the model\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader):\n",
    "            results = model.test_step(data, criterion)\n",
    "            val_losses.append(results['loss'].item())\n",
    "            val_accuracies.append(results['accuracy'].item())\n",
    "\n",
    "    # Calculate average test loss and accuracy for the epoch\n",
    "    avg_validation_loss = sum(val_losses) / len(val_losses)\n",
    "    avg_validation_accuracy = sum(val_accuracies) / len(val_accuracies)\n",
    "    print(f'Validation loss: {avg_validation_loss:.4f}, Validation accuracy: {avg_validation_accuracy:.4f}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN from article about weighted random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm import tqdm\n",
    "\n",
    "class MyCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=736, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=736, out_channels=508, kernel_size=3, padding=1)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=508, out_channels=664, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=664, out_channels=916, kernel_size=3, padding=1)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv5 = nn.Conv2d(in_channels=916, out_channels=186, kernel_size=3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(in_channels=186, out_channels=352, kernel_size=3, padding=1)\n",
    "        self.linear = nn.Linear(in_features=22528, out_features=1229)\n",
    "        self.output = nn.Linear(in_features=1229, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv3(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.conv4(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.conv5(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.conv6(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "    def train_step(self, data, optimizer, criterion):\n",
    "        x, y = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = self(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        accuracy = (logits.argmax(dim=1) == y).float().mean()\n",
    "\n",
    "        return {'loss': loss, 'accuracy': accuracy}\n",
    "\n",
    "    def test_step(self, data, criterion):\n",
    "        x, y = data\n",
    "\n",
    "        logits = self(x)\n",
    "        loss = criterion(logits, y)\n",
    "        accuracy = (logits.argmax(dim=1) == y).float().mean()\n",
    "\n",
    "        return {'loss': loss, 'accuracy': accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x177b2576e90>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "import torch\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Pillow\n",
    "from PIL import Image\n",
    "img = Image.open(\"Cifar10/val/1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "transform = transforms.Compose([            #[1]\n",
    " transforms.Resize(256),                    #[2]\n",
    " transforms.CenterCrop(224),                #[3]\n",
    " transforms.ToTensor(),                     #[4]\n",
    " transforms.Normalize(                      #[5]\n",
    " mean=[0.485, 0.456, 0.406],                #[6]\n",
    " std=[0.229, 0.224, 0.225]                  #[7]\n",
    " )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_t = transform(img)\n",
    "batch_t = torch.unsqueeze(img_t, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "\t\n",
    "alexnet.eval()\n",
    "\t\n",
    "out = alexnet(batch_t)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to C:\\Users\\mikol/.cache\\torch\\hub\\checkpoints\\resnet101-63fe2227.pth\n",
      "100%|██████████| 171M/171M [00:03<00:00, 46.5MB/s] \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mikol\\OneDrive\\Desktop\\Deep_Learning\\CNN.ipynb Cell 13\u001b[0m in \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mikol/OneDrive/Desktop/Deep_Learning/CNN.ipynb#X21sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m _, indices \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msort(out, descending\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mikol/OneDrive/Desktop/Deep_Learning/CNN.ipynb#X21sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m percentage \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39msoftmax(out, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mikol/OneDrive/Desktop/Deep_Learning/CNN.ipynb#X21sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m [(labels[idx], percentage[idx]\u001b[39m.\u001b[39mitem()) \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m indices[\u001b[39m0\u001b[39m][:\u001b[39m5\u001b[39m]]\n",
      "\u001b[1;32mc:\\Users\\mikol\\OneDrive\\Desktop\\Deep_Learning\\CNN.ipynb Cell 13\u001b[0m in \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mikol/OneDrive/Desktop/Deep_Learning/CNN.ipynb#X21sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m _, indices \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msort(out, descending\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mikol/OneDrive/Desktop/Deep_Learning/CNN.ipynb#X21sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m percentage \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39msoftmax(out, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mikol/OneDrive/Desktop/Deep_Learning/CNN.ipynb#X21sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m [(labels[idx], percentage[idx]\u001b[39m.\u001b[39mitem()) \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m indices[\u001b[39m0\u001b[39m][:\u001b[39m5\u001b[39m]]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "# First, load the model\n",
    "resnet = models.resnet101(pretrained=True)\n",
    " \n",
    "# Second, put the network in eval mode\n",
    "resnet.eval()\n",
    " \n",
    "# Third, carry out model inference\n",
    "out = resnet(batch_t)\n",
    " \n",
    "# Forth, print the top 5 classes predicted by the model\n",
    "_, indices = torch.sort(out, descending=True)\n",
    "percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
    "[(labels[idx], percentage[idx].item()) for idx in indices[0][:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'imagenet_classes.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mikol\\OneDrive\\Desktop\\Deep_Learning\\CNN.ipynb Cell 13\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mikol/OneDrive/Desktop/Deep_Learning/CNN.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mimagenet_classes.txt\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mikol/OneDrive/Desktop/Deep_Learning/CNN.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m   classes \u001b[39m=\u001b[39m [line\u001b[39m.\u001b[39mstrip() \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m f\u001b[39m.\u001b[39mreadlines()]\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'imagenet_classes.txt'"
     ]
    }
   ],
   "source": [
    "with open('imagenet_classes.txt') as f:\n",
    "  classes = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mikol\\OneDrive\\Desktop\\Deep_Learning\\CNN.ipynb Cell 14\u001b[0m in \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mikol/OneDrive/Desktop/Deep_Learning/CNN.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m _, index \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(out, \u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mikol/OneDrive/Desktop/Deep_Learning/CNN.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m percentage \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39msoftmax(out, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mikol/OneDrive/Desktop/Deep_Learning/CNN.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(labels[index[\u001b[39m0\u001b[39m]], percentage[index[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39mitem())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "_, index = torch.max(out, 1)\n",
    " \n",
    "percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
    " \n",
    "print(labels[index[0]], percentage[index[0]].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
