{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm import tqdm\n",
    "from func import *\n",
    "\n",
    "# Hyperparameters\n",
    "in_channel = 3\n",
    "num_classes = 10\n",
    "\n",
    "# TO DO\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 5\n",
    "\n",
    "optimizer: dict\n",
    "activation_func: dict\n",
    "dropout_rate = 0.1\n",
    "no_neurons = 100\n",
    "\n",
    "# class with typical neural network - no convolutional layers\n",
    "class NN_1_class(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(NN_1_class, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def train_step(self, data, optimizer, criterion):\n",
    "        x, y = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = self(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        accuracy = (logits.argmax(dim=1) == y).float().mean()\n",
    "\n",
    "        return {'loss': loss, 'accuracy': accuracy}\n",
    "\n",
    "    def test_step(self, data, criterion):\n",
    "        x, y = data\n",
    "\n",
    "        logits = self(x)\n",
    "        loss = criterion(logits, y)\n",
    "        accuracy = (logits.argmax(dim=1) == y).float().mean()\n",
    "\n",
    "        return {'loss': loss, 'accuracy': accuracy}\n",
    "\n",
    "\n",
    "    \n",
    "# https://towardsdatascience.com/deep-learning-with-cifar-10-image-classification-64ab92110d79\n",
    "class CNN_2_class(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_2_class, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(64*5*5, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(torch.relu(self.conv1(x)))\n",
    "        x = self.pool2(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64*5*5)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def train_step(self, data, optimizer, criterion):\n",
    "        x, y = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = self(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        accuracy = (logits.argmax(dim=1) == y).float().mean()\n",
    "\n",
    "        return {'loss': loss, 'accuracy': accuracy}\n",
    "\n",
    "    def test_step(self, data, criterion):\n",
    "        x, y = data\n",
    "\n",
    "        logits = self(x)\n",
    "        loss = criterion(logits, y)\n",
    "        accuracy = (logits.argmax(dim=1) == y).float().mean()\n",
    "\n",
    "        return {'loss': loss, 'accuracy': accuracy}\n",
    "    \n",
    "# https://adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks-Part-2/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 5\n",
    "optimizer = optim.Adam\n",
    "activation_func = nn.ReLU()\n",
    "dropout_rate = 0.1\n",
    "no_neurons = 128\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "kernel_size=3\n",
    "stride=1\n",
    "padding=1\n",
    "number_of_filters=32\n",
    "length_of_input0=32\n",
    "\n",
    "def Conv2d_output_size(w, k, s, p):\n",
    "    '''\n",
    "    w - width of input image\n",
    "    k - kernel size\n",
    "    s - stride\n",
    "    p - padding\n",
    "    '''\n",
    "    return (w - k + 2 * p) / s + 1\n",
    "\n",
    "class CNN_3_class(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN_3_class, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, number_of_filters, kernel_size, stride, padding)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        length_of_input1 = Conv2d_output_size(length_of_input0, kernel_size, stride, padding)/2\n",
    "        self.conv2 = nn.Conv2d(number_of_filters, number_of_filters, kernel_size, stride, padding)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        length_of_input2 = Conv2d_output_size(length_of_input1, kernel_size, stride, padding)/2\n",
    "        self.fc1 = nn.Linear(int(number_of_filters*length_of_input2*length_of_input2), no_neurons)\n",
    "        self.fc2 = nn.Linear(no_neurons, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(torch.relu(self.conv1(x)))\n",
    "        length_of_input1 = Conv2d_output_size(length_of_input0, kernel_size, stride, padding)/2\n",
    "        x = self.pool2(torch.relu(self.conv2(x)))\n",
    "        length_of_input2 = Conv2d_output_size(length_of_input1, kernel_size, stride, padding)/2\n",
    "        x = x.view(-1, int(number_of_filters*length_of_input2*length_of_input2))\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def train_step(self, data, optimizer, criterion):\n",
    "        x, y = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = self(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        accuracy = (logits.argmax(dim=1) == y).float().mean()\n",
    "\n",
    "        return {'loss': loss, 'accuracy': accuracy}\n",
    "\n",
    "    def test_step(self, data, criterion):\n",
    "        x, y = data\n",
    "\n",
    "        logits = self(x)\n",
    "        loss = criterion(logits, y)\n",
    "        accuracy = (logits.argmax(dim=1) == y).float().mean()\n",
    "\n",
    "        return {'loss': loss, 'accuracy': accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class CNN_3_class(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CNN_3_class, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "#         self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "#         self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.fc1 = nn.Linear(64*8*8, 64*8*8)\n",
    "#         self.fc2 = nn.Linear(64*8*8, 10)\n",
    "#         # self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "#         # self.pool1 = nn.MaxPool2d(2)\n",
    "#         # self.conv3 = nn.Conv2d(64, 128, 3)\n",
    "#         # self.pool2 = nn.MaxPool2d(2)\n",
    "#         # self.fc1 = nn.Linear(128*5*5, 128)\n",
    "#         # self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool1(torch.relu(self.conv1(x)))\n",
    "#         x = self.pool2(torch.relu(self.conv2(x)))\n",
    "#         x = x.view(-1, 64*8*8)\n",
    "#         x = torch.relu(self.fc1(x))\n",
    "#         x = self.fc2(x)\n",
    "#         return x\n",
    "\n",
    "#     def train_step(self, data, optimizer, criterion):\n",
    "#         x, y = data\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         logits = self(x)\n",
    "#         loss = criterion(logits, y)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         accuracy = (logits.argmax(dim=1) == y).float().mean()\n",
    "\n",
    "#         return {'loss': loss, 'accuracy': accuracy}\n",
    "\n",
    "#     def test_step(self, data, criterion):\n",
    "#         x, y = data\n",
    "\n",
    "#         logits = self(x)\n",
    "#         loss = criterion(logits, y)\n",
    "#         accuracy = (logits.argmax(dim=1) == y).float().mean()\n",
    "\n",
    "#         return {'loss': loss, 'accuracy': accuracy}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alexnet nn trained on cifar10\n",
    "# https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "class CNN_4_class(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_4_class, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.conv2 = nn.Conv2d(64, 192, kernel_size=5, padding=2)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.conv3 = nn.Conv2d(192, 384, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(384, 256, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.fc1 = nn.Linear(256*6*6, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(torch.relu(self.conv1(x)))\n",
    "        x = self.pool2(torch.relu(self.conv2(x)))\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = torch.relu(self.conv4(x))\n",
    "        x = self.pool3(torch.relu(self.conv5(x)))\n",
    "        x = x.view(-1, 256*6*6)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def train_step(self, data, optimizer, criterion):\n",
    "        x, y = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = self(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        accuracy = (logits.argmax(dim=1) == y).float().mean()\n",
    "\n",
    "        return {'loss': loss, 'accuracy': accuracy}\n",
    "\n",
    "    def test_step(self, data, criterion):\n",
    "        x, y = data\n",
    "\n",
    "        logits = self(x)\n",
    "        loss = criterion(logits, y)\n",
    "        accuracy = (logits.argmax(dim=1) == y).float().mean()\n",
    "\n",
    "        return {'loss': loss, 'accuracy': accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to directory containing training images\n",
    "ROOT_DIR = 'Cifar10\\\\train'\n",
    "# Path to Dataframe with labels for training data\n",
    "LABELS = 'Cifar10\\\\trainLabels.csv'\n",
    "# All unique labels\n",
    "CLASS_NAMES = ['frog', 'truck', 'deer', 'automobile', 'bird', 'horse', 'ship', 'cat', 'dog',\n",
    " 'airplane']\n",
    "# Dictionary for encoding classes\n",
    "CLASS_DICT = {CLASS_NAMES[i]: i for i in range(len(CLASS_NAMES))}\n",
    "\n",
    "\n",
    "from func import CifarDataset\n",
    "\n",
    "# Generate Dataset and DataLoader instances for training data\n",
    "cifar_dataset = CifarDataset(root_dir = ROOT_DIR, labels=LABELS, transform=transforms.ToTensor(), class_dict=CLASS_DICT)\n",
    "from torch.utils.data import random_split\n",
    "train, test = random_split(cifar_dataset, [40000, 10000])\n",
    "test_loader = DataLoader(dataset=train, batch_size=64, shuffle=True)\n",
    "train_loader = DataLoader(dataset=test, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [01:04<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.8977, Train accuracy: 0.3020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [04:09<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:09<00:00, 16.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.5757, Train accuracy: 0.4341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:20<00:00, 30.42it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# # Load the MNIST dataset\n",
    "# batch_size = 64\n",
    "# train_dataset = MNIST(root='.', train=True, transform=ToTensor(), download=True)\n",
    "# test_dataset = MNIST(root='.', train=False, transform=ToTensor(), download=True)\n",
    "\n",
    "# # Create data loaders\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Create model, criterion, and optimizer\n",
    "model = CNN_3_class(10)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Train the model\n",
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch {epoch+1}/{epochs}')\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    for data in tqdm(train_loader):\n",
    "        results = model.train_step(data, optimizer, criterion)\n",
    "        train_losses.append(results['loss'].item())\n",
    "        train_accuracies.append(results['accuracy'].item())\n",
    "\n",
    "    # Calculate average training loss and accuracy for the epoch\n",
    "    avg_train_loss = sum(train_losses) / len(train_losses)\n",
    "    avg_train_accuracy = sum(train_accuracies) / len(train_accuracies)\n",
    "    print(f'Train loss: {avg_train_loss:.4f}, Train accuracy: {avg_train_accuracy:.4f}')\n",
    "\n",
    "    # Test the model\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader):\n",
    "            results = model.test_step(data, criterion)\n",
    "            test_losses.append(results['loss'].item())\n",
    "            test_accuracies.append(results['accuracy'].item())\n",
    "\n",
    "    # Calculate average test loss and accuracy for the epoch\n",
    "    avg_test_loss = sum(test_losses) / len(test_losses)\n",
    "    avg_test_accuracy = sum(test_accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from func import *\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "# Path to directory containing training images\n",
    "ROOT_DIR = 'Cifar10\\\\train'\n",
    "# Path to Dataframe with labels for training data\n",
    "LABELS = 'Cifar10\\\\trainLabels.csv'\n",
    "# All unique labels\n",
    "CLASS_NAMES = ['frog', 'truck', 'deer', 'automobile', 'bird', 'horse', 'ship', 'cat', 'dog',\n",
    " 'airplane']\n",
    "# Dictionary for encoding classes\n",
    "CLASS_DICT = {CLASS_NAMES[i]: i for i in range(len(CLASS_NAMES))}\n",
    "\n",
    "# Generate Dataset and DataLoader instances for training data\n",
    "cifar_dataset = CifarDataset(root_dir = ROOT_DIR, labels=LABELS, transform=transforms.ToTensor(), class_dict=CLASS_DICT)\n",
    "train_loader = DataLoader(dataset=cifar_dataset, batch_size=32, shuffle=True, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm import tqdm\n",
    "from dataset import *\n",
    "\n",
    "class MyCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(64*5*5, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(torch.relu(self.conv1(x)))\n",
    "        x = self.pool2(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64*5*5)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def train_step(self, data, optimizer, criterion):\n",
    "        x, y = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = self(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        accuracy = (logits.argmax(dim=1) == y).float().mean()\n",
    "\n",
    "        return {'loss': loss, 'accuracy': accuracy}\n",
    "\n",
    "    def test_step(self, data, criterion):\n",
    "        x, y = data\n",
    "\n",
    "        logits = self(x)\n",
    "        loss = criterion(logits, y)\n",
    "        accuracy = (logits.argmax(dim=1) == y).float().mean()\n",
    "\n",
    "        return {'loss': loss, 'accuracy': accuracy}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [32, 1, 3, 3], expected input[32, 3, 32, 32] to have 1 channels, but got 3 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mikol\\OneDrive\\Desktop\\Deep_Learning\\CNN.ipynb Cell 4\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mikol/OneDrive/Desktop/Deep_Learning/CNN.ipynb#X13sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# zerowanie gradientu, wykonanie forward pass, obliczenie błędu, wykonanie backward pass i aktualizacja wag\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mikol/OneDrive/Desktop/Deep_Learning/CNN.ipynb#X13sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mikol/OneDrive/Desktop/Deep_Learning/CNN.ipynb#X13sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mikol/OneDrive/Desktop/Deep_Learning/CNN.ipynb#X13sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mikol/OneDrive/Desktop/Deep_Learning/CNN.ipynb#X13sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\mikol\\OneDrive\\Desktop\\Deep_Learning\\CNN.ipynb Cell 4\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mikol/OneDrive/Desktop/Deep_Learning/CNN.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mikol/OneDrive/Desktop/Deep_Learning/CNN.ipynb#X13sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool1(torch\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mikol/OneDrive/Desktop/Deep_Learning/CNN.ipynb#X13sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool2(torch\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x)))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mikol/OneDrive/Desktop/Deep_Learning/CNN.ipynb#X13sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m64\u001b[39m\u001b[39m*\u001b[39m\u001b[39m5\u001b[39m\u001b[39m*\u001b[39m\u001b[39m5\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\mikol\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 1, 3, 3], expected input[32, 3, 32, 32] to have 1 channels, but got 3 channels instead"
     ]
    }
   ],
   "source": [
    "# definicja modelu, kryterium oraz optymalizatora\n",
    "model = MyCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# przypisanie modelu do GPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# trening modelu\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "    \n",
    "    # przejście przez wszystkie mini-batche w DataLoader\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # zerowanie gradientu, wykonanie forward pass, obliczenie błędu, wykonanie backward pass i aktualizacja wag\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # obliczenie metryk\n",
    "        running_loss += loss.item()\n",
    "        running_accuracy += (outputs.argmax(dim=1) == labels).float().mean().item()\n",
    "        \n",
    "        # wyświetlenie metryk co 100 mini-batchy\n",
    "        if i % 100 == 99:\n",
    "            print(f'Epoch {epoch+1}, mini-batch {i+1}, loss: {running_loss/100:.3f}, accuracy: {running_accuracy/100:.3f}')\n",
    "            running_loss = 0.0\n",
    "            running_accuracy = 0.0\n",
    "\n",
    "print('Finished training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
