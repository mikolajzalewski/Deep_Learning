{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 klasy potrzebne do tuningu hiperparametrów:\n",
    "1. Net_wrapper - klasa do załadowania modelu sieci i pozostałych elementów niezbędnych w procesie trenowania (optimizer, loss criterion, scheduler itp.)\n",
    "2. GridSearch - klasyczny grid search po danych parametrach\n",
    "3. RandomSearch - klasyczny random search, czyli losujemy n-krotnie losowe zestawienia parametrów."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalacja "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeśli import .ipynb nie przejdzie (to średnio działa często) można przekopiować klasy do pliku .py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'CNN_3_class' from 'CNN' (CNN.ipynb)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mimport_ipynb\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mCNN\u001b[39;00m \u001b[39mimport\u001b[39;00m CNN_3_class\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mhyperparameter_search\u001b[39;00m \u001b[39mimport\u001b[39;00m Net_wrapper, GridSearch, RandomSearch\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'CNN_3_class' from 'CNN' (CNN.ipynb)"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from CNN import CNN_3_class\n",
    "from hyperparameter_search import Net_wrapper, GridSearch, RandomSearch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dane do testowania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ładuję przykładowe dane do testowania funkcji. \n",
    "\n",
    "from torch.utils.data import SubsetRandomSampler, Subset\n",
    "\n",
    "train_dataset = datasets.cifar_train\n",
    "val_dataset = datasets.cifar_val\n",
    "\n",
    "# Pierwsze 500 obrazków ze zbioru testowego i treningowego\n",
    "\n",
    "subset_indices = list(range(500))\n",
    "subset_sampler = SubsetRandomSampler(subset_indices)\n",
    "\n",
    "subset_train_dataset = Subset(train_dataset, subset_indices)\n",
    "subset_val_dataset = Subset(val_dataset, subset_indices)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Net_wrapper\n",
    "Jeśli zamierzasz korzystać z GridSearch lub RandomSearch. jedyny konieczny parametr to model sieci (sama klasa modelu, bez parametrów). Poza tym możesz ustawić na sztywno te parametry, których nie zamierzasz przeszukiwać"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ustawiony na sztywno model i max_epochs (chociaż w teorii jeśli w \n",
    "# gridsearchu lub random searchu podasz parametr max_epochs to i tak się będzie zmieniać)\n",
    "\n",
    "my_net = Net_wrapper(model=CNN_3_class, max_epochs=5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bazowe argumenty, step_size to ilość epok po której wartość learning rate spadnie, a gamma to o ile ta wartość spadnie. \n",
    "# Pozostałe parametry raczej jasne\n",
    "\n",
    "my_net2 = Net_wrapper(model=CNN_3_class, criterion=nn.CrossEntropyLoss(), optimizer=optim.Adam, weight_decay = 0,\n",
    "                 max_epochs=5, batch_size=32, learning_rate=0.001, step_size=10, gamma=0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metoda która liczy accuracy i loss dla konkretnego modelu\n",
    "\n",
    "my_net2.score(subset_train_dataset, subset_val_dataset, verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poza tym jeśli twoja klasa sieci przyjmuje jakieś argumenty na wejściu (np kernel_size, no_neurons) to można je też na sztywno podać jako parametr Net_wrappera i on je zaaplikuje do sieci przed treningiem. W przeciwnym razie bedą się ładować defaultowe (albo takie określone w Grid czy Random Searchu)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. GridSearch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podajesz na wejściu wcześniej stworzoną instancję Net_wrappera, słownik parametrów, które chcesz przeszukać, to czy chcesz zrobić całą siatkę możliwości parametrów czy robić sobie step by step (parametr step_by_step) i verbose (czy chcesz printować rzeczy takie jak accuracy podczas searchowania). Przykład działania poniżej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# słownik hiperparametrów do przeszukania \n",
    "# nazwy hiperparametrów mają być takie same jak w Net_wraperze lub jak parametry modelu sieci podawane w inicie\n",
    "\n",
    "test_hyper_params = {'learning_rate': [0.0001, 0.0005], 'batch_size': [8, 16], 'no_neurons': [50, 100]}\n",
    "\n",
    "# Instancja Net_wrappera z ustawionym modelem i maksymalną liczbą epok (oraz defultowymi pozostałymi parametrami)\n",
    "\n",
    "my_net = Net_wrapper(model=CNN_3_class, max_epochs=5)\n",
    "\n",
    "# Instancja grid search, podajemy sieć my_net, słownik parametrów, chcemy robić step_by_step i z printowaniem wyników na bieżąco\n",
    "\n",
    "gs = GridSearch(net=my_net, param_grid=test_hyper_params, step_by_step=True, verbose=1)\n",
    "\n",
    "# Fitujemy model datasetami (nie loaderami) danych treningowych i walidacyjnych.\n",
    "\n",
    "gs = gs.fit(subset_train_dataset, subset_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyprintowanie najlepszego val_accuracy wśród wszystkich i najlepszych parametrów\n",
    "\n",
    "print(gs.best_score)\n",
    "print(gs.best_params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Random Search"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wszystko prawie tak samo jak w grid search, jedyne różnice:\n",
    "1. Słownik działa tak, że jeśli Twoje wartości to float'y, to będzie losowana wartość z przedziału określonego w słowniku z rozkładu jednostajnego (np `learning_rate`: [0.01, 0.1] to losowy float z tego przedziału). Jeśli int'y to też z jednostajnego, ale na integerach. Jeśli jakiekolwiek inne wartości niż float i integer, to losowa wartość z podanych (np `optimizer`: [`Adam`, `SGD`, `Adagrad`] to wybierze jedno z 3) \n",
    "2. W metodzie `fit` masz parametr `n_trials` czyli liczba losowych przeszukań."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# słownik hipermarametrów\n",
    "\n",
    "test_hyper_params = {'learning_rate': [0.0001, 0.01], 'batch_size': [8, 128]}\n",
    "\n",
    "# instancja wrappera\n",
    "\n",
    "my_net = Net_wrapper(model=CNN_3_class)\n",
    "\n",
    "# instancja random searcha, podajemy instancję wrappera, słownik parametrów i czy printujemy wyniki w trakcie szukania.\n",
    "\n",
    "rs = RandomSearch(my_net, test_hyper_params, verbose=1)\n",
    "\n",
    "# Fit, podajemy liczbę przeszukiwań\n",
    "\n",
    "rs.fit(subset_train_dataset, subset_val_dataset, n_trials = 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
