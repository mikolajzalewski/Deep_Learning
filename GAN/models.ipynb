{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (3, 256, 256)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Linear block for MLP.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, out_features, activation=True, batch_norm=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_features (int): Number of input features.\n",
    "            out_features (int): Number of output features.\n",
    "            activation (bool): If True, ReLU activation is used.\n",
    "            batch_norm (bool): If True, batch normalization is used.\n",
    "        \"\"\"\n",
    "        super(LinearBlock, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "        self.activation = nn.LeakyReLU(0.2) if activation else None\n",
    "        self.batch_norm = nn.BatchNorm1d(out_features) if batch_norm else None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        if self.activation:\n",
    "            x = self.activation(x)\n",
    "        if self.batch_norm:\n",
    "            x = self.batch_norm(x)\n",
    "        if self.dropout:\n",
    "            x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, img_shape):\n",
    "        super(Generator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.img_shape = img_shape\n",
    "        self.model = nn.Sequential(\n",
    "            LinearBlock(latent_dim, 256, batch_norm=False),\n",
    "            LinearBlock(256, 512),\n",
    "            LinearBlock(512, 1024),\n",
    "            LinearBlock(1024, 2048),\n",
    "            nn.Linear(2048, int(torch.prod(torch.tensor(img_shape)))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = x.view(x.size(0), *self.img_shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_shape):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            LinearBlock(int(torch.prod(torch.tensor(img_shape))), 512, batch_norm=False),\n",
    "            LinearBlock(512, 256),\n",
    "            LinearBlock(256, 1, activation=False, batch_norm=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DC-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvTransposedBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional transpose block for DCGAN.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, batch_norm=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels.\n",
    "            out_channels (int): Number of output channels.\n",
    "            kernel_size (int): Kernel size.\n",
    "            stride (int): Stride.\n",
    "            padding (int): Padding.\n",
    "            batch_norm (bool): If True, batch normalization is used.\n",
    "        \"\"\"\n",
    "        super(ConvTransposedBlock, self).__init__()\n",
    "        self.conv_transpose = nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias=False)\n",
    "        self.batch_norm = nn.BatchNorm2d(out_channels) if batch_norm else None\n",
    "        self.activation = nn.ReLU(True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_transpose(x)\n",
    "        if self.batch_norm:\n",
    "            x = self.batch_norm(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConvBlock(nn.module):\n",
    "    \"\"\"\n",
    "    Convolutional block for DCGAN.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, batch_norm=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels.\n",
    "            out_channels (int): Number of output channels.\n",
    "            kernel_size (int): Kernel size.\n",
    "            stride (int): Stride.\n",
    "            padding (int): Padding.\n",
    "            batch_norm (bool): If True, batch normalization is used.\n",
    "        \"\"\"\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False)\n",
    "        self.batch_norm = nn.BatchNorm2d(out_channels) if batch_norm else None\n",
    "        self.activation = nn.LeakyReLU(0.2, inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.batch_norm:\n",
    "            x = self.batch_norm(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_latent_vector_size, feature_maps_size, num_channels=3):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # input: z_latent_vector_size x 1 x 1\n",
    "            ConvTransposedBlock(z_latent_vector_size, feature_maps_size * 32, 4, 1, 0),\n",
    "            # (feature_maps_size*32) x 4 x 4\n",
    "            ConvTransposedBlock(feature_maps_size * 32, feature_maps_size * 16, 4, 1, 0),\n",
    "            # (feature_maps_size*16) x 8 x 8\n",
    "            ConvTransposedBlock(feature_maps_size * 16, feature_maps_size * 8, 4, 2, 1),\n",
    "            # (feature_maps_size*8) x 16 x 16\n",
    "            ConvTransposedBlock(feature_maps_size * 8, feature_maps_size * 4, 4, 2, 1),\n",
    "            # (feature_maps_size*4) x 32 x 32\n",
    "            ConvTransposedBlock(feature_maps_size * 4, feature_maps_size * 2, 4, 2, 1),\n",
    "            # (feature_maps_size*2) x 64 x 64\n",
    "            ConvTransposedBlock(feature_maps_size * 2, feature_maps_size, 4, 2, 1),\n",
    "            # (feature_maps_size) x 128 x 128\n",
    "            nn.ConvTranspose2d(feature_maps_size, num_channels, 4, 2, 1),\n",
    "            nn.Tanh()\n",
    "            # (num_channels) x 256 x 256\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = input.view(input.size(0), input.size(1), 1, 1)\n",
    "        return self.model(input)\n",
    "    \n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_channels, feature_maps_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # input: 3x256x256\n",
    "            ConvBlock(num_channels, feature_maps_size, 4, 2, 1, batch_norm=False),\n",
    "            # (feature_maps_size) x 128 x 128\n",
    "            ConvBlock(feature_maps_size, feature_maps_size * 2, 4, 2, 1),\n",
    "            # (feature_maps_size*2) x 64 x 64\n",
    "            ConvBlock(feature_maps_size * 2, feature_maps_size * 4, 4, 2, 1),\n",
    "            # (feature_maps_size*4) x 32 x 32\n",
    "            ConvBlock(feature_maps_size * 4, feature_maps_size * 8, 4, 2, 1),\n",
    "            # (feature_maps_size*8) x 16 x 16\n",
    "            nn.Conv2d(feature_maps_size * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
